// src/readers/from-fetch.ts
function parseContentRange(input) {
  const matches = input.match(/^(\w+) ((\d+)-(\d+)|\*)\/(\d+|\*)$/);
  if (!matches)
    return null;
  const [, unit, , start, end, size] = matches;
  const range = {
    unit,
    start: start != null ? Number(start) : null,
    end: end != null ? Number(end) : null,
    size: size === "*" ? null : Number(size)
  };
  if (range.start === null && range.end === null && range.size === null) {
    return null;
  }
  return range;
}
var validateContentRangeAndDetectIfSupported = (actualRange, parsedContentRange, statusCode) => {
  if (statusCode === 206) {
    return { supportsContentRange: true };
  }
  if (typeof actualRange === "number" && parsedContentRange?.start !== actualRange) {
    if (actualRange === 0) {
      return { supportsContentRange: false };
    }
    throw new Error(`Range header (${actualRange}) does not match content-range header (${parsedContentRange?.start})`);
  }
  if (actualRange !== null && typeof actualRange !== "number" && (parsedContentRange?.start !== actualRange[0] || parsedContentRange?.end !== actualRange[1])) {
    throw new Error(`Range header (${actualRange}) does not match content-range header (${parsedContentRange?.start})`);
  }
  return { supportsContentRange: true };
};
var fetchReader = {
  read: async (src, range, signal) => {
    if (typeof src !== "string") {
      throw new Error("src must be a string when using `fetchReader`");
    }
    const resolvedUrl = typeof window !== "undefined" && typeof window.location !== "undefined" ? new URL(src, window.location.origin).toString() : src;
    if (!resolvedUrl.startsWith("https://") && !resolvedUrl.startsWith("blob:") && !resolvedUrl.startsWith("http://")) {
      return Promise.reject(new Error(resolvedUrl + " is not a URL - needs to start with http:// or https:// or blob:. If you want to read a local file, pass `reader: nodeReader` to parseMedia()."));
    }
    const controller = new AbortController;
    const cache = typeof navigator !== "undefined" && navigator.userAgent.includes("Cloudflare-Workers") ? undefined : "no-store";
    const actualRange = range === null ? 0 : range;
    const res = await fetch(resolvedUrl, {
      headers: typeof actualRange === "number" ? {
        Range: `bytes=${actualRange}-`
      } : {
        Range: `bytes=${`${actualRange[0]}-${actualRange[1]}`}`
      },
      signal: controller.signal,
      cache
    });
    const contentRange = res.headers.get("content-range");
    const parsedContentRange = contentRange ? parseContentRange(contentRange) : null;
    const { supportsContentRange } = validateContentRangeAndDetectIfSupported(actualRange, parsedContentRange, res.status);
    signal?.addEventListener("abort", () => {
      controller.abort(new Error("Aborted by user"));
    }, { once: true });
    if (res.status.toString().startsWith("4") || res.status.toString().startsWith("5")) {
      throw new Error(`Server returned status code ${res.status} for ${src} and range ${actualRange}`);
    }
    if (!res.body) {
      throw new Error("No body");
    }
    const length = res.headers.get("content-length");
    const contentLength = length === null ? null : parseInt(length, 10);
    const contentDisposition = res.headers.get("content-disposition");
    const name = contentDisposition?.match(/filename="([^"]+)"/)?.[1];
    const fallbackName = src.split("/").pop();
    const reader = res.body.getReader();
    if (signal) {
      signal.addEventListener("abort", () => {
        reader.cancel().catch(() => {
        });
      }, { once: true });
    }
    return {
      reader: {
        reader,
        abort: () => {
          controller.abort();
        }
      },
      contentLength,
      contentType: res.headers.get("content-type"),
      name: name ?? fallbackName,
      supportsContentRange
    };
  },
  getLength: async (src) => {
    if (typeof src !== "string") {
      throw new Error("src must be a string when using `fetchReader`");
    }
    const res = await fetch(src, {
      method: "HEAD"
    });
    if (!res.body) {
      throw new Error("No body");
    }
    const length = res.headers.get("content-length");
    if (!length) {
      throw new Error("No content-length");
    }
    return parseInt(length, 10);
  }
};

// src/aac-codecprivate.ts
var getSampleRateFromSampleFrequencyIndex = (samplingFrequencyIndex) => {
  switch (samplingFrequencyIndex) {
    case 0:
      return 96000;
    case 1:
      return 88200;
    case 2:
      return 64000;
    case 3:
      return 48000;
    case 4:
      return 44100;
    case 5:
      return 32000;
    case 6:
      return 24000;
    case 7:
      return 22050;
    case 8:
      return 16000;
    case 9:
      return 12000;
    case 10:
      return 11025;
    case 11:
      return 8000;
    case 12:
      return 7350;
    default:
      throw new Error(`Unexpected sampling frequency index ${samplingFrequencyIndex}`);
  }
};
var getConfigForSampleRate = (sampleRate) => {
  if (sampleRate === 96000) {
    return 0;
  }
  if (sampleRate === 88200) {
    return 1;
  }
  if (sampleRate === 64000) {
    return 2;
  }
  if (sampleRate === 48000) {
    return 3;
  }
  if (sampleRate === 44100) {
    return 4;
  }
  if (sampleRate === 32000) {
    return 5;
  }
  if (sampleRate === 24000) {
    return 6;
  }
  if (sampleRate === 22050) {
    return 7;
  }
  if (sampleRate === 16000) {
    return 8;
  }
  if (sampleRate === 12000) {
    return 9;
  }
  if (sampleRate === 11025) {
    return 10;
  }
  if (sampleRate === 8000) {
    return 11;
  }
  if (sampleRate === 7350) {
    return 12;
  }
  throw new Error(`Unexpected sample rate ${sampleRate}`);
};
var createAacCodecPrivate = ({
  audioObjectType,
  sampleRate,
  channelConfiguration
}) => {
  const bits = `${audioObjectType.toString(2).padStart(5, "0")}${getConfigForSampleRate(sampleRate).toString(2).padStart(4, "0")}${channelConfiguration.toString(2).padStart(4, "0")}000`;
  if (bits.length !== 16) {
    throw new Error("Invalid AAC codec private " + bits.length);
  }
  if (channelConfiguration === 0 || channelConfiguration > 7) {
    throw new Error("Invalid channel configuration " + channelConfiguration);
  }
  const firstByte = parseInt(bits.slice(0, 8), 2);
  const secondByte = parseInt(bits.slice(8, 16), 2);
  return new Uint8Array([firstByte, secondByte]);
};
var parseAacCodecPrivate = (bytes) => {
  if (bytes.length < 2) {
    throw new Error("Invalid AAC codec private length");
  }
  const bits = `${bytes[0].toString(2).padStart(8, "0")}${bytes[1].toString(2).padStart(8, "0")}`;
  if (bits.length !== 16) {
    throw new Error("Invalid AAC codec private bits length");
  }
  const audioObjectType = parseInt(bits.slice(0, 5), 2);
  const samplingFrequencyIndex = parseInt(bits.slice(5, 9), 2);
  const channelConfiguration = parseInt(bits.slice(9, 13), 2);
  const sampleRate = getSampleRateFromSampleFrequencyIndex(samplingFrequencyIndex);
  return {
    audioObjectType,
    sampleRate,
    channelConfiguration
  };
};
var mapAudioObjectTypeToCodecString = (audioObjectType) => {
  switch (audioObjectType) {
    case 1:
      return "mp4a.40.2";
    case 2:
      return "mp4a.40.5";
    case 3:
      return "mp4a.40.29";
    case 4:
      return "mp4a.40.1";
    case 5:
      return "mp4a.40.3";
    case 6:
      return "mp4a.40.4";
    case 17:
      return "mp4a.40.17";
    case 23:
      return "mp4a.40.23";
    default:
      throw new Error(`Unexpected audio object type ${audioObjectType}`);
  }
};

// src/boxes/iso-base-media/ftyp.ts
var parseFtyp = ({
  iterator,
  size,
  offset
}) => {
  const majorBrand = iterator.getByteString(4, false);
  const minorVersion = iterator.getFourByteNumber();
  const types = (size - iterator.counter.getOffset()) / 4;
  const compatibleBrands = [];
  for (let i = 0;i < types; i++) {
    compatibleBrands.push(iterator.getByteString(4, false).trim());
  }
  const offsetAtEnd = iterator.counter.getOffset();
  return {
    type: "ftyp-box",
    majorBrand,
    minorVersion,
    compatibleBrands,
    offset,
    boxSize: offsetAtEnd - offset
  };
};

// src/boxes/webm/segments/all-segments.ts
var matroskaElements = {
  Header: "0x1a45dfa3",
  EBMLMaxIDLength: "0x42f2",
  EBMLVersion: "0x4286",
  EBMLReadVersion: "0x42f7",
  EBMLMaxSizeLength: "0x42f3",
  DocType: "0x4282",
  DocTypeVersion: "0x4287",
  DocTypeReadVersion: "0x4285",
  Segment: "0x18538067",
  SeekHead: "0x114d9b74",
  Seek: "0x4dbb",
  SeekID: "0x53ab",
  SeekPosition: "0x53ac",
  Info: "0x1549a966",
  SegmentUUID: "0x73a4",
  SegmentFilename: "0x7384",
  PrevUUID: "0x3cb923",
  PrevFilename: "0x3c83ab",
  NextUUID: "0x3eb923",
  NextFilename: "0x3e83bb",
  SegmentFamily: "0x4444",
  ChapterTranslate: "0x6924",
  ChapterTranslateID: "0x69a5",
  ChapterTranslateCodec: "0x69bf",
  ChapterTranslateEditionUID: "0x69fc",
  TimestampScale: "0x2ad7b1",
  Duration: "0x4489",
  DateUTC: "0x4461",
  Title: "0x7ba9",
  MuxingApp: "0x4d80",
  WritingApp: "0x5741",
  Cluster: "0x1f43b675",
  Timestamp: "0xe7",
  SilentTracks: "0x5854",
  SilentTrackNumber: "0x58d7",
  Position: "0xa7",
  PrevSize: "0xab",
  SimpleBlock: "0xa3",
  BlockGroup: "0xa0",
  Block: "0xa1",
  BlockVirtual: "0xa2",
  BlockAdditions: "0x75a1",
  BlockMore: "0xa6",
  BlockAdditional: "0xa5",
  BlockAddID: "0xee",
  BlockDuration: "0x9b",
  ReferencePriority: "0xfa",
  ReferenceBlock: "0xfb",
  ReferenceVirtual: "0xfd",
  CodecState: "0xa4",
  DiscardPadding: "0x75a2",
  Slices: "0x8e",
  TimeSlice: "0xe8",
  LaceNumber: "0xcc",
  FrameNumber: "0xcd",
  BlockAdditionID: "0xcb",
  Delay: "0xce",
  SliceDuration: "0xcf",
  ReferenceFrame: "0xc8",
  ReferenceOffset: "0xc9",
  ReferenceTimestamp: "0xca",
  EncryptedBlock: "0xaf",
  Tracks: "0x1654ae6b",
  TrackEntry: "0xae",
  TrackNumber: "0xd7",
  TrackUID: "0x73c5",
  TrackType: "0x83",
  FlagEnabled: "0xb9",
  FlagDefault: "0x88",
  FlagForced: "0x55aa",
  FlagHearingImpaired: "0x55ab",
  FlagVisualImpaired: "0x55ac",
  FlagTextDescriptions: "0x55ad",
  FlagOriginal: "0x55ae",
  FlagCommentary: "0x55af",
  FlagLacing: "0x9c",
  MinCache: "0x6de7",
  MaxCache: "0x6df8",
  DefaultDuration: "0x23e383",
  DefaultDecodedFieldDuration: "0x234e7a",
  TrackTimestampScale: "0x23314f",
  TrackOffset: "0x537f",
  MaxBlockAdditionID: "0x55ee",
  BlockAdditionMapping: "0x41e4",
  BlockAddIDValue: "0x41f0",
  BlockAddIDName: "0x41a4",
  BlockAddIDType: "0x41e7",
  BlockAddIDExtraData: "0x41ed",
  Name: "0x536e",
  Language: "0x22b59c",
  LanguageBCP47: "0x22b59d",
  CodecID: "0x86",
  CodecPrivate: "0x63a2",
  CodecName: "0x258688",
  AttachmentLink: "0x7446",
  CodecSettings: "0x3a9697",
  CodecInfoURL: "0x3b4040",
  CodecDownloadURL: "0x26b240",
  CodecDecodeAll: "0xaa",
  TrackOverlay: "0x6fab",
  CodecDelay: "0x56aa",
  SeekPreRoll: "0x56bb",
  TrackTranslate: "0x6624",
  TrackTranslateTrackID: "0x66a5",
  TrackTranslateCodec: "0x66bf",
  TrackTranslateEditionUID: "0x66fc",
  Video: "0xe0",
  FlagInterlaced: "0x9a",
  FieldOrder: "0x9d",
  StereoMode: "0x53b8",
  AlphaMode: "0x53c0",
  OldStereoMode: "0x53b9",
  PixelWidth: "0xb0",
  PixelHeight: "0xba",
  PixelCropBottom: "0x54aa",
  PixelCropTop: "0x54bb",
  PixelCropLeft: "0x54cc",
  PixelCropRight: "0x54dd",
  DisplayWidth: "0x54b0",
  DisplayHeight: "0x54ba",
  DisplayUnit: "0x54b2",
  AspectRatioType: "0x54b3",
  UncompressedFourCC: "0x2eb524",
  GammaValue: "0x2fb523",
  FrameRate: "0x2383e3",
  Colour: "0x55b0",
  MatrixCoefficients: "0x55b1",
  BitsPerChannel: "0x55b2",
  ChromaSubsamplingHorz: "0x55b3",
  ChromaSubsamplingVert: "0x55b4",
  CbSubsamplingHorz: "0x55b5",
  CbSubsamplingVert: "0x55b6",
  ChromaSitingHorz: "0x55b7",
  ChromaSitingVert: "0x55b8",
  Range: "0x55b9",
  TransferCharacteristics: "0x55ba",
  Primaries: "0x55bb",
  MaxCLL: "0x55bc",
  MaxFALL: "0x55bd",
  MasteringMetadata: "0x55d0",
  PrimaryRChromaticityX: "0x55d1",
  PrimaryRChromaticityY: "0x55d2",
  PrimaryGChromaticityX: "0x55d3",
  PrimaryGChromaticityY: "0x55d4",
  PrimaryBChromaticityX: "0x55d5",
  PrimaryBChromaticityY: "0x55d6",
  WhitePointChromaticityX: "0x55d7",
  WhitePointChromaticityY: "0x55d8",
  LuminanceMax: "0x55d9",
  LuminanceMin: "0x55da",
  Projection: "0x7670",
  ProjectionType: "0x7671",
  ProjectionPrivate: "0x7672",
  ProjectionPoseYaw: "0x7673",
  ProjectionPosePitch: "0x7674",
  ProjectionPoseRoll: "0x7675",
  Audio: "0xe1",
  SamplingFrequency: "0xb5",
  OutputSamplingFrequency: "0x78b5",
  Channels: "0x9f",
  ChannelPositions: "0x7d7b",
  BitDepth: "0x6264",
  Emphasis: "0x52f1",
  TrackOperation: "0xe2",
  TrackCombinePlanes: "0xe3",
  TrackPlane: "0xe4",
  TrackPlaneUID: "0xe5",
  TrackPlaneType: "0xe6",
  TrackJoinBlocks: "0xe9",
  TrackJoinUID: "0xed",
  TrickTrackUID: "0xc0",
  TrickTrackSegmentUID: "0xc1",
  TrickTrackFlag: "0xc6",
  TrickMasterTrackUID: "0xc7",
  TrickMasterTrackSegmentUID: "0xc4",
  ContentEncodings: "0x6d80",
  ContentEncoding: "0x6240",
  ContentEncodingOrder: "0x5031",
  ContentEncodingScope: "0x5032",
  ContentEncodingType: "0x5033",
  ContentCompression: "0x5034",
  ContentCompAlgo: "0x4254",
  ContentCompSettings: "0x4255",
  ContentEncryption: "0x5035",
  ContentEncAlgo: "0x47e1",
  ContentEncKeyID: "0x47e2",
  ContentEncAESSettings: "0x47e7",
  AESSettingsCipherMode: "0x47e8",
  ContentSignature: "0x47e3",
  ContentSigKeyID: "0x47e4",
  ContentSigAlgo: "0x47e5",
  ContentSigHashAlgo: "0x47e6",
  Cues: "0x1c53bb6b",
  CuePoint: "0xbb",
  CueTime: "0xb3",
  CueTrackPositions: "0xb7",
  CueTrack: "0xf7",
  CueClusterPosition: "0xf1",
  CueRelativePosition: "0xf0",
  CueDuration: "0xb2",
  CueBlockNumber: "0x5378",
  CueCodecState: "0xea",
  CueReference: "0xdb",
  CueRefTime: "0x96",
  CueRefCluster: "0x97",
  CueRefNumber: "0x535f",
  CueRefCodecState: "0xeb",
  Attachments: "0x1941a469",
  AttachedFile: "0x61a7",
  FileDescription: "0x467e",
  FileName: "0x466e",
  FileMediaType: "0x4660",
  FileData: "0x465c",
  FileUID: "0x46ae",
  FileReferral: "0x4675",
  FileUsedStartTime: "0x4661",
  FileUsedEndTime: "0x4662",
  Chapters: "0x1043a770",
  EditionEntry: "0x45b9",
  EditionUID: "0x45bc",
  EditionFlagHidden: "0x45bd",
  EditionFlagDefault: "0x45db",
  EditionFlagOrdered: "0x45dd",
  EditionDisplay: "0x4520",
  EditionString: "0x4521",
  EditionLanguageIETF: "0x45e4",
  ChapterAtom: "0xb6",
  ChapterUID: "0x73c4",
  ChapterStringUID: "0x5654",
  ChapterTimeStart: "0x91",
  ChapterTimeEnd: "0x92",
  ChapterFlagHidden: "0x98",
  ChapterFlagEnabled: "0x4598",
  ChapterSegmentUUID: "0x6e67",
  ChapterSkipType: "0x4588",
  ChapterSegmentEditionUID: "0x6ebc",
  ChapterPhysicalEquiv: "0x63c3",
  ChapterTrack: "0x8f",
  ChapterTrackUID: "0x89",
  ChapterDisplay: "0x80",
  ChapString: "0x85",
  ChapLanguage: "0x437c",
  ChapLanguageBCP47: "0x437d",
  ChapCountry: "0x437e",
  ChapProcess: "0x6944",
  ChapProcessCodecID: "0x6955",
  ChapProcessPrivate: "0x450d",
  ChapProcessCommand: "0x6911",
  ChapProcessTime: "0x6922",
  ChapProcessData: "0x6933",
  Tags: "0x1254c367",
  Tag: "0x7373",
  Targets: "0x63c0",
  TargetTypeValue: "0x68ca",
  TargetType: "0x63ca",
  TagTrackUID: "0x63c5",
  TagEditionUID: "0x63c9",
  TagChapterUID: "0x63c4",
  TagAttachmentUID: "0x63c6",
  SimpleTag: "0x67c8",
  TagName: "0x45a3",
  TagLanguage: "0x447a",
  TagLanguageBCP47: "0x447b",
  TagDefault: "0x4484",
  TagDefaultBogus: "0x44b4",
  TagString: "0x4487",
  TagBinary: "0x4485",
  Void: "0xec",
  Crc32: "0xbf"
};
var matroskaIds = Object.values(matroskaElements);
var knownIdsWithOneLength = matroskaIds.filter((id) => id.length === 4);
var knownIdsWithTwoLength = matroskaIds.filter((id) => id.length === 6);
var knownIdsWithThreeLength = matroskaIds.filter((id) => id.length === 8);
var ebmlVersion = {
  name: "EBMLVersion",
  type: "uint"
};
var ebmlReadVersion = {
  name: "EBMLReadVersion",
  type: "uint"
};
var ebmlMaxIdLength = {
  name: "EBMLMaxIDLength",
  type: "uint"
};
var ebmlMaxSizeLength = {
  name: "EBMLMaxSizeLength",
  type: "uint"
};
var docType = {
  name: "DocType",
  type: "string"
};
var docTypeVersion = {
  name: "DocTypeVersion",
  type: "uint"
};
var docTypeReadVersion = {
  name: "DocTypeReadVersion",
  type: "uint"
};
var voidEbml = {
  name: "Void",
  type: "uint8array"
};
var matroskaHeader = {
  name: "Header",
  type: "children"
};
var seekId = {
  name: "SeekID",
  type: "hex-string"
};
var _name = {
  name: "Name",
  type: "string"
};
var minCache = {
  name: "MinCache",
  type: "uint"
};
var maxCache = {
  name: "MaxCache",
  type: "uint"
};
var seekPosition = {
  name: "SeekPosition",
  type: "uint"
};
var seek = {
  name: "Seek",
  type: "children"
};
var seekHead = {
  name: "SeekHead",
  type: "children"
};
var trackType = {
  name: "TrackType",
  type: "uint"
};
var widthType = {
  name: "PixelWidth",
  type: "uint"
};
var heightType = {
  name: "PixelHeight",
  type: "uint"
};
var muxingApp = {
  name: "MuxingApp",
  type: "string"
};
var duration = {
  name: "Duration",
  type: "float"
};
var timestampScale = {
  name: "TimestampScale",
  type: "uint"
};
var infoType = {
  name: "Info",
  type: "children"
};
var titleType = {
  name: "Title",
  type: "string"
};
var tagTrackUidType = {
  name: "TagTrackUID",
  type: "hex-string"
};
var samplingFrequency = {
  name: "SamplingFrequency",
  type: "float"
};
var channels = {
  name: "Channels",
  type: "uint"
};
var alphaMode = {
  name: "AlphaMode",
  type: "uint"
};
var interlaced = {
  name: "FlagInterlaced",
  type: "uint"
};
var bitDepth = {
  name: "BitDepth",
  type: "uint"
};
var displayWidth = {
  name: "DisplayWidth",
  type: "uint"
};
var displayHeight = {
  name: "DisplayHeight",
  type: "uint"
};
var displayUnit = {
  name: "DisplayUnit",
  type: "uint"
};
var flagLacing = {
  name: "FlagLacing",
  type: "uint"
};
var tagSegment = {
  name: "Tag",
  type: "children"
};
var tags = {
  name: "Tags",
  type: "children"
};
var trackNumber = {
  name: "TrackNumber",
  type: "uint"
};
var trackUID = {
  name: "TrackUID",
  type: "hex-string"
};
var color = {
  name: "Colour",
  type: "children"
};
var transferCharacteristics = {
  name: "TransferCharacteristics",
  type: "uint"
};
var matrixCoefficients = {
  name: "MatrixCoefficients",
  type: "uint"
};
var primaries = {
  name: "Primaries",
  type: "uint"
};
var range = {
  name: "Range",
  type: "uint"
};
var ChromaSitingHorz = {
  name: "ChromaSitingHorz",
  type: "uint"
};
var ChromaSitingVert = {
  name: "ChromaSitingVert",
  type: "uint"
};
var language = {
  name: "Language",
  type: "string"
};
var defaultDuration = {
  name: "DefaultDuration",
  type: "uint"
};
var codecPrivate = {
  name: "CodecPrivate",
  type: "uint8array"
};
var blockAdditionsSegment = {
  name: "BlockAdditions",
  type: "uint8array"
};
var maxBlockAdditionIdSegment = {
  name: "MaxBlockAdditionID",
  type: "uint"
};
var audioSegment = {
  name: "Audio",
  type: "children"
};
var videoSegment = {
  name: "Video",
  type: "children"
};
var flagDefault = {
  name: "FlagDefault",
  type: "uint"
};
var referenceBlock = {
  name: "ReferenceBlock",
  type: "uint"
};
var blockDurationSegment = {
  name: "BlockDuration",
  type: "uint"
};
var codecName = {
  name: "CodecName",
  type: "string"
};
var trackTimestampScale = {
  name: "TrackTimestampScale",
  type: "float"
};
var trackEntry = {
  name: "TrackEntry",
  type: "children"
};
var tracks = {
  name: "Tracks",
  type: "children"
};
var block = {
  name: "Block",
  type: "uint8array"
};
var simpleBlock = {
  name: "SimpleBlock",
  type: "uint8array"
};
var blockGroup = {
  name: "BlockGroup",
  type: "children"
};
var targetsType = {
  name: "Targets",
  type: "children"
};
var simpleTagType = {
  name: "SimpleTag",
  type: "children"
};
var tagNameType = {
  name: "TagName",
  type: "string"
};
var tagStringType = {
  name: "TagString",
  type: "string"
};
var ebmlMap = {
  [matroskaElements.Header]: matroskaHeader,
  [matroskaElements.DocType]: docType,
  [matroskaElements.Targets]: targetsType,
  [matroskaElements.SimpleTag]: simpleTagType,
  [matroskaElements.TagName]: tagNameType,
  [matroskaElements.TagString]: tagStringType,
  [matroskaElements.DocTypeVersion]: docTypeVersion,
  [matroskaElements.DocTypeReadVersion]: docTypeReadVersion,
  [matroskaElements.EBMLVersion]: ebmlVersion,
  [matroskaElements.EBMLReadVersion]: ebmlReadVersion,
  [matroskaElements.EBMLMaxIDLength]: ebmlMaxIdLength,
  [matroskaElements.EBMLMaxSizeLength]: ebmlMaxSizeLength,
  [matroskaElements.Void]: voidEbml,
  [matroskaElements.Cues]: {
    name: "Cues",
    type: "children"
  },
  [matroskaElements.CuePoint]: {
    name: "CuePoint",
    type: "children"
  },
  [matroskaElements.CueTime]: {
    name: "CueTime",
    type: "uint"
  },
  [matroskaElements.CueTrackPositions]: {
    name: "CueTrackPositions",
    type: "children"
  },
  [matroskaElements.CueClusterPosition]: {
    name: "CueClusterPosition",
    type: "uint"
  },
  [matroskaElements.CueRelativePosition]: {
    name: "CueRelativePosition",
    type: "uint"
  },
  [matroskaElements.CueBlockNumber]: {
    name: "CueBlockNumber",
    type: "uint"
  },
  [matroskaElements.CueTrack]: {
    name: "CueTrack",
    type: "uint"
  },
  [matroskaElements.DateUTC]: {
    name: "DateUTC",
    type: "uint8array"
  },
  [matroskaElements.TrackTimestampScale]: trackTimestampScale,
  [matroskaElements.CodecDelay]: {
    name: "CodecDelay",
    type: "uint8array"
  },
  [matroskaElements.SeekPreRoll]: {
    name: "SeekPreRoll",
    type: "uint8array"
  },
  [matroskaElements.DiscardPadding]: {
    name: "DiscardPadding",
    type: "uint8array"
  },
  [matroskaElements.OutputSamplingFrequency]: {
    name: "OutputSamplingFrequency",
    type: "uint8array"
  },
  [matroskaElements.CodecName]: codecName,
  [matroskaElements.Position]: {
    name: "Position",
    type: "uint8array"
  },
  [matroskaElements.SliceDuration]: {
    name: "SliceDuration",
    type: "uint8array"
  },
  [matroskaElements.TagTrackUID]: tagTrackUidType,
  [matroskaElements.SeekHead]: seekHead,
  [matroskaElements.Seek]: seek,
  [matroskaElements.SeekID]: seekId,
  [matroskaElements.Name]: _name,
  [matroskaElements.MinCache]: minCache,
  [matroskaElements.MaxCache]: maxCache,
  [matroskaElements.SeekPosition]: seekPosition,
  [matroskaElements.Crc32]: {
    name: "Crc32",
    type: "uint8array"
  },
  [matroskaElements.MuxingApp]: muxingApp,
  [matroskaElements.WritingApp]: {
    name: "WritingApp",
    type: "string"
  },
  [matroskaElements.SegmentUUID]: {
    name: "SegmentUUID",
    type: "string"
  },
  [matroskaElements.Duration]: duration,
  [matroskaElements.CodecID]: {
    name: "CodecID",
    type: "string"
  },
  [matroskaElements.TrackType]: trackType,
  [matroskaElements.PixelWidth]: widthType,
  [matroskaElements.PixelHeight]: heightType,
  [matroskaElements.TimestampScale]: timestampScale,
  [matroskaElements.Info]: infoType,
  [matroskaElements.Title]: titleType,
  [matroskaElements.SamplingFrequency]: samplingFrequency,
  [matroskaElements.Channels]: channels,
  [matroskaElements.AlphaMode]: alphaMode,
  [matroskaElements.FlagInterlaced]: interlaced,
  [matroskaElements.BitDepth]: bitDepth,
  [matroskaElements.DisplayHeight]: displayHeight,
  [matroskaElements.DisplayWidth]: displayWidth,
  [matroskaElements.DisplayUnit]: displayUnit,
  [matroskaElements.FlagLacing]: flagLacing,
  [matroskaElements.Tags]: tags,
  [matroskaElements.Tag]: tagSegment,
  [matroskaElements.TrackNumber]: trackNumber,
  [matroskaElements.TrackUID]: trackUID,
  [matroskaElements.Colour]: color,
  [matroskaElements.Language]: language,
  [matroskaElements.DefaultDuration]: defaultDuration,
  [matroskaElements.CodecPrivate]: codecPrivate,
  [matroskaElements.BlockDuration]: blockDurationSegment,
  [matroskaElements.BlockAdditions]: blockAdditionsSegment,
  [matroskaElements.MaxBlockAdditionID]: maxBlockAdditionIdSegment,
  [matroskaElements.Audio]: audioSegment,
  [matroskaElements.Video]: videoSegment,
  [matroskaElements.FlagDefault]: flagDefault,
  [matroskaElements.ReferenceBlock]: referenceBlock,
  [matroskaElements.TrackEntry]: trackEntry,
  [matroskaElements.Timestamp]: {
    name: "Timestamp",
    type: "uint"
  },
  [matroskaElements.Tracks]: tracks,
  [matroskaElements.Block]: block,
  [matroskaElements.SimpleBlock]: simpleBlock,
  [matroskaElements.BlockGroup]: blockGroup,
  [matroskaElements.Segment]: {
    name: "Segment",
    type: "children"
  },
  [matroskaElements.Cluster]: {
    name: "Cluster",
    type: "children"
  },
  [matroskaElements.TransferCharacteristics]: transferCharacteristics,
  [matroskaElements.MatrixCoefficients]: matrixCoefficients,
  [matroskaElements.Primaries]: primaries,
  [matroskaElements.Range]: range,
  [matroskaElements.ChromaSitingHorz]: ChromaSitingHorz,
  [matroskaElements.ChromaSitingVert]: ChromaSitingVert
};

// src/file-types/detect-file-type.ts
var webmPattern = new Uint8Array([26, 69, 223, 163]);
var matchesPattern = (pattern) => {
  return (data) => {
    return pattern.every((value, index) => data[index] === value);
  };
};
var isRiffAvi = (data) => {
  const riffPattern = new Uint8Array([82, 73, 70, 70]);
  if (!matchesPattern(riffPattern)(data.subarray(0, 4))) {
    return false;
  }
  const fileType = data.subarray(8, 12);
  const aviPattern = new Uint8Array([65, 86, 73, 32]);
  return matchesPattern(aviPattern)(fileType);
};
var isRiffWave = (data) => {
  const riffPattern = new Uint8Array([82, 73, 70, 70]);
  if (!matchesPattern(riffPattern)(data.subarray(0, 4))) {
    return false;
  }
  const fileType = data.subarray(8, 12);
  const wavePattern = new Uint8Array([87, 65, 86, 69]);
  return matchesPattern(wavePattern)(fileType);
};
var isWebm = (data) => {
  return matchesPattern(webmPattern)(data.subarray(0, 4));
};
var isIsoBaseMedia = (data) => {
  const isoBaseMediaMp4Pattern = new TextEncoder().encode("ftyp");
  return matchesPattern(isoBaseMediaMp4Pattern)(data.subarray(4, 8));
};
var isTransportStream = (data) => {
  return data[0] === 71 && data[188] === 71;
};
var isMp3 = (data) => {
  const mpegPattern = new Uint8Array([255, 243, 228, 100]);
  const id3Pattern = new Uint8Array([73, 68, 51, 3]);
  const subarray = data.subarray(0, 4);
  return matchesPattern(mpegPattern)(subarray) || matchesPattern(id3Pattern)(subarray);
};
var isGif = (data) => {
  const gifPattern = new Uint8Array([71, 73, 70, 56]);
  return matchesPattern(gifPattern)(data.subarray(0, 4));
};
var isAac = (data) => {
  const aacPattern = new Uint8Array([255, 241]);
  return matchesPattern(aacPattern)(data.subarray(0, 2));
};

// src/file-types/bmp.ts
function getBmpDimensions(bmpData) {
  if (bmpData.length < 26) {
    return null;
  }
  const view = new DataView(bmpData.buffer, bmpData.byteOffset);
  return {
    width: view.getUint32(18, true),
    height: Math.abs(view.getInt32(22, true))
  };
}
var isBmp = (data) => {
  const bmpPattern = new Uint8Array([66, 77]);
  if (matchesPattern(bmpPattern)(data.subarray(0, 2))) {
    const bmp = getBmpDimensions(data);
    return { dimensions: bmp, type: "bmp" };
  }
  return null;
};

// src/file-types/jpeg.ts
function getJpegDimensions(data) {
  let offset = 0;
  function readUint16BE(o) {
    return data[o] << 8 | data[o + 1];
  }
  if (readUint16BE(offset) !== 65496) {
    return null;
  }
  offset += 2;
  while (offset < data.length) {
    if (data[offset] === 255) {
      const marker = data[offset + 1];
      if (marker === 192 || marker === 194) {
        const height = readUint16BE(offset + 5);
        const width = readUint16BE(offset + 7);
        return { width, height };
      }
      const length = readUint16BE(offset + 2);
      offset += length + 2;
    } else {
      offset++;
    }
  }
  return null;
}
var isJpeg = (data) => {
  const jpegPattern = new Uint8Array([255, 216]);
  const jpeg = matchesPattern(jpegPattern)(data.subarray(0, 2));
  if (!jpeg) {
    return null;
  }
  const dim = getJpegDimensions(data);
  return { dimensions: dim, type: "jpeg" };
};

// src/file-types/pdf.ts
var isPdf = (data) => {
  if (data.length < 4) {
    return null;
  }
  const pdfPattern = new Uint8Array([37, 80, 68, 70]);
  return matchesPattern(pdfPattern)(data.subarray(0, 4)) ? { type: "pdf" } : null;
};

// src/file-types/png.ts
function getPngDimensions(pngData) {
  if (pngData.length < 24) {
    return null;
  }
  const view = new DataView(pngData.buffer, pngData.byteOffset);
  const pngSignature = [137, 80, 78, 71, 13, 10, 26, 10];
  for (let i = 0;i < 8; i++) {
    if (pngData[i] !== pngSignature[i]) {
      return null;
    }
  }
  return {
    width: view.getUint32(16, false),
    height: view.getUint32(20, false)
  };
}
var isPng = (data) => {
  const pngPattern = new Uint8Array([137, 80, 78, 71]);
  if (matchesPattern(pngPattern)(data.subarray(0, 4))) {
    const png = getPngDimensions(data);
    return { dimensions: png, type: "png" };
  }
  return null;
};

// src/file-types/webp.ts
function getWebPDimensions(bytes) {
  if (bytes.length < 30) {
    return null;
  }
  if (bytes[0] !== 82 || bytes[1] !== 73 || bytes[2] !== 70 || bytes[3] !== 70 || bytes[8] !== 87 || bytes[9] !== 69 || bytes[10] !== 66 || bytes[11] !== 80) {
    return null;
  }
  if (bytes[12] === 86 && bytes[13] === 80 && bytes[14] === 56) {
    if (bytes[15] === 32) {
      return {
        width: bytes[26] | bytes[27] << 8 & 16383,
        height: bytes[28] | bytes[29] << 8 & 16383
      };
    }
  }
  if (bytes[12] === 86 && bytes[13] === 80 && bytes[14] === 56 && bytes[15] === 76) {
    return {
      width: 1 + (bytes[21] | (bytes[22] & 63) << 8),
      height: 1 + ((bytes[22] & 192) >> 6 | bytes[23] << 2 | (bytes[24] & 15) << 10)
    };
  }
  if (bytes[12] === 86 && bytes[13] === 80 && bytes[14] === 56 && bytes[15] === 88) {
    return {
      width: 1 + (bytes[24] | bytes[25] << 8 | bytes[26] << 16),
      height: 1 + (bytes[27] | bytes[28] << 8 | bytes[29] << 16)
    };
  }
  return null;
}
var isWebp = (data) => {
  const webpPattern = new Uint8Array([82, 73, 70, 70]);
  if (matchesPattern(webpPattern)(data.subarray(0, 4))) {
    return {
      type: "webp",
      dimensions: getWebPDimensions(data)
    };
  }
  return null;
};

// src/file-types/index.ts
var detectFileType = (data) => {
  if (isRiffWave(data)) {
    return { type: "wav" };
  }
  if (isRiffAvi(data)) {
    return { type: "riff" };
  }
  if (isAac(data)) {
    return { type: "aac" };
  }
  const webp = isWebp(data);
  if (webp) {
    return webp;
  }
  if (isWebm(data)) {
    return { type: "webm" };
  }
  if (isIsoBaseMedia(data)) {
    return { type: "iso-base-media" };
  }
  if (isTransportStream(data)) {
    return { type: "transport-stream" };
  }
  if (isMp3(data)) {
    return { type: "mp3" };
  }
  if (isGif(data)) {
    return { type: "gif" };
  }
  const png = isPng(data);
  if (png) {
    return png;
  }
  const pdf = isPdf(data);
  if (pdf) {
    return pdf;
  }
  const bmp = isBmp(data);
  if (bmp) {
    return bmp;
  }
  const jpeg = isJpeg(data);
  if (jpeg) {
    return jpeg;
  }
  return { type: "unknown" };
};

// src/buffer-iterator.ts
class OffsetCounter {
  #offset;
  #discardedBytes;
  constructor(initial) {
    this.#offset = initial;
    this.#discardedBytes = 0;
  }
  increment(amount) {
    if (amount < 0) {
      throw new Error("Cannot increment by a negative amount: " + amount);
    }
    this.#offset += amount;
  }
  getOffset() {
    return this.#offset;
  }
  getDiscardedOffset() {
    return this.#offset - this.#discardedBytes;
  }
  setDiscardedOffset(offset) {
    this.#discardedBytes = offset;
  }
  getDiscardedBytes() {
    return this.#discardedBytes;
  }
  discardBytes(amount) {
    this.#discardedBytes += amount;
  }
  decrement(amount) {
    if (amount < 0) {
      throw new Error("Cannot decrement by a negative amount");
    }
    this.#offset -= amount;
  }
}
var makeOffsetCounter = () => {
  return new OffsetCounter(0);
};
var getArrayBufferIterator = (initialData, maxBytes) => {
  const buf = new ArrayBuffer(initialData.byteLength, {
    maxByteLength: maxBytes === null ? initialData.byteLength : Math.min(maxBytes, 2 ** 32)
  });
  if (!buf.resize) {
    throw new Error("`ArrayBuffer.resize` is not supported in this Runtime. On the server: Use at least Node.js 20 or Bun. In the browser: Chrome 111, Edge 111, Safari 16.4, Firefox 128, Opera 111");
  }
  let data = new Uint8Array(buf);
  data.set(initialData);
  let view = new DataView(data.buffer);
  const counter = makeOffsetCounter();
  let discardAllowed = true;
  const getSlice = (amount) => {
    const value = data.slice(counter.getDiscardedOffset(), counter.getDiscardedOffset() + amount);
    counter.increment(amount);
    return value;
  };
  const disallowDiscard = () => {
    discardAllowed = false;
  };
  const allowDiscard = () => {
    discardAllowed = true;
  };
  const discard = (length) => {
    counter.increment(length);
  };
  const readUntilNullTerminator = () => {
    const bytes = [];
    let byte;
    while ((byte = getUint8()) !== 0) {
      bytes.push(byte);
    }
    counter.decrement(1);
    return new TextDecoder().decode(new Uint8Array(bytes));
  };
  const getUint8 = () => {
    const val = view.getUint8(counter.getDiscardedOffset());
    counter.increment(1);
    return val;
  };
  const getEightByteNumber = (littleEndian = false) => {
    if (littleEndian) {
      const one = getUint8();
      const two = getUint8();
      const three = getUint8();
      const four = getUint8();
      const five = getUint8();
      const six = getUint8();
      const seven = getUint8();
      const eight = getUint8();
      return eight << 56 | seven << 48 | six << 40 | five << 32 | four << 24 | three << 16 | two << 8 | one;
    }
    function byteArrayToBigInt(byteArray) {
      let result = BigInt(0);
      for (let i = 0;i < byteArray.length; i++) {
        result = (result << BigInt(8)) + BigInt(byteArray[i]);
      }
      return result;
    }
    const bigInt = byteArrayToBigInt([
      getUint8(),
      getUint8(),
      getUint8(),
      getUint8(),
      getUint8(),
      getUint8(),
      getUint8(),
      getUint8()
    ]);
    return Number(bigInt);
  };
  const getFourByteNumber = () => {
    return getUint8() << 24 | getUint8() << 16 | getUint8() << 8 | getUint8();
  };
  const getPaddedFourByteNumber = () => {
    let lastInt = 128;
    while (lastInt = getUint8(), lastInt === 128) {
    }
    return lastInt;
  };
  const getUint32 = () => {
    const val = view.getUint32(counter.getDiscardedOffset());
    counter.increment(4);
    return val;
  };
  const getUint64 = (littleEndian = false) => {
    const val = view.getBigUint64(counter.getDiscardedOffset(), littleEndian);
    counter.increment(8);
    return val;
  };
  const getInt64 = (littleEndian = false) => {
    const val = view.getBigInt64(counter.getDiscardedOffset(), littleEndian);
    counter.increment(8);
    return val;
  };
  const startBox = (size) => {
    const startOffset = counter.getOffset();
    return {
      discardRest: () => discard(size - (counter.getOffset() - startOffset)),
      expectNoMoreBytes: () => {
        const remaining = size - (counter.getOffset() - startOffset);
        if (remaining !== 0) {
          throw new Error("expected 0 bytes, got " + remaining);
        }
      }
    };
  };
  const getUint32Le = () => {
    const val = view.getUint32(counter.getDiscardedOffset(), true);
    counter.increment(4);
    return val;
  };
  const getInt32Le = () => {
    const val = view.getInt32(counter.getDiscardedOffset(), true);
    counter.increment(4);
    return val;
  };
  const getInt32 = () => {
    const val = view.getInt32(counter.getDiscardedOffset());
    counter.increment(4);
    return val;
  };
  const addData = (newData) => {
    const oldLength = buf.byteLength;
    const newLength = oldLength + newData.byteLength;
    buf.resize(newLength);
    const newArray = new Uint8Array(buf);
    newArray.set(newData, oldLength);
    data = newArray;
    view = new DataView(data.buffer);
  };
  const byteLength = () => {
    return data.byteLength;
  };
  const bytesRemaining = () => {
    return data.byteLength - counter.getDiscardedOffset();
  };
  const removeBytesRead = () => {
    if (!discardAllowed) {
      return;
    }
    const bytesToRemove = counter.getDiscardedOffset();
    if (bytesToRemove < 1e5) {
      return;
    }
    counter.discardBytes(bytesToRemove);
    const newData = data.slice(bytesToRemove);
    data.set(newData);
    buf.resize(newData.byteLength);
    view = new DataView(data.buffer);
  };
  const skipTo = (offset, reset) => {
    const becomesSmaller = offset < counter.getOffset();
    if (becomesSmaller) {
      if (reset) {
        buf.resize(0);
        counter.decrement(counter.getOffset() - offset);
        counter.setDiscardedOffset(offset);
      } else {
        const toDecrement = counter.getOffset() - offset;
        const newOffset = counter.getOffset() - toDecrement;
        counter.decrement(toDecrement);
        const c = counter.getDiscardedBytes();
        if (c > newOffset) {
          throw new Error("already discarded too many bytes");
        }
      }
    } else {
      const currentOffset = counter.getOffset();
      counter.increment(offset - currentOffset);
      removeBytesRead();
    }
  };
  const readExpGolomb = () => {
    if (!bitReadingMode) {
      throw new Error("Not in bit reading mode");
    }
    let zerosCount = 0;
    while (getBits(1) === 0) {
      zerosCount++;
    }
    let suffix = 0;
    for (let i = 0;i < zerosCount; i++) {
      suffix = suffix << 1 | getBits(1);
    }
    return (1 << zerosCount) - 1 + suffix;
  };
  const peekB = (length) => {
    console.log([...getSlice(length)].map((b) => b.toString(16).padStart(2, "0")));
    counter.decrement(length);
  };
  const peekD = (length) => {
    console.log([...getSlice(length)].map((b) => b));
    counter.decrement(length);
  };
  const leb128 = () => {
    let result = 0;
    let shift = 0;
    let byte;
    do {
      byte = getBits(8);
      result |= (byte & 127) << shift;
      shift += 7;
    } while (byte >= 128);
    return result;
  };
  let bitIndex = 0;
  const stopReadingBits = () => {
    bitIndex = 0;
    bitReadingMode = false;
  };
  let byteToShift = 0;
  let bitReadingMode = false;
  const startReadingBits = () => {
    bitReadingMode = true;
    byteToShift = getUint8();
  };
  const getBits = (bits) => {
    let result = 0;
    let bitsCollected = 0;
    while (bitsCollected < bits) {
      if (bitIndex >= 8) {
        bitIndex = 0;
        byteToShift = getUint8();
      }
      const remainingBitsInByte = 8 - bitIndex;
      const bitsToReadNow = Math.min(bits - bitsCollected, remainingBitsInByte);
      const mask = (1 << bitsToReadNow) - 1;
      const shift = remainingBitsInByte - bitsToReadNow;
      result <<= bitsToReadNow;
      result |= byteToShift >> shift & mask;
      bitsCollected += bitsToReadNow;
      bitIndex += bitsToReadNow;
    }
    return result;
  };
  const destroy = () => {
    data = new Uint8Array(0);
    buf.resize(0);
  };
  return {
    startReadingBits,
    stopReadingBits,
    skipTo,
    addData,
    counter,
    peekB,
    peekD,
    getBits,
    byteLength,
    bytesRemaining,
    leb128,
    removeBytesRead,
    discard,
    getEightByteNumber,
    getFourByteNumber,
    getSlice,
    getAtom: () => {
      const atom = getSlice(4);
      return new TextDecoder().decode(atom);
    },
    detectFileType: () => {
      return detectFileType(data);
    },
    getPaddedFourByteNumber,
    getMatroskaSegmentId: () => {
      if (bytesRemaining() === 0) {
        return null;
      }
      const first = getSlice(1);
      const firstOneString = `0x${Array.from(new Uint8Array(first)).map((b) => {
        return b.toString(16).padStart(2, "0");
      }).join("")}`;
      if (knownIdsWithOneLength.includes(firstOneString)) {
        return firstOneString;
      }
      if (bytesRemaining() === 0) {
        return null;
      }
      const firstTwo = getSlice(1);
      const firstTwoString = `${firstOneString}${Array.from(new Uint8Array(firstTwo)).map((b) => {
        return b.toString(16).padStart(2, "0");
      }).join("")}`;
      if (knownIdsWithTwoLength.includes(firstTwoString)) {
        return firstTwoString;
      }
      if (bytesRemaining() === 0) {
        return null;
      }
      const firstThree = getSlice(1);
      const firstThreeString = `${firstTwoString}${Array.from(new Uint8Array(firstThree)).map((b) => {
        return b.toString(16).padStart(2, "0");
      }).join("")}`;
      if (knownIdsWithThreeLength.includes(firstThreeString)) {
        return firstThreeString;
      }
      if (bytesRemaining() === 0) {
        return null;
      }
      const segmentId = getSlice(1);
      return `${firstThreeString}${Array.from(new Uint8Array(segmentId)).map((b) => {
        return b.toString(16).padStart(2, "0");
      }).join("")}`;
    },
    getVint: () => {
      if (bytesRemaining() === 0) {
        return null;
      }
      const firstByte = getUint8();
      const totalLength = firstByte;
      if (totalLength === 0) {
        return 0;
      }
      let actualLength = 0;
      while ((totalLength >> 7 - actualLength & 1) === 0) {
        actualLength++;
      }
      if (bytesRemaining() < actualLength) {
        return null;
      }
      const slice = getSlice(actualLength);
      const d = [firstByte, ...Array.from(new Uint8Array(slice))];
      actualLength += 1;
      let value = 0;
      value = totalLength & 255 >> actualLength;
      for (let i = 1;i < actualLength; i++) {
        value = value << 8 | d[i];
      }
      if (value === -1) {
        return Infinity;
      }
      return value;
    },
    getUint8,
    getEBML: () => {
      const val = getUint8();
      const actualValue = val & 127;
      return actualValue;
    },
    getInt8: () => {
      const val = view.getInt8(counter.getDiscardedOffset());
      counter.increment(1);
      return val;
    },
    getUint16: () => {
      const val = view.getUint16(counter.getDiscardedOffset());
      counter.increment(2);
      return val;
    },
    getUint16Le: () => {
      const val = view.getUint16(counter.getDiscardedOffset(), true);
      counter.increment(2);
      return val;
    },
    getUint24: () => {
      const val1 = view.getUint8(counter.getDiscardedOffset());
      const val2 = view.getUint8(counter.getDiscardedOffset() + 1);
      const val3 = view.getUint8(counter.getDiscardedOffset() + 2);
      counter.increment(3);
      return val1 << 16 | val2 << 8 | val3;
    },
    getInt24: () => {
      const val1 = view.getInt8(counter.getDiscardedOffset());
      const val2 = view.getUint8(counter.getDiscardedOffset() + 1);
      const val3 = view.getUint8(counter.getDiscardedOffset() + 2);
      counter.increment(3);
      return val1 << 16 | val2 << 8 | val3;
    },
    getInt16: () => {
      const val = view.getInt16(counter.getDiscardedOffset());
      counter.increment(2);
      return val;
    },
    getUint32,
    getUint64,
    getInt64,
    getFixedPointUnsigned1616Number: () => {
      const val = getUint32();
      return val / 2 ** 16;
    },
    getFixedPointSigned1616Number: () => {
      const val = getInt32();
      return val / 2 ** 16;
    },
    getFixedPointSigned230Number: () => {
      const val = getInt32();
      return val / 2 ** 30;
    },
    getPascalString: () => {
      const val = getSlice(32);
      return [...Array.from(new Uint8Array(val))];
    },
    getUint(length) {
      const bytes = getSlice(length);
      const numbers = [...Array.from(new Uint8Array(bytes))];
      return numbers.reduce((acc, byte, index) => acc + (byte << 8 * (numbers.length - index - 1)), 0);
    },
    getByteString(length, trimTrailingZeroes) {
      let bytes = getSlice(length);
      while (trimTrailingZeroes && bytes[bytes.length - 1] === 0) {
        bytes = bytes.slice(0, -1);
      }
      return new TextDecoder().decode(bytes).trim();
    },
    getFloat64: () => {
      const val = view.getFloat64(counter.getDiscardedOffset());
      counter.increment(8);
      return val;
    },
    readUntilNullTerminator,
    getFloat32: () => {
      const val = view.getFloat32(counter.getDiscardedOffset());
      counter.increment(4);
      return val;
    },
    getUint32Le,
    getInt32Le,
    getInt32,
    destroy,
    disallowDiscard,
    allowDiscard,
    startBox,
    readExpGolomb
  };
};

// src/boxes/iso-base-media/to-date.ts
var toUnixTimestamp = (value) => {
  if (value === 0) {
    return null;
  }
  const baseDate = new Date("1904-01-01T00:00:00Z");
  return Math.floor(value + baseDate.getTime() / 1000) * 1000;
};

// src/boxes/iso-base-media/mvhd.ts
var parseMvhd = ({
  iterator,
  offset,
  size
}) => {
  const version = iterator.getUint8();
  iterator.discard(3);
  const creationTime = version === 1 ? iterator.getUint64() : iterator.getUint32();
  const modificationTime = version === 1 ? iterator.getUint64() : iterator.getUint32();
  const timeScale = iterator.getUint32();
  const durationInUnits = version === 1 ? iterator.getUint64() : iterator.getUint32();
  const durationInSeconds = Number(durationInUnits) / timeScale;
  const rateArray = iterator.getSlice(4);
  const rateView = getArrayBufferIterator(rateArray, rateArray.length);
  const rate = rateView.getInt8() * 10 + rateView.getInt8() + rateView.getInt8() * 0.1 + rateView.getInt8() * 0.01;
  const volumeArray = iterator.getSlice(2);
  const volumeView = getArrayBufferIterator(volumeArray, volumeArray.length);
  const volume = volumeView.getInt8() + volumeView.getInt8() * 0.1;
  iterator.discard(2);
  iterator.discard(4);
  iterator.discard(4);
  const matrix = [
    iterator.getFixedPointSigned1616Number(),
    iterator.getFixedPointSigned1616Number(),
    iterator.getFixedPointSigned230Number(),
    iterator.getFixedPointSigned1616Number(),
    iterator.getFixedPointSigned1616Number(),
    iterator.getFixedPointSigned230Number(),
    iterator.getFixedPointSigned1616Number(),
    iterator.getFixedPointSigned1616Number(),
    iterator.getFixedPointSigned230Number()
  ];
  iterator.discard(4 * 6);
  const nextTrackId = iterator.getUint32();
  volumeView.destroy();
  const bytesRemaining = size - (iterator.counter.getOffset() - offset);
  if (bytesRemaining !== 0) {
    throw new Error("expected 0 bytes " + bytesRemaining);
  }
  return {
    creationTime: toUnixTimestamp(Number(creationTime)),
    modificationTime: toUnixTimestamp(Number(modificationTime)),
    timeScale,
    durationInUnits: Number(durationInUnits),
    durationInSeconds,
    rate,
    volume,
    matrix,
    nextTrackId,
    type: "mvhd-box",
    boxSize: size,
    offset
  };
};

// src/boxes/iso-base-media/traversal.ts
var getMoovBox = (segments) => {
  const moovBox = segments.find((s) => s.type === "moov-box");
  if (!moovBox || moovBox.type !== "moov-box") {
    return null;
  }
  return moovBox;
};
var getMoofBox = (main) => {
  const moofBox = main.find((s) => s.type === "regular-box" && s.boxType === "moof");
  if (!moofBox || moofBox.type !== "regular-box") {
    return null;
  }
  return moofBox;
};
var getMvhdBox = (moovBox) => {
  const mvHdBox = moovBox.children.find((s) => s.type === "mvhd-box");
  if (!mvHdBox || mvHdBox.type !== "mvhd-box") {
    return null;
  }
  return mvHdBox;
};
var getTraks = (moovBox) => {
  return moovBox.children.filter((s) => s.type === "trak-box");
};
var getTkhdBox = (trakBox) => {
  const tkhdBox = trakBox.children.find((s) => s.type === "tkhd-box");
  return tkhdBox;
};
var getMdiaBox = (trakBox) => {
  const mdiaBox = trakBox.children.find((s) => s.type === "regular-box" && s.boxType === "mdia");
  if (!mdiaBox || mdiaBox.type !== "regular-box") {
    return null;
  }
  return mdiaBox;
};
var getMdhdBox = (trakBox) => {
  const mdiaBox = getMdiaBox(trakBox);
  if (!mdiaBox) {
    return null;
  }
  const mdhdBox = mdiaBox.children.find((c) => c.type === "mdhd-box");
  return mdhdBox;
};
var getStblBox = (trakBox) => {
  const mdiaBox = getMdiaBox(trakBox);
  if (!mdiaBox) {
    return null;
  }
  const minfBox = mdiaBox.children.find((s) => s.type === "regular-box" && s.boxType === "minf");
  if (!minfBox || minfBox.type !== "regular-box") {
    return null;
  }
  const stblBox = minfBox.children.find((s) => s.type === "regular-box" && s.boxType === "stbl");
  if (!stblBox || stblBox.type !== "regular-box") {
    return null;
  }
  return stblBox;
};
var getStsdBox = (trakBox) => {
  const stblBox = getStblBox(trakBox);
  if (!stblBox || stblBox.type !== "regular-box") {
    return null;
  }
  const stsdBox = stblBox.children.find((s) => s.type === "stsd-box");
  return stsdBox;
};
var getVideoDescriptors = (trakBox) => {
  const stsdBox = getStsdBox(trakBox);
  if (!stsdBox) {
    return null;
  }
  const descriptors = stsdBox.samples.map((s) => {
    return s.type === "video" ? s.descriptors.map((d) => {
      return d.type === "avcc-box" ? d.privateData : d.type === "hvcc-box" ? d.privateData : null;
    }) : [];
  });
  return descriptors.flat(1).filter(Boolean)[0] ?? null;
};
var getStcoBox = (trakBox) => {
  const stblBox = getStblBox(trakBox);
  if (!stblBox || stblBox.type !== "regular-box") {
    return null;
  }
  const stcoBox = stblBox.children.find((s) => s.type === "stco-box");
  return stcoBox;
};
var getSttsBox = (trakBox) => {
  const stblBox = getStblBox(trakBox);
  if (!stblBox || stblBox.type !== "regular-box") {
    return null;
  }
  const sttsBox = stblBox.children.find((s) => s.type === "stts-box");
  return sttsBox;
};
var getCttsBox = (trakBox) => {
  const stblBox = getStblBox(trakBox);
  if (!stblBox || stblBox.type !== "regular-box") {
    return null;
  }
  const cttsBox = stblBox.children.find((s) => s.type === "ctts-box");
  return cttsBox;
};
var getStszBox = (trakBox) => {
  const stblBox = getStblBox(trakBox);
  if (!stblBox || stblBox.type !== "regular-box") {
    return null;
  }
  const stszBox = stblBox.children.find((s) => s.type === "stsz-box");
  return stszBox;
};
var getStscBox = (trakBox) => {
  const stblBox = getStblBox(trakBox);
  if (!stblBox || stblBox.type !== "regular-box") {
    return null;
  }
  const stcoBox = stblBox.children.find((b) => b.type === "stsc-box");
  return stcoBox;
};
var getStssBox = (trakBox) => {
  const stblBox = getStblBox(trakBox);
  if (!stblBox || stblBox.type !== "regular-box") {
    return null;
  }
  const stssBox = stblBox.children.find((b) => b.type === "stss-box");
  return stssBox;
};
var getTfdtBox = (segment) => {
  if (segment.type !== "regular-box" || segment.boxType !== "traf") {
    throw new Error("Expected traf-box");
  }
  const tfhdBox = segment.children.find((c) => c.type === "tfdt-box");
  if (!tfhdBox || tfhdBox.type !== "tfdt-box") {
    throw new Error("Expected tfhd-box");
  }
  return tfhdBox;
};
var getTfhdBox = (segment) => {
  if (segment.type !== "regular-box" || segment.boxType !== "traf") {
    throw new Error("Expected traf-box");
  }
  const tfhdBox = segment.children.find((c) => c.type === "tfhd-box");
  if (!tfhdBox || tfhdBox.type !== "tfhd-box") {
    throw new Error("Expected tfhd-box");
  }
  return tfhdBox;
};
var getTrunBoxes = (segment) => {
  if (segment.type !== "regular-box" || segment.boxType !== "traf") {
    throw new Error("Expected traf-box");
  }
  const trunBoxes = segment.children.filter((c) => c.type === "trun-box");
  return trunBoxes;
};
var getMdatBox = (anySegment) => {
  const mdat = anySegment.find((b) => b.type === "mdat-box");
  if (!mdat) {
    return null;
  }
  if (mdat.type !== "mdat-box") {
    throw new Error("Expected mdat-box");
  }
  return mdat;
};

// src/boxes/riff/traversal.ts
var isRiffAvi2 = (structure) => {
  return structure.boxes.some((box) => box.type === "riff-header" && box.fileType === "AVI");
};
var getHdlrBox = (structure) => {
  return structure.boxes.find((box) => box.type === "list-box" && box.listType === "hdrl");
};
var getAvihBox = (structure) => {
  const hdlrBox = getHdlrBox(structure);
  if (!hdlrBox) {
    return null;
  }
  return hdlrBox.children.find((box) => box.type === "avih-box");
};
var getStrlBoxes = (structure) => {
  const hdlrBox = getHdlrBox(structure);
  if (!hdlrBox) {
    return [];
  }
  return hdlrBox.children.filter((box) => box.type === "list-box" && box.listType === "strl");
};
var getStrhBox = (strlBoxChildren) => {
  return strlBoxChildren.find((box) => box.type === "strh-box");
};
var getStrfBox = (strlBoxChildren) => {
  return strlBoxChildren.find((box) => box.type === "strf-box-audio" || box.type === "strf-box-video") ?? null;
};

// src/get-fps.ts
var calculateFps = ({
  sttsBox,
  timeScale,
  durationInSamples
}) => {
  let totalSamples = 0;
  for (const sample of sttsBox.sampleDistribution) {
    totalSamples += sample.sampleCount;
  }
  const durationInSeconds = durationInSamples / timeScale;
  const fps = totalSamples / durationInSeconds;
  return fps;
};
var trakBoxContainsAudio = (trakBox) => {
  const stsd = getStsdBox(trakBox);
  if (!stsd) {
    return false;
  }
  const videoSample = stsd.samples.find((s) => s.type === "audio");
  if (!videoSample || videoSample.type !== "audio") {
    return false;
  }
  return true;
};
var trakBoxContainsVideo = (trakBox) => {
  const stsd = getStsdBox(trakBox);
  if (!stsd) {
    return false;
  }
  const videoSample = stsd.samples.find((s) => s.type === "video");
  if (!videoSample || videoSample.type !== "video") {
    return false;
  }
  return true;
};
var getTimescaleAndDuration = (trakBox) => {
  const mdhdBox = getMdhdBox(trakBox);
  if (mdhdBox) {
    return { timescale: mdhdBox.timescale, duration: mdhdBox.duration };
  }
  return null;
};
var getFpsFromMp4TrakBox = (trakBox) => {
  const timescaleAndDuration = getTimescaleAndDuration(trakBox);
  if (!timescaleAndDuration) {
    return null;
  }
  const sttsBox = getSttsBox(trakBox);
  if (!sttsBox) {
    return null;
  }
  return calculateFps({
    sttsBox,
    timeScale: timescaleAndDuration.timescale,
    durationInSamples: timescaleAndDuration.duration
  });
};
var getFpsFromIsoMaseMedia = (structure) => {
  const moovBox = getMoovBox(structure.boxes);
  if (!moovBox) {
    return null;
  }
  const trackBoxes = getTraks(moovBox);
  const trackBox = trackBoxes.find(trakBoxContainsVideo);
  if (!trackBox) {
    return null;
  }
  return getFpsFromMp4TrakBox(trackBox);
};
var getFpsFromAvi = (structure) => {
  const strl = getStrlBoxes(structure);
  for (const s of strl) {
    const strh = getStrhBox(s.children);
    if (!strh) {
      throw new Error("No strh box");
    }
    if (strh.fccType === "auds") {
      continue;
    }
    return strh.rate;
  }
  return null;
};
var getFps = (segments) => {
  if (segments.type === "iso-base-media") {
    return getFpsFromIsoMaseMedia(segments);
  }
  if (segments.type === "riff") {
    return getFpsFromAvi(segments);
  }
  if (segments.type === "matroska") {
    return null;
  }
  if (segments.type === "transport-stream") {
    return null;
  }
  throw new Error("Cannot get fps, not implemented");
};
var hasFpsSuitedForSlowFps = (boxes) => {
  try {
    return getFps(boxes) !== null;
  } catch {
    return false;
  }
};
var hasFps = (boxes) => {
  if (boxes.type === "matroska") {
    return true;
  }
  if (boxes.type === "transport-stream") {
    return true;
  }
  return hasFpsSuitedForSlowFps(boxes);
};

// src/get-audio-codec.ts
var getAudioCodec = (boxes, parserState) => {
  const tracks2 = getTracks(boxes, parserState);
  const allTracks = tracks2.audioTracks.length + tracks2.otherTracks.length + tracks2.videoTracks.length;
  if (allTracks === 0) {
    throw new Error("No tracks yet");
  }
  const audioTrack = tracks2.audioTracks[0];
  if (!audioTrack) {
    return null;
  }
  if (audioTrack.type === "audio") {
    return audioTrack.codecWithoutConfig;
  }
  return null;
};
var hasAudioCodec = (boxes, state) => {
  return hasTracks(boxes, state);
};
var getCodecSpecificatorFromEsdsBox = ({
  child
}) => {
  const descriptor = child.descriptors.find((d) => d.type === "decoder-config-descriptor");
  if (!descriptor) {
    throw new Error("No decoder-config-descriptor");
  }
  if (descriptor.type !== "decoder-config-descriptor") {
    throw new Error("Expected decoder-config-descriptor");
  }
  if (descriptor.asNumber !== 64) {
    return {
      primary: descriptor.asNumber,
      secondary: null,
      description: undefined
    };
  }
  const audioSpecificConfig = descriptor.decoderSpecificConfigs.find((d) => {
    return d.type === "mp4a-specific-config" ? d : null;
  });
  if (!audioSpecificConfig || audioSpecificConfig.type !== "mp4a-specific-config") {
    throw new Error("No audio-specific-config");
  }
  return {
    primary: descriptor.asNumber,
    secondary: audioSpecificConfig.audioObjectType,
    description: audioSpecificConfig.asBytes
  };
};
var getCodecPrivateFromTrak = (trakBox) => {
  const stsdBox = getStsdBox(trakBox);
  if (!stsdBox) {
    return null;
  }
  const audioSample = stsdBox.samples.find((s) => s.type === "audio");
  if (!audioSample || audioSample.type !== "audio") {
    return null;
  }
  const esds = audioSample.children.find((b) => b.type === "esds-box");
  if (!esds || esds.type !== "esds-box") {
    return null;
  }
  const decoderConfigDescriptor = esds.descriptors.find((d) => d.type === "decoder-config-descriptor");
  if (!decoderConfigDescriptor) {
    return null;
  }
  const mp4a = decoderConfigDescriptor.decoderSpecificConfigs.find((d) => d.type === "mp4a-specific-config");
  if (!mp4a) {
    return null;
  }
  return mp4a.asBytes;
};
var onSample = (sample, children) => {
  const child = children.find((c) => c.type === "esds-box");
  if (child && child.type === "esds-box") {
    const ret = getCodecSpecificatorFromEsdsBox({ child });
    return {
      format: sample.format,
      primarySpecificator: ret.primary,
      secondarySpecificator: ret.secondary,
      description: ret.description
    };
  }
  return {
    format: sample.format,
    primarySpecificator: null,
    secondarySpecificator: null,
    description: undefined
  };
};
var getNumberOfChannelsFromTrak = (trak) => {
  const stsdBox = getStsdBox(trak);
  if (!stsdBox) {
    return null;
  }
  const sample = stsdBox.samples.find((s) => s.type === "audio");
  if (!sample || sample.type !== "audio") {
    return null;
  }
  return sample.numberOfChannels;
};
var getSampleRate = (trak) => {
  const stsdBox = getStsdBox(trak);
  if (!stsdBox) {
    return null;
  }
  const sample = stsdBox.samples.find((s) => s.type === "audio");
  if (!sample || sample.type !== "audio") {
    return null;
  }
  return sample.sampleRate;
};
var getAudioCodecFromTrak = (trak) => {
  const stsdBox = getStsdBox(trak);
  if (!stsdBox) {
    return null;
  }
  const sample = stsdBox.samples.find((s) => s.type === "audio");
  if (!sample || sample.type !== "audio") {
    return null;
  }
  const waveBox = sample.children.find((b) => b.type === "regular-box" && b.boxType === "wave");
  if (waveBox && waveBox.type === "regular-box" && waveBox.boxType === "wave") {
    const esdsSample = onSample(sample, waveBox.children);
    if (esdsSample) {
      return esdsSample;
    }
  }
  const ret = onSample(sample, sample.children);
  if (ret) {
    return ret;
  }
  return null;
};
var isLpcmAudioCodec = (trak) => {
  return getAudioCodecFromTrak(trak)?.format === "lpcm";
};
var getAudioCodecStringFromTrak = (trak) => {
  const codec = getAudioCodecFromTrak(trak);
  if (!codec) {
    throw new Error("Expected codec");
  }
  if (codec.format === "lpcm") {
    return {
      codecString: "pcm-s16",
      description: codec.description
    };
  }
  const codecStringWithoutMp3Exception = [
    codec.format,
    codec.primarySpecificator ? codec.primarySpecificator.toString(16) : null,
    codec.secondarySpecificator ? codec.secondarySpecificator.toString().padStart(2, "0") : null
  ].filter(Boolean).join(".");
  const codecString = codecStringWithoutMp3Exception === "mp4a.6b" ? "mp3" : codecStringWithoutMp3Exception;
  return {
    codecString,
    description: codec.description
  };
};
var getAudioCodecFromAudioCodecInfo = (codec) => {
  if (codec.format === "twos") {
    return "pcm-s16";
  }
  if (codec.format === "lpcm") {
    return "pcm-s16";
  }
  if (codec.format === "sowt") {
    return "aiff";
  }
  if (codec.format === "mp4a") {
    if (codec.primarySpecificator === 64) {
      return "aac";
    }
    if (codec.primarySpecificator === 107) {
      return "mp3";
    }
    if (codec.primarySpecificator === null) {
      return "aac";
    }
    throw new Error("Unknown mp4a codec: " + codec.primarySpecificator);
  }
  throw new Error(`Unknown audio format: ${codec.format}`);
};
var getAudioCodecFromTrack = (track) => {
  const audioSample = getAudioCodecFromTrak(track);
  if (!audioSample) {
    throw new Error("Could not find audio sample");
  }
  return getAudioCodecFromAudioCodecInfo(audioSample);
};

// src/get-sample-aspect-ratio.ts
var getStsdVideoConfig = (trakBox) => {
  const stsdBox = getStsdBox(trakBox);
  if (!stsdBox) {
    return null;
  }
  const videoConfig = stsdBox.samples.find((s) => s.type === "video");
  if (!videoConfig || videoConfig.type !== "video") {
    return null;
  }
  return videoConfig;
};
var getAvccBox = (trakBox) => {
  const videoConfig = getStsdVideoConfig(trakBox);
  if (!videoConfig) {
    return null;
  }
  const avccBox = videoConfig.descriptors.find((c) => c.type === "avcc-box");
  if (!avccBox || avccBox.type !== "avcc-box") {
    return null;
  }
  return avccBox;
};
var getAv1CBox = (trakBox) => {
  const videoConfig = getStsdVideoConfig(trakBox);
  if (!videoConfig) {
    return null;
  }
  const av1cBox = videoConfig.descriptors.find((c) => c.type === "av1C-box");
  if (!av1cBox || av1cBox.type !== "av1C-box") {
    return null;
  }
  return av1cBox;
};
var getPaspBox = (trakBox) => {
  const videoConfig = getStsdVideoConfig(trakBox);
  if (!videoConfig) {
    return null;
  }
  const paspBox = videoConfig.descriptors.find((c) => c.type === "pasp-box");
  if (!paspBox || paspBox.type !== "pasp-box") {
    return null;
  }
  return paspBox;
};
var getHvccBox = (trakBox) => {
  const videoConfig = getStsdVideoConfig(trakBox);
  if (!videoConfig) {
    return null;
  }
  const hvccBox = videoConfig.descriptors.find((c) => c.type === "hvcc-box");
  if (!hvccBox || hvccBox.type !== "hvcc-box") {
    return null;
  }
  return hvccBox;
};
var getSampleAspectRatio = (trakBox) => {
  const paspBox = getPaspBox(trakBox);
  if (!paspBox) {
    return {
      numerator: 1,
      denominator: 1
    };
  }
  return {
    numerator: paspBox.hSpacing,
    denominator: paspBox.vSpacing
  };
};
var getColrBox = (videoSample) => {
  const colrBox = videoSample.descriptors.find((c) => c.type === "colr-box");
  if (!colrBox || colrBox.type !== "colr-box") {
    return null;
  }
  return colrBox;
};
var applyTkhdBox = (aspectRatioApplied, tkhdBox) => {
  if (tkhdBox === null || tkhdBox.rotation === 0) {
    return {
      displayAspectWidth: aspectRatioApplied.width,
      displayAspectHeight: aspectRatioApplied.height,
      width: aspectRatioApplied.width,
      height: aspectRatioApplied.height,
      rotation: 0
    };
  }
  return {
    width: tkhdBox.width,
    height: tkhdBox.height,
    rotation: tkhdBox.rotation,
    displayAspectWidth: aspectRatioApplied.width,
    displayAspectHeight: aspectRatioApplied.height
  };
};
var applyAspectRatios = ({
  dimensions,
  sampleAspectRatio,
  displayAspectRatio
}) => {
  if (displayAspectRatio.numerator === 0) {
    return dimensions;
  }
  if (displayAspectRatio.denominator === 0) {
    return dimensions;
  }
  const newWidth = Math.round(dimensions.width * sampleAspectRatio.numerator / sampleAspectRatio.denominator);
  const newHeight = Math.floor(newWidth / (displayAspectRatio.numerator / displayAspectRatio.denominator));
  return {
    width: Math.floor(newWidth),
    height: newHeight
  };
};
function gcd(a, b) {
  return b === 0 ? a : gcd(b, a % b);
}
function reduceFraction(numerator, denominator) {
  const greatestCommonDivisor = gcd(Math.abs(numerator), Math.abs(denominator));
  return {
    numerator: numerator / greatestCommonDivisor,
    denominator: denominator / greatestCommonDivisor
  };
}
var getDisplayAspectRatio = ({
  sampleAspectRatio,
  nativeDimensions
}) => {
  const num = Math.round(nativeDimensions.width * sampleAspectRatio.numerator);
  const den = Math.round(nativeDimensions.height * sampleAspectRatio.denominator);
  return reduceFraction(num, den);
};

// src/boxes/avc/color.ts
var getMatrixCoefficientsFromIndex = (index) => {
  return index === 1 ? "bt709" : index === 5 ? "bt470bg" : index === 6 ? "smpte170m" : index === 9 ? "bt2020" : null;
};
var getTransferCharacteristicsFromIndex = (index) => {
  return index === 1 ? "bt709" : index === 6 ? "smpte170m" : index === 13 ? "iec61966-2-1" : index === 18 ? "arib-std-b67" : null;
};
var getPrimariesFromIndex = (index) => {
  return index === 1 ? "bt709" : index === 5 ? "bt470bg" : index === 6 ? "smpte170m" : index === 9 ? "bt2020" : null;
};

// src/boxes/webm/av1-codec-private.ts
var parseAv1PrivateData = (data, colrAtom) => {
  const iterator = getArrayBufferIterator(data, data.byteLength);
  iterator.startReadingBits();
  if (iterator.getBits(1) !== 1) {
    iterator.destroy();
    throw new Error("Expected av1 private data to be version 1");
  }
  const version = iterator.getBits(7);
  if (version !== 1) {
    iterator.destroy();
    throw new Error(`Expected av1 private data to be version 1, got ${version}`);
  }
  let str = "av01.";
  const seqProfile = iterator.getBits(3);
  str += seqProfile;
  str += ".";
  const seq_level_idx = iterator.getBits(5);
  const seq_tier_0 = iterator.getBits(1);
  str += seq_level_idx.toString(16).padStart(2, "0");
  str += seq_tier_0 ? "H" : "M";
  str += ".";
  const high_bitdepth = iterator.getBits(1);
  const twelve_bit = iterator.getBits(1);
  const bitDepth2 = high_bitdepth && seqProfile === 2 ? twelve_bit ? 12 : 10 : high_bitdepth ? 10 : 8;
  str += bitDepth2.toString().padStart(2, "0");
  str += ".";
  const mono_chrome = iterator.getBits(1);
  str += mono_chrome ? "1" : "0";
  str += ".";
  const subsampling_x = iterator.getBits(1);
  str += subsampling_x ? "1" : "0";
  const subsampling_y = iterator.getBits(1);
  str += subsampling_y ? "1" : "0";
  const chroma_sample_position = iterator.getBits(2);
  str += subsampling_x && subsampling_y ? chroma_sample_position === 1 ? "1" : "0" : "0";
  str += ".";
  if (colrAtom && colrAtom.colorType === "transfer-characteristics") {
    str += colrAtom.primaries.toString().padStart(2, "0");
    str += ".";
    str += colrAtom.transfer.toString().padStart(2, "0");
    str += ".";
    str += colrAtom.matrixIndex.toString().padStart(2, "0");
    str += ".";
    str += colrAtom.fullRangeFlag ? "1" : "0";
  } else {
    str += "01";
    str += ".";
    str += "01";
    str += ".";
    str += "01";
    str += ".";
    str += "0";
  }
  const suffix = ".0.110.01.01.01.0";
  if (str.endsWith(suffix)) {
    str = str.slice(0, -suffix.length);
  }
  iterator.destroy();
  return str;
};

// src/get-video-codec.ts
var getVideoCodec = (boxes, state) => {
  const track = getTracks(boxes, state);
  return track.videoTracks[0]?.codecWithoutConfig ?? null;
};
var hasVideoCodec = (boxes, state) => {
  return hasTracks(boxes, state);
};
var getVideoPrivateData = (trakBox) => {
  const videoSample = getStsdVideoConfig(trakBox);
  const avccBox = getAvccBox(trakBox);
  const hvccBox = getHvccBox(trakBox);
  const av1cBox = getAv1CBox(trakBox);
  if (!videoSample) {
    return null;
  }
  if (avccBox) {
    return avccBox.privateData;
  }
  if (hvccBox) {
    return hvccBox.privateData;
  }
  if (av1cBox) {
    return av1cBox.privateData;
  }
  return null;
};
var getIsoBmColrConfig = (trakBox) => {
  const videoSample = getStsdVideoConfig(trakBox);
  if (!videoSample) {
    return null;
  }
  const colrAtom = getColrBox(videoSample);
  if (!colrAtom) {
    return null;
  }
  if (colrAtom.colorType !== "transfer-characteristics") {
    return null;
  }
  return {
    fullRange: colrAtom.fullRangeFlag,
    matrixCoefficients: getMatrixCoefficientsFromIndex(colrAtom.matrixIndex),
    primaries: getPrimariesFromIndex(colrAtom.primaries),
    transferCharacteristics: getTransferCharacteristicsFromIndex(colrAtom.transfer)
  };
};
var getVideoCodecString = (trakBox) => {
  const videoSample = getStsdVideoConfig(trakBox);
  const avccBox = getAvccBox(trakBox);
  const hvccBox = getHvccBox(trakBox);
  const av1cBox = getAv1CBox(trakBox);
  if (!videoSample) {
    return null;
  }
  if (avccBox) {
    return `${videoSample.format}.${avccBox.configurationString}`;
  }
  if (hvccBox) {
    return `${videoSample.format}.${hvccBox.configurationString}`;
  }
  if (av1cBox) {
    const colrAtom = getColrBox(videoSample);
    return parseAv1PrivateData(av1cBox.privateData, colrAtom);
  }
  return videoSample.format;
};

// src/boxes/iso-base-media/get-actual-number-of-channels.ts
var getActualDecoderParameters = ({
  audioCodec,
  codecPrivate: codecPrivate2,
  numberOfChannels,
  sampleRate
}) => {
  if (audioCodec !== "aac") {
    return { numberOfChannels, sampleRate, codecPrivate: codecPrivate2 };
  }
  if (codecPrivate2 === null) {
    return { numberOfChannels, sampleRate, codecPrivate: codecPrivate2 };
  }
  const parsed = parseAacCodecPrivate(codecPrivate2);
  return {
    numberOfChannels: parsed.channelConfiguration,
    sampleRate: parsed.sampleRate,
    codecPrivate: createAacCodecPrivate(parsed)
  };
};

// src/boxes/iso-base-media/get-video-codec-from-iso-track.ts
var getVideoCodecFromIsoTrak = (trakBox) => {
  const stsdBox = getStsdBox(trakBox);
  if (stsdBox && stsdBox.type === "stsd-box") {
    const videoSample = stsdBox.samples.find((s) => s.type === "video");
    if (videoSample && videoSample.type === "video") {
      if (videoSample.format === "hvc1") {
        return "h265";
      }
      if (videoSample.format === "avc1") {
        return "h264";
      }
      if (videoSample.format === "av01") {
        return "av1";
      }
      if (videoSample.format === "ap4h") {
        return "prores";
      }
      if (videoSample.format === "ap4x") {
        return "prores";
      }
      if (videoSample.format === "apch") {
        return "prores";
      }
      if (videoSample.format === "apcn") {
        return "prores";
      }
      if (videoSample.format === "apcs") {
        return "prores";
      }
      if (videoSample.format === "apco") {
        return "prores";
      }
      if (videoSample.format === "aprh") {
        return "prores";
      }
      if (videoSample.format === "aprn") {
        return "prores";
      }
    }
  }
  throw new Error("Could not find video codec");
};

// src/boxes/iso-base-media/make-track.ts
var makeBaseMediaTrack = (trakBox) => {
  const tkhdBox = getTkhdBox(trakBox);
  const videoDescriptors = getVideoDescriptors(trakBox);
  const timescaleAndDuration = getTimescaleAndDuration(trakBox);
  if (!tkhdBox) {
    throw new Error("Expected tkhd box in trak box");
  }
  if (!timescaleAndDuration) {
    throw new Error("Expected timescale and duration in trak box");
  }
  if (trakBoxContainsAudio(trakBox)) {
    const numberOfChannels = getNumberOfChannelsFromTrak(trakBox);
    if (numberOfChannels === null) {
      throw new Error("Could not find number of channels");
    }
    const sampleRate = getSampleRate(trakBox);
    if (sampleRate === null) {
      throw new Error("Could not find sample rate");
    }
    const { codecString, description } = getAudioCodecStringFromTrak(trakBox);
    const codecPrivate2 = getCodecPrivateFromTrak(trakBox) ?? description ?? null;
    const codecWithoutConfig = getAudioCodecFromTrack(trakBox);
    const actual = getActualDecoderParameters({
      audioCodec: codecWithoutConfig,
      codecPrivate: codecPrivate2,
      numberOfChannels,
      sampleRate
    });
    return {
      type: "audio",
      trackId: tkhdBox.trackId,
      timescale: timescaleAndDuration.timescale,
      codec: codecString,
      numberOfChannels: actual.numberOfChannels,
      sampleRate: actual.sampleRate,
      description: actual.codecPrivate ?? undefined,
      trakBox,
      codecPrivate: actual.codecPrivate,
      codecWithoutConfig
    };
  }
  if (!trakBoxContainsVideo(trakBox)) {
    return {
      type: "other",
      trackId: tkhdBox.trackId,
      timescale: timescaleAndDuration.timescale,
      trakBox
    };
  }
  const videoSample = getStsdVideoConfig(trakBox);
  if (!videoSample) {
    throw new Error("No video sample");
  }
  const sampleAspectRatio = getSampleAspectRatio(trakBox);
  const aspectRatioApplied = applyAspectRatios({
    dimensions: videoSample,
    sampleAspectRatio,
    displayAspectRatio: getDisplayAspectRatio({
      sampleAspectRatio,
      nativeDimensions: videoSample
    })
  });
  const { displayAspectHeight, displayAspectWidth, height, rotation, width } = applyTkhdBox(aspectRatioApplied, tkhdBox);
  const codec = getVideoCodecString(trakBox);
  if (!codec) {
    throw new Error("Could not find video codec");
  }
  const privateData = getVideoPrivateData(trakBox);
  const track = {
    type: "video",
    trackId: tkhdBox.trackId,
    description: videoDescriptors ?? undefined,
    timescale: timescaleAndDuration.timescale,
    codec,
    sampleAspectRatio: getSampleAspectRatio(trakBox),
    width,
    height,
    codedWidth: videoSample.width,
    codedHeight: videoSample.height,
    displayAspectWidth,
    displayAspectHeight,
    rotation,
    trakBox,
    codecPrivate: privateData,
    color: getIsoBmColrConfig(trakBox) ?? {
      fullRange: null,
      matrixCoefficients: null,
      primaries: null,
      transferCharacteristics: null
    },
    codecWithoutConfig: getVideoCodecFromIsoTrak(trakBox),
    fps: getFpsFromMp4TrakBox(trakBox)
  };
  return track;
};

// src/boxes/avc/codec-string.ts
var getCodecStringFromSpsAndPps = (sps) => {
  return `avc1.${sps.spsData.profile.toString(16).padStart(2, "0")}${sps.spsData.compatibility.toString(16).padStart(2, "0")}${sps.spsData.level.toString(16).padStart(2, "0")}`;
};

// src/combine-uint8-arrays.ts
var combineUint8Arrays = (arrays) => {
  if (arrays.length === 0) {
    return new Uint8Array([]);
  }
  if (arrays.length === 1) {
    return arrays[0];
  }
  let totalLength = 0;
  for (const array of arrays) {
    totalLength += array.length;
  }
  const result = new Uint8Array(totalLength);
  let offset = 0;
  for (const array of arrays) {
    result.set(array, offset);
    offset += array.length;
  }
  return result;
};

// src/boxes/avc/create-sps-pps-data.ts
function serializeUint16(value) {
  const buffer = new ArrayBuffer(2);
  const view = new DataView(buffer);
  view.setUint16(0, value);
  return new Uint8Array(buffer);
}
var createSpsPpsData = (avc1Profile) => {
  return combineUint8Arrays([
    new Uint8Array([
      1,
      avc1Profile.sps.spsData.profile,
      avc1Profile.sps.spsData.compatibility,
      avc1Profile.sps.spsData.level,
      255,
      225
    ]),
    serializeUint16(avc1Profile.sps.sps.length),
    avc1Profile.sps.sps,
    new Uint8Array([1]),
    serializeUint16(avc1Profile.pps.pps.length),
    avc1Profile.pps.pps
  ]);
};

// src/add-avc-profile-to-track.ts
var addAvcProfileToTrack = (track, avc1Profile) => {
  if (avc1Profile === null) {
    return track;
  }
  return {
    ...track,
    codec: getCodecStringFromSpsAndPps(avc1Profile.sps),
    codecPrivate: createSpsPpsData(avc1Profile)
  };
};

// src/boxes/riff/timescale.ts
var MEDIA_PARSER_RIFF_TIMESCALE = 1e6;

// src/boxes/riff/get-tracks-from-avi.ts
var TO_BE_OVERRIDDEN_LATER = "to-be-overriden-later";
var getNumberOfTracks = (structure) => {
  const avihBox = getAvihBox(structure);
  if (avihBox) {
    return avihBox.streams;
  }
  throw new Error("No avih box found");
};
var makeAviAudioTrack = ({
  strf,
  index
}) => {
  if (strf.formatTag !== 255) {
    throw new Error(`Unsupported audio format ${strf.formatTag}`);
  }
  return {
    type: "audio",
    codec: "mp4a.40.2",
    codecPrivate: new Uint8Array([18, 16]),
    codecWithoutConfig: "aac",
    description: new Uint8Array([18, 16]),
    numberOfChannels: strf.numberOfChannels,
    sampleRate: strf.sampleRate,
    timescale: MEDIA_PARSER_RIFF_TIMESCALE,
    trackId: index,
    trakBox: null
  };
};
var makeAviVideoTrack = ({
  strh,
  strf,
  index
}) => {
  if (strh.handler !== "H264") {
    throw new Error(`Unsupported video codec ${strh.handler}`);
  }
  return {
    codecPrivate: null,
    codec: TO_BE_OVERRIDDEN_LATER,
    codecWithoutConfig: "h264",
    codedHeight: strf.height,
    codedWidth: strf.width,
    width: strf.width,
    height: strf.height,
    type: "video",
    displayAspectHeight: strf.height,
    timescale: MEDIA_PARSER_RIFF_TIMESCALE,
    description: undefined,
    trackId: index,
    color: {
      fullRange: null,
      matrixCoefficients: null,
      primaries: null,
      transferCharacteristics: null
    },
    displayAspectWidth: strf.width,
    trakBox: null,
    rotation: 0,
    sampleAspectRatio: {
      numerator: 1,
      denominator: 1
    },
    fps: strh.rate / strh.scale
  };
};
var getTracksFromAvi = (structure, state) => {
  if (!isRiffAvi2(structure)) {
    throw new Error("Not an AVI file");
  }
  const videoTracks = [];
  const audioTracks = [];
  const otherTracks = [];
  const boxes = getStrlBoxes(structure);
  let i = 0;
  for (const box of boxes) {
    const strh = getStrhBox(box.children);
    const strf = getStrfBox(box.children);
    if (!strh || !strf) {
      continue;
    }
    if (strf.type === "strf-box-video") {
      videoTracks.push(addAvcProfileToTrack(makeAviVideoTrack({ strh, strf, index: i }), state.riff.getAvcProfile()));
    } else if (strh.fccType === "auds") {
      audioTracks.push(makeAviAudioTrack({ strf, index: i }));
    } else {
      throw new Error(`Unsupported track type ${strh.fccType}`);
    }
    i++;
  }
  return { audioTracks, otherTracks, videoTracks };
};
var hasAllTracksFromAvi = (structure, state) => {
  if (!isRiffAvi2(structure)) {
    throw new Error("Not an AVI file");
  }
  try {
    const numberOfTracks = getNumberOfTracks(structure);
    const tracks2 = getTracksFromAvi(structure, state);
    return tracks2.videoTracks.length + tracks2.audioTracks.length + tracks2.otherTracks.length === numberOfTracks;
  } catch {
    return false;
  }
};

// src/truthy.ts
function truthy(value) {
  return Boolean(value);
}

// src/boxes/transport-stream/traversal.ts
var findProgramAssociationTableOrThrow = (structure) => {
  const box = structure.boxes.find((b) => b.type === "transport-stream-pat-box");
  if (!box) {
    throw new Error("No PAT box found");
  }
  return box;
};
var findProgramMapTableOrThrow = (structure) => {
  const box = structure.boxes.find((b) => b.type === "transport-stream-pmt-box");
  if (!box) {
    throw new Error("No PMT box found");
  }
  return box;
};
var getProgramForId = (structure, packetIdentifier) => {
  const box = findProgramAssociationTableOrThrow(structure);
  const entry = box.pat.find((e) => e.programMapIdentifier === packetIdentifier);
  return entry ?? null;
};
var getStreamForId = (structure, packetIdentifier) => {
  const box = findProgramMapTableOrThrow(structure);
  const entry = box.streams.find((e) => e.pid === packetIdentifier);
  return entry ?? null;
};

// src/boxes/transport-stream/get-tracks.ts
var getTracksFromTransportStream = (structure, parserState) => {
  const programMapTable = findProgramMapTableOrThrow(structure);
  const parserTracks = parserState.callbacks.tracks.getTracks();
  const mapped = programMapTable.streams.map((stream) => {
    return parserTracks.find((track) => track.trackId === stream.pid);
  }).filter(truthy);
  if (mapped.length !== programMapTable.streams.length) {
    throw new Error("Not all tracks found");
  }
  return {
    videoTracks: mapped.filter((track) => track.type === "video"),
    audioTracks: mapped.filter((track) => track.type === "audio"),
    otherTracks: []
  };
};
var hasAllTracksFromTransportStream = (structure, parserState) => {
  try {
    getTracksFromTransportStream(structure, parserState);
    return true;
  } catch {
    return false;
  }
};

// src/make-hvc1-codec-strings.ts
var getHvc1CodecString = (data) => {
  const configurationVersion = data.getUint8();
  if (configurationVersion !== 1) {
    throw new Error(`Unsupported HVCC version ${configurationVersion}`);
  }
  const generalProfileSpaceTierFlagAndIdc = data.getUint8();
  let generalProfileCompatibility = data.getUint32();
  const generalProfileSpace = generalProfileSpaceTierFlagAndIdc >> 6;
  const generalTierFlag = generalProfileSpaceTierFlagAndIdc >> 5;
  const generalProfileIdc = generalProfileSpaceTierFlagAndIdc >> 0;
  const generalConstraintIndicator = data.getSlice(6);
  const generalLevelIdc = data.getUint8();
  let reversedGeneralProfileSpace = 0;
  for (let i = 0;i < 32; i++) {
    reversedGeneralProfileSpace |= generalProfileCompatibility & 1;
    if (i === 31)
      break;
    reversedGeneralProfileSpace <<= 1;
    generalProfileCompatibility >>= 1;
  }
  const profileSpaceChar = generalProfileSpace === 0 ? "" : generalProfileSpace === 1 ? "A" : generalProfileSpace === 2 ? "B" : "C";
  const generalTierChar = generalTierFlag === 0 ? "L" : "H";
  let hasByte = false;
  let generalConstraintString = "";
  for (let i = 5;i >= 0; i--) {
    if (generalConstraintIndicator[i] || hasByte) {
      generalConstraintString = generalConstraintIndicator[i].toString(16) + generalConstraintString;
      hasByte = true;
    }
  }
  return `${profileSpaceChar}${generalProfileIdc.toString(16)}.${reversedGeneralProfileSpace.toString(16)}.${generalTierChar}${generalLevelIdc}.${generalConstraintString}`;
};

// src/boxes/webm/traversal.ts
var getMainSegment = (segments) => {
  return segments.find((s) => s.type === "Segment");
};
var getTrackCodec = (track) => {
  const child = track.value.find((b) => b.type === "CodecID");
  return child ?? null;
};
var getTrackTimestampScale = (track) => {
  const child = track.value.find((b) => b.type === "TrackTimestampScale");
  if (!child) {
    return null;
  }
  if (child.type !== "TrackTimestampScale") {
    throw new Error("Expected TrackTimestampScale");
  }
  return child.value;
};
var getTrackId = (track) => {
  const trackId = track.value.find((b) => b.type === "TrackNumber");
  if (!trackId || trackId.type !== "TrackNumber") {
    throw new Error("Expected track number segment");
  }
  return trackId.value.value;
};
var getCodecSegment = (track) => {
  const codec = track.value.find((b) => b.type === "CodecID");
  if (!codec || codec.type !== "CodecID") {
    return null;
  }
  return codec;
};
var getColourSegment = (track) => {
  const videoSegment2 = getVideoSegment(track);
  if (!videoSegment2) {
    return null;
  }
  const colour = videoSegment2.value.find((b) => b.type === "Colour");
  if (!colour || colour.type !== "Colour") {
    return null;
  }
  return colour;
};
var getTransferCharacteristicsSegment = (color2) => {
  if (!color2 || color2.type !== "Colour") {
    return null;
  }
  const box = color2.value.find((b) => b.type === "TransferCharacteristics");
  if (!box || box.type !== "TransferCharacteristics") {
    return null;
  }
  return box;
};
var getMatrixCoefficientsSegment = (color2) => {
  if (!color2 || color2.type !== "Colour") {
    return null;
  }
  const box = color2.value.find((b) => b.type === "MatrixCoefficients");
  if (!box || box.type !== "MatrixCoefficients") {
    return null;
  }
  return box;
};
var getPrimariesSegment = (color2) => {
  if (!color2 || color2.type !== "Colour") {
    return null;
  }
  const box = color2.value.find((b) => b.type === "Primaries");
  if (!box || box.type !== "Primaries") {
    return null;
  }
  return box;
};
var getRangeSegment = (color2) => {
  if (!color2 || color2.type !== "Colour") {
    return null;
  }
  const box = color2.value.find((b) => b.type === "Range");
  if (!box || box.type !== "Range") {
    return null;
  }
  return box;
};
var getDisplayHeightSegment = (track) => {
  const videoSegment2 = getVideoSegment(track);
  if (!videoSegment2) {
    return null;
  }
  const displayHeight2 = videoSegment2.value.find((b) => b.type === "DisplayHeight");
  if (!displayHeight2 || displayHeight2.type !== "DisplayHeight") {
    return null;
  }
  return displayHeight2;
};
var getTrackTypeSegment = (track) => {
  const trackType2 = track.value.find((b) => b.type === "TrackType");
  if (!trackType2 || trackType2.type !== "TrackType") {
    return null;
  }
  return trackType2;
};
var getWidthSegment = (track) => {
  const videoSegment2 = getVideoSegment(track);
  if (!videoSegment2) {
    return null;
  }
  const width = videoSegment2.value.find((b) => b.type === "PixelWidth");
  if (!width || width.type !== "PixelWidth") {
    return null;
  }
  return width;
};
var getHeightSegment = (track) => {
  const videoSegment2 = getVideoSegment(track);
  if (!videoSegment2) {
    return null;
  }
  const height = videoSegment2.value.find((b) => b.type === "PixelHeight");
  if (!height || height.type !== "PixelHeight") {
    return null;
  }
  return height;
};
var getDisplayWidthSegment = (track) => {
  const videoSegment2 = getVideoSegment(track);
  if (!videoSegment2) {
    return null;
  }
  const displayWidth2 = videoSegment2.value.find((b) => b.type === "DisplayWidth");
  if (!displayWidth2 || displayWidth2.type !== "DisplayWidth") {
    return null;
  }
  return displayWidth2;
};
var getTracksSegment = (segment) => {
  const tracksSegment = segment.value.find((b) => b.type === "Tracks");
  if (!tracksSegment) {
    return null;
  }
  return tracksSegment;
};
var getTrackWithUid = (segment, trackUid) => {
  const tracksSegment = getTracksSegment(segment);
  if (!tracksSegment) {
    return null;
  }
  const trackEntries = tracksSegment.value.filter((t) => t.type === "TrackEntry");
  const trackEntry2 = trackEntries.find((entry) => {
    return entry?.value.find((t) => t.type === "TrackUID" && t.value === trackUid);
  });
  if (!trackEntry2) {
    return null;
  }
  return trackEntry2.value.find((t) => t.type === "TrackNumber")?.value.value ?? null;
};
var getVideoSegment = (track) => {
  const videoSegment2 = track.value.find((b) => b.type === "Video");
  if (!videoSegment2 || videoSegment2.type !== "Video") {
    return null;
  }
  return videoSegment2 ?? null;
};
var getAudioSegment = (track) => {
  const audioSegment2 = track.value.find((b) => b.type === "Audio");
  if (!audioSegment2 || audioSegment2.type !== "Audio") {
    return null;
  }
  return audioSegment2 ?? null;
};
var getSampleRate2 = (track) => {
  const audioSegment2 = getAudioSegment(track);
  if (!audioSegment2) {
    return null;
  }
  const samplingFrequency2 = audioSegment2.value.find((b) => b.type === "SamplingFrequency");
  if (!samplingFrequency2 || samplingFrequency2.type !== "SamplingFrequency") {
    return null;
  }
  return samplingFrequency2.value.value;
};
var getNumberOfChannels = (track) => {
  const audioSegment2 = getAudioSegment(track);
  if (!audioSegment2) {
    throw new Error("Could not find audio segment");
  }
  const channels2 = audioSegment2.value.find((b) => b.type === "Channels");
  if (!channels2 || channels2.type !== "Channels") {
    return 1;
  }
  return channels2.value.value;
};
var getBitDepth = (track) => {
  const audioSegment2 = getAudioSegment(track);
  if (!audioSegment2) {
    return null;
  }
  const bitDepth2 = audioSegment2.value.find((b) => b.type === "BitDepth");
  if (!bitDepth2 || bitDepth2.type !== "BitDepth") {
    return null;
  }
  return bitDepth2.value.value;
};
var getPrivateData = (track) => {
  const privateData = track.value.find((b) => b.type === "CodecPrivate");
  if (!privateData || privateData.type !== "CodecPrivate") {
    return null;
  }
  return privateData.value;
};

// src/boxes/webm/color.ts
var parseColorSegment = (colourSegment) => {
  const transferCharacteristics2 = getTransferCharacteristicsSegment(colourSegment);
  const matrixCoefficients2 = getMatrixCoefficientsSegment(colourSegment);
  const primaries2 = getPrimariesSegment(colourSegment);
  const range2 = getRangeSegment(colourSegment);
  return {
    transferCharacteristics: transferCharacteristics2 ? transferCharacteristics2.value.value === 1 ? "bt709" : transferCharacteristics2.value.value === 6 ? "smpte170m" : transferCharacteristics2.value.value === 13 ? "iec61966-2-1" : null : null,
    matrixCoefficients: matrixCoefficients2 ? matrixCoefficients2.value.value === 1 ? "bt709" : matrixCoefficients2.value.value === 6 ? "smpte170m" : matrixCoefficients2.value.value === 5 ? "bt470bg" : null : null,
    primaries: primaries2 ? primaries2.value.value === 1 ? "bt709" : primaries2.value.value === 6 ? "smpte170m" : primaries2.value.value === 5 ? "bt470bg" : null : null,
    fullRange: transferCharacteristics2?.value.value && matrixCoefficients2?.value.value ? null : range2 ? Boolean(range2?.value.value) : null
  };
};

// src/boxes/webm/description.ts
var getAudioDescription = (track) => {
  const codec = getCodecSegment(track);
  if (!codec || codec.value !== "A_VORBIS") {
    return;
  }
  const privateData = getPrivateData(track);
  if (!privateData) {
    return;
  }
  if (privateData[0] !== 2) {
    throw new Error("Expected vorbis private data version 2");
  }
  let offset = 1;
  let vorbisInfoLength = 0;
  let vorbisSkipLength = 0;
  while ((privateData[offset] & 255) === 255) {
    vorbisInfoLength += 255;
    offset++;
  }
  vorbisInfoLength += privateData[offset++] & 255;
  while ((privateData[offset] & 255) === 255) {
    vorbisSkipLength += 255;
    offset++;
  }
  vorbisSkipLength += privateData[offset++] & 255;
  if (privateData[offset] !== 1) {
    throw new Error("Error parsing vorbis codec private");
  }
  const vorbisInfo = privateData.slice(offset, offset + vorbisInfoLength);
  offset += vorbisInfoLength;
  if (privateData[offset] !== 3) {
    throw new Error("Error parsing vorbis codec private");
  }
  const vorbisComments = privateData.slice(offset, offset + vorbisSkipLength);
  offset += vorbisSkipLength;
  if (privateData[offset] !== 5) {
    throw new Error("Error parsing vorbis codec private");
  }
  const vorbisBooks = privateData.slice(offset);
  const bufferIterator = getArrayBufferIterator(vorbisInfo.slice(0), vorbisInfo.length);
  bufferIterator.getUint8();
  const vorbis = bufferIterator.getByteString(6, false);
  if (vorbis !== "vorbis") {
    throw new Error("Error parsing vorbis codec private");
  }
  const vorbisVersion = bufferIterator.getUint32Le();
  if (vorbisVersion !== 0) {
    throw new Error("Error parsing vorbis codec private");
  }
  const vorbisDescription = new Uint8Array([
    2,
    vorbisInfo.length,
    vorbisComments.length,
    ...vorbisInfo,
    ...vorbisComments,
    ...vorbisBooks
  ]);
  return vorbisDescription;
};

// src/boxes/webm/segments/track-entry.ts
var trackTypeToString = (trackType2) => {
  switch (trackType2) {
    case 1:
      return "video";
    case 2:
      return "audio";
    case 3:
      return "complex";
    case 4:
      return "subtitle";
    case 5:
      return "button";
    case 6:
      return "control";
    case 7:
      return "metadata";
    default:
      throw new Error(`Unknown track type: ${trackType2}`);
  }
};

// src/boxes/webm/make-track.ts
var getDescription = (track) => {
  const codec = getCodecSegment(track);
  if (!codec) {
    return;
  }
  if (codec.value === "V_MPEG4/ISO/AVC" || codec.value === "V_MPEGH/ISO/HEVC") {
    const priv = getPrivateData(track);
    if (priv) {
      return priv;
    }
  }
  return;
};
var getMatroskaVideoCodecWithoutConfigString = ({
  codecSegment: codec
}) => {
  if (codec.value === "V_VP8") {
    return "vp8";
  }
  if (codec.value === "V_VP9") {
    return "vp9";
  }
  if (codec.value === "V_MPEG4/ISO/AVC") {
    return "h264";
  }
  if (codec.value === "V_AV1") {
    return "av1";
  }
  if (codec.value === "V_MPEGH/ISO/HEVC") {
    return "h265";
  }
  throw new Error(`Unknown codec: ${codec.value}`);
};
var getMatroskaVideoCodecString = ({
  track,
  codecSegment: codec
}) => {
  if (codec.value === "V_VP8") {
    return "vp8";
  }
  if (codec.value === "V_VP9") {
    const priv = getPrivateData(track);
    if (priv) {
      throw new Error("@remotion/media-parser cannot handle the private data for VP9. Do you have an example file you could send so we can implement it?");
    }
    return "vp09.00.10.08";
  }
  if (codec.value === "V_MPEG4/ISO/AVC") {
    const priv = getPrivateData(track);
    if (priv) {
      return `avc1.${priv[1].toString(16).padStart(2, "0")}${priv[2].toString(16).padStart(2, "0")}${priv[3].toString(16).padStart(2, "0")}`;
    }
    throw new Error("Could not find a CodecPrivate field in TrackEntry");
  }
  if (codec.value === "V_AV1") {
    const priv = getPrivateData(track);
    if (!priv) {
      throw new Error("Expected private data in AV1 track");
    }
    return parseAv1PrivateData(priv, null);
  }
  if (codec.value === "V_MPEGH/ISO/HEVC") {
    const priv = getPrivateData(track);
    const iterator = getArrayBufferIterator(priv, priv.length);
    return "hvc1." + getHvc1CodecString(iterator);
  }
  throw new Error(`Unknown codec: ${codec.value}`);
};
var getMatroskaAudioCodecWithoutConfigString = ({
  track
}) => {
  const codec = getCodecSegment(track);
  if (!codec) {
    throw new Error("Expected codec segment");
  }
  if (codec.value === "A_OPUS") {
    return "opus";
  }
  if (codec.value === "A_VORBIS") {
    return "vorbis";
  }
  if (codec.value === "A_PCM/INT/LIT") {
    const bitDepth2 = getBitDepth(track);
    if (bitDepth2 === null) {
      throw new Error("Expected bit depth");
    }
    if (bitDepth2 === 8) {
      return "pcm-u8";
    }
    if (bitDepth2 === 16) {
      return "pcm-s16";
    }
    if (bitDepth2 === 24) {
      return "pcm-s24";
    }
    throw new Error("Unknown audio format");
  }
  if (codec.value === "A_AAC") {
    return `aac`;
  }
  if (codec.value === "A_MPEG/L3") {
    return "mp3";
  }
  throw new Error(`Unknown codec: ${codec.value}`);
};
var getMatroskaAudioCodecString = (track) => {
  const codec = getCodecSegment(track);
  if (!codec) {
    throw new Error("Expected codec segment");
  }
  if (codec.value === "A_OPUS") {
    return "opus";
  }
  if (codec.value === "A_VORBIS") {
    return "vorbis";
  }
  if (codec.value === "A_PCM/INT/LIT") {
    const bitDepth2 = getBitDepth(track);
    if (bitDepth2 === null) {
      throw new Error("Expected bit depth");
    }
    if (bitDepth2 === 8) {
      return "pcm-u8";
    }
    return "pcm-s" + bitDepth2;
  }
  if (codec.value === "A_AAC") {
    const priv = getPrivateData(track);
    const iterator = getArrayBufferIterator(priv, priv.length);
    iterator.startReadingBits();
    const profile = iterator.getBits(5);
    iterator.stopReadingBits();
    iterator.destroy();
    return `mp4a.40.${profile.toString().padStart(2, "0")}`;
  }
  if (codec.value === "A_MPEG/L3") {
    return "mp3";
  }
  throw new Error(`Unknown codec: ${codec.value}`);
};
var getTrack = ({
  timescale,
  track
}) => {
  const trackType2 = getTrackTypeSegment(track);
  if (!trackType2) {
    throw new Error("Expected track type segment");
  }
  const trackId = getTrackId(track);
  if (trackTypeToString(trackType2.value.value) === "video") {
    const width = getWidthSegment(track);
    if (width === null) {
      throw new Error("Expected width segment");
    }
    const height = getHeightSegment(track);
    if (height === null) {
      throw new Error("Expected height segment");
    }
    const displayHeight2 = getDisplayHeightSegment(track);
    const displayWidth2 = getDisplayWidthSegment(track);
    const codec = getCodecSegment(track);
    if (!codec) {
      return null;
    }
    const codecPrivate2 = getPrivateData(track);
    const codecString = getMatroskaVideoCodecString({
      track,
      codecSegment: codec
    });
    const colour = getColourSegment(track);
    if (!codecString) {
      return null;
    }
    return {
      type: "video",
      trackId,
      codec: codecString,
      description: getDescription(track),
      height: displayHeight2 ? displayHeight2.value.value : height.value.value,
      width: displayWidth2 ? displayWidth2.value.value : width.value.value,
      sampleAspectRatio: {
        numerator: 1,
        denominator: 1
      },
      timescale,
      codedHeight: height.value.value,
      codedWidth: width.value.value,
      displayAspectHeight: displayHeight2 ? displayHeight2.value.value : height.value.value,
      displayAspectWidth: displayWidth2 ? displayWidth2.value.value : width.value.value,
      rotation: 0,
      trakBox: null,
      codecPrivate: codecPrivate2,
      color: colour ? parseColorSegment(colour) : {
        fullRange: null,
        matrixCoefficients: null,
        primaries: null,
        transferCharacteristics: null
      },
      codecWithoutConfig: getMatroskaVideoCodecWithoutConfigString({
        codecSegment: codec
      }),
      fps: null
    };
  }
  if (trackTypeToString(trackType2.value.value) === "audio") {
    const sampleRate = getSampleRate2(track);
    const numberOfChannels = getNumberOfChannels(track);
    const codecPrivate2 = getPrivateData(track);
    if (sampleRate === null) {
      throw new Error("Could not find sample rate or number of channels");
    }
    return {
      type: "audio",
      trackId,
      codec: getMatroskaAudioCodecString(track),
      timescale,
      numberOfChannels,
      sampleRate,
      description: getAudioDescription(track),
      trakBox: null,
      codecPrivate: codecPrivate2,
      codecWithoutConfig: getMatroskaAudioCodecWithoutConfigString({
        track
      })
    };
  }
  return null;
};

// src/boxes/webm/get-ready-tracks.ts
var getTracksFromMatroska = (segment, timescale) => {
  const tracksSegment = getTracksSegment(segment);
  if (!tracksSegment) {
    throw new Error("No tracks segment");
  }
  const tracks2 = [];
  for (const trackEntrySegment of tracksSegment.value) {
    if (trackEntrySegment.type === "Crc32") {
      continue;
    }
    if (trackEntrySegment.type !== "TrackEntry") {
      throw new Error("Expected track entry segment");
    }
    const track = getTrack({
      track: trackEntrySegment,
      timescale
    });
    if (track) {
      tracks2.push(track);
    }
  }
  return tracks2;
};

// src/get-tracks.ts
var getNumberOfTracks2 = (moovBox) => {
  const mvHdBox = getMvhdBox(moovBox);
  if (!mvHdBox) {
    return 0;
  }
  return mvHdBox.nextTrackId - 1;
};
var isoBaseMediaHasTracks = (structure) => {
  const moovBox = getMoovBox(structure.boxes);
  if (!moovBox) {
    return false;
  }
  const numberOfTracks = getNumberOfTracks2(moovBox);
  const tracks2 = getTraks(moovBox);
  return tracks2.length === numberOfTracks;
};
var hasTracks = (structure, state) => {
  if (structure.type === "matroska") {
    const mainSegment = getMainSegment(structure.boxes);
    if (!mainSegment) {
      return false;
    }
    return getTracksSegment(mainSegment) !== null;
  }
  if (structure.type === "iso-base-media") {
    return isoBaseMediaHasTracks(structure);
  }
  if (structure.type === "riff") {
    return hasAllTracksFromAvi(structure, state);
  }
  if (structure.type === "transport-stream") {
    return hasAllTracksFromTransportStream(structure, state);
  }
  throw new Error("Unknown container " + structure);
};
var getTracksFromMa = (segments, state) => {
  const videoTracks = [];
  const audioTracks = [];
  const otherTracks = [];
  const mainSegment = segments.find((s) => s.type === "Segment");
  if (!mainSegment) {
    throw new Error("No main segment found");
  }
  const matroskaTracks = getTracksFromMatroska(mainSegment, state.webm.getTimescale());
  for (const track of matroskaTracks) {
    if (track.type === "video") {
      videoTracks.push(track);
    } else if (track.type === "audio") {
      audioTracks.push(track);
    } else if (track.type === "other") {
      otherTracks.push(track);
    }
  }
  return {
    videoTracks,
    audioTracks,
    otherTracks
  };
};
var getTracksFromIsoBaseMedia = (segments) => {
  const videoTracks = [];
  const audioTracks = [];
  const otherTracks = [];
  const moovBox = getMoovBox(segments);
  if (!moovBox) {
    return {
      videoTracks,
      audioTracks,
      otherTracks
    };
  }
  const tracks2 = getTraks(moovBox);
  for (const trakBox of tracks2) {
    const track = makeBaseMediaTrack(trakBox);
    if (!track) {
      continue;
    }
    if (track.type === "video") {
      videoTracks.push(track);
    } else if (track.type === "audio") {
      audioTracks.push(track);
    } else if (track.type === "other") {
      otherTracks.push(track);
    }
  }
  return {
    videoTracks,
    audioTracks,
    otherTracks
  };
};
var getTracks = (segments, state) => {
  if (segments.type === "matroska") {
    return getTracksFromMa(segments.boxes, state);
  }
  if (segments.type === "iso-base-media") {
    return getTracksFromIsoBaseMedia(segments.boxes);
  }
  if (segments.type === "riff") {
    return getTracksFromAvi(segments, state);
  }
  if (segments.type === "transport-stream") {
    return getTracksFromTransportStream(segments, state);
  }
  throw new Error(`Unknown container${segments}`);
};

// src/get-container.ts
var getContainer = (segments) => {
  if (segments.type === "iso-base-media") {
    return "mp4";
  }
  if (segments.type === "matroska") {
    return "webm";
  }
  if (segments.type === "transport-stream") {
    return "transport-stream";
  }
  if (segments.type === "riff") {
    if (isRiffAvi2(segments)) {
      return "avi";
    }
  }
  throw new Error("Unknown container");
};
var hasContainer = (boxes) => {
  try {
    return getContainer(boxes) !== null;
  } catch {
    return false;
  }
};

// src/get-dimensions.ts
var getDimensions = (boxes, state) => {
  const { videoTracks } = getTracks(boxes, state);
  if (!videoTracks.length) {
    throw new Error("Expected video track");
  }
  const firstVideoTrack = videoTracks[0];
  return {
    width: firstVideoTrack.width,
    height: firstVideoTrack.height,
    rotation: firstVideoTrack.rotation,
    unrotatedHeight: firstVideoTrack.displayAspectHeight,
    unrotatedWidth: firstVideoTrack.displayAspectWidth
  };
};
var hasDimensions = (boxes, state) => {
  try {
    return getDimensions(boxes, state) !== null;
  } catch {
    return false;
  }
};

// src/get-sample-positions.ts
var getSamplePositions = ({
  stcoBox,
  stszBox,
  stscBox,
  stssBox,
  sttsBox,
  cttsBox
}) => {
  const sttsDeltas = [];
  for (const distribution of sttsBox.sampleDistribution) {
    for (let i = 0;i < distribution.sampleCount; i++) {
      sttsDeltas.push(distribution.sampleDelta);
    }
  }
  const cttsEntries = [];
  for (const entry of cttsBox?.entries ?? [
    { sampleCount: sttsDeltas.length, sampleOffset: 0 }
  ]) {
    for (let i = 0;i < entry.sampleCount; i++) {
      cttsEntries.push(entry.sampleOffset);
    }
  }
  let dts = 0;
  const chunks = stcoBox.entries;
  const samples = [];
  let samplesPerChunk = 1;
  for (let i = 0;i < chunks.length; i++) {
    const hasEntry = stscBox.entries.find((entry) => entry.firstChunk === i + 1);
    if (hasEntry) {
      samplesPerChunk = hasEntry.samplesPerChunk;
    }
    let offsetInThisChunk = 0;
    for (let j = 0;j < samplesPerChunk; j++) {
      const size = stszBox.countType === "fixed" ? stszBox.sampleSize : stszBox.entries[samples.length];
      const isKeyframe = stssBox ? stssBox.sampleNumber.includes(samples.length + 1) : true;
      const delta = sttsDeltas[samples.length];
      const ctsOffset = cttsEntries[samples.length];
      const cts = dts + ctsOffset;
      samples.push({
        offset: Number(chunks[i]) + offsetInThisChunk,
        size,
        isKeyframe,
        dts,
        cts,
        duration: delta,
        chunk: i
      });
      dts += delta;
      offsetInThisChunk += size;
    }
  }
  return samples;
};

// src/get-sample-positions-from-lpcm.ts
var getSamplePositionsFromLpcm = (trakBox) => {
  const stscBox = getStscBox(trakBox);
  const stszBox = getStszBox(trakBox);
  const stcoBox = getStcoBox(trakBox);
  if (!stscBox) {
    throw new Error("Expected stsc box in trak box");
  }
  if (!stcoBox) {
    throw new Error("Expected stco box in trak box");
  }
  if (!stszBox) {
    throw new Error("Expected stsz box in trak box");
  }
  if (stszBox.countType !== "fixed") {
    throw new Error("Only supporting fixed count type in stsz box");
  }
  const samples = [];
  let timestamp = 0;
  for (let i = 0;i < stcoBox.entries.length; i++) {
    const entry = stcoBox.entries[i];
    const chunk = i + 1;
    const stscEntry = stscBox.entries.findLast((e) => e.firstChunk <= chunk);
    if (!stscEntry) {
      throw new Error("should not be");
    }
    samples.push({
      chunk,
      cts: timestamp,
      dts: timestamp,
      offset: Number(entry),
      size: stszBox.sampleSize * stscEntry.samplesPerChunk,
      duration: stscEntry.samplesPerChunk,
      isKeyframe: true
    });
    timestamp += stscEntry.samplesPerChunk;
  }
  return samples;
};

// src/samples-from-moof.ts
var getSamplesFromTraf = (trafSegment, moofOffset) => {
  if (trafSegment.type !== "regular-box" || trafSegment.boxType !== "traf") {
    throw new Error("Expected traf-box");
  }
  const tfhdBox = getTfhdBox(trafSegment);
  const defaultSampleDuration = tfhdBox?.defaultSampleDuration ?? null;
  const defaultSampleSize = tfhdBox?.defaultSampleSize ?? null;
  const defaultSampleFlags = tfhdBox?.defaultSampleFlags ?? null;
  const tfdtBox = getTfdtBox(trafSegment);
  const trunBoxes = getTrunBoxes(trafSegment);
  let time = 0;
  let offset = 0;
  let dataOffset = 0;
  const samples = [];
  for (const trunBox of trunBoxes) {
    let i = -1;
    if (trunBox.dataOffset) {
      dataOffset = trunBox.dataOffset;
      offset = 0;
    }
    for (const sample of trunBox.samples) {
      i++;
      const duration2 = sample.sampleDuration ?? defaultSampleDuration;
      if (duration2 === null) {
        throw new Error("Expected duration");
      }
      const size = sample.sampleSize ?? defaultSampleSize;
      if (size === null) {
        throw new Error("Expected size");
      }
      const isFirstSample = i === 0;
      const sampleFlags = sample.sampleFlags ? sample.sampleFlags : isFirstSample && trunBox.firstSampleFlags !== null ? trunBox.firstSampleFlags : defaultSampleFlags;
      if (sampleFlags === null) {
        throw new Error("Expected sample flags");
      }
      const keyframe = !(sampleFlags >> 16 & 1);
      const dts = time + (tfdtBox?.baseMediaDecodeTime ?? 0);
      const samplePosition = {
        offset: offset + (moofOffset ?? 0) + (dataOffset ?? 0),
        dts,
        cts: dts,
        duration: duration2,
        isKeyframe: keyframe,
        size,
        chunk: 0
      };
      samples.push(samplePosition);
      offset += size;
      time += duration2;
    }
  }
  return samples;
};
var getSamplesFromMoof = ({
  moofBox,
  trackId
}) => {
  if (moofBox.type !== "regular-box") {
    throw new Error("Expected moof-box");
  }
  const trafs = moofBox.children.filter((c) => c.type === "regular-box" && c.boxType === "traf");
  const mapped = trafs.map((traf) => {
    const tfhdBox = getTfhdBox(traf);
    return tfhdBox?.trackId === trackId ? getSamplesFromTraf(traf, moofBox.offset) : [];
  });
  return mapped.flat(1);
};

// src/boxes/iso-base-media/get-sample-positions-from-track.ts
var getSamplePositionsFromTrack = (trakBox, moofBox) => {
  const isLpcm = isLpcmAudioCodec(trakBox);
  const timescaleAndDuration = getTimescaleAndDuration(trakBox);
  if (isLpcm) {
    return getSamplePositionsFromLpcm(trakBox);
  }
  const stszBox = getStszBox(trakBox);
  const stcoBox = getStcoBox(trakBox);
  const stscBox = getStscBox(trakBox);
  const stssBox = getStssBox(trakBox);
  const sttsBox = getSttsBox(trakBox);
  const tkhdBox = getTkhdBox(trakBox);
  const cttsBox = getCttsBox(trakBox);
  if (!tkhdBox) {
    throw new Error("Expected tkhd box in trak box");
  }
  if (!stszBox) {
    throw new Error("Expected stsz box in trak box");
  }
  if (!stcoBox) {
    throw new Error("Expected stco box in trak box");
  }
  if (!stscBox) {
    throw new Error("Expected stsc box in trak box");
  }
  if (!sttsBox) {
    throw new Error("Expected stts box in trak box");
  }
  if (!timescaleAndDuration) {
    throw new Error("Expected timescale and duration in trak box");
  }
  let samplePositions = getSamplePositions({
    stcoBox,
    stscBox,
    stszBox,
    stssBox,
    sttsBox,
    cttsBox
  });
  if (samplePositions.length === 0 && moofBox) {
    samplePositions = getSamplesFromMoof({ moofBox, trackId: tkhdBox.trackId });
  }
  return samplePositions;
};

// src/get-duration.ts
var getDurationFromMatroska = (segments) => {
  const mainSegment = segments.find((s) => s.type === "Segment");
  if (!mainSegment || mainSegment.type !== "Segment") {
    return null;
  }
  const { value: children } = mainSegment;
  if (!children) {
    return null;
  }
  const infoSegment = children.find((s) => s.type === "Info");
  const relevantBoxes = [
    ...mainSegment.value,
    ...infoSegment && infoSegment.type === "Info" ? infoSegment.value : []
  ];
  const timestampScale2 = relevantBoxes.find((s) => s.type === "TimestampScale");
  if (!timestampScale2 || timestampScale2.type !== "TimestampScale") {
    return null;
  }
  const duration2 = relevantBoxes.find((s) => s.type === "Duration");
  if (!duration2 || duration2.type !== "Duration") {
    return null;
  }
  return duration2.value.value / timestampScale2.value.value * 1000;
};
var getDurationFromIsoBaseMedia = (structure, parserState) => {
  const moovBox = getMoovBox(structure.boxes);
  if (!moovBox) {
    return null;
  }
  const moofBox = getMoofBox(structure.boxes);
  const mvhdBox = getMvhdBox(moovBox);
  if (!mvhdBox) {
    return null;
  }
  if (mvhdBox.type !== "mvhd-box") {
    throw new Error("Expected mvhd-box");
  }
  if (mvhdBox.durationInSeconds > 0) {
    return mvhdBox.durationInSeconds;
  }
  const tracks2 = getTracks(structure, parserState);
  const allTracks = [
    ...tracks2.videoTracks,
    ...tracks2.audioTracks,
    ...tracks2.otherTracks
  ];
  const allSamples = allTracks.map((t) => {
    const { timescale: ts } = t;
    const samplePositions = getSamplePositionsFromTrack(t.trakBox, moofBox);
    const highest = samplePositions?.map((sp) => (sp.cts + sp.duration) / ts).reduce((a, b) => Math.max(a, b), 0);
    return highest ?? 0;
  });
  const highestTimestamp = Math.max(...allSamples);
  return highestTimestamp;
};
var getDurationFromAvi = (structure) => {
  const strl = getStrlBoxes(structure);
  const lengths = [];
  for (const s of strl) {
    const strh = getStrhBox(s.children);
    if (!strh) {
      throw new Error("No strh box");
    }
    const samplesPerSecond = strh.rate / strh.scale;
    const streamLength = strh.length / samplesPerSecond;
    lengths.push(streamLength);
  }
  return Math.max(...lengths);
};
var getDuration = (structure, parserState) => {
  if (structure.type === "matroska") {
    return getDurationFromMatroska(structure.boxes);
  }
  if (structure.type === "iso-base-media") {
    return getDurationFromIsoBaseMedia(structure, parserState);
  }
  if (structure.type === "riff") {
    return getDurationFromAvi(structure);
  }
  if (structure.type === "transport-stream") {
    return null;
  }
  throw new Error("Has no duration " + structure);
};
var hasDuration = (structure, parserState) => {
  return hasTracks(structure, parserState);
};
var hasSlowDuration = (structure, parserState) => {
  try {
    return getDuration(structure, parserState) !== null;
  } catch {
    return false;
  }
};

// src/get-is-hdr.ts
var isVideoTrackHdr = (track) => {
  return track.color.matrixCoefficients === "bt2020" && track.color.transferCharacteristics === "arib-std-b67" && track.color.primaries === "bt2020";
};
var getIsHdr = (boxes, state) => {
  const { videoTracks } = getTracks(boxes, state);
  return videoTracks.some((track) => isVideoTrackHdr(track));
};
var hasHdr = (boxes, state) => {
  return hasTracks(boxes, state);
};

// src/boxes/iso-base-media/get-keyframes.ts
var getKeyframesFromIsoBaseMedia = (structure) => {
  const { videoTracks } = getTracksFromIsoBaseMedia(structure.boxes);
  const moofBox = getMoofBox(structure.boxes);
  const allSamples = videoTracks.map((t) => {
    const { timescale: ts } = t;
    const samplePositions = getSamplePositionsFromTrack(t.trakBox, moofBox);
    const keyframes = samplePositions.filter((k) => {
      return k.isKeyframe;
    }).map((k) => {
      return {
        trackId: t.trackId,
        presentationTimeInSeconds: k.cts / ts,
        decodingTimeInSeconds: k.dts / ts,
        positionInBytes: k.offset,
        sizeInBytes: k.size
      };
    });
    return keyframes;
  });
  return allSamples.flat();
};

// src/get-keyframes.ts
var getKeyframes = (structure) => {
  if (structure.type === "iso-base-media") {
    return getKeyframesFromIsoBaseMedia(structure);
  }
  return null;
};
var hasKeyframes = (structure, parserState) => {
  if (structure.type === "iso-base-media") {
    return hasTracks(structure, parserState);
  }
  return true;
};

// src/may-skip-video-data/need-samples-for-fields.ts
var needsSamples = {
  slowDurationInSeconds: true,
  slowFps: true,
  slowKeyframes: true,
  slowNumberOfFrames: true,
  audioCodec: false,
  container: false,
  dimensions: false,
  durationInSeconds: false,
  fps: false,
  internalStats: false,
  isHdr: false,
  name: false,
  rotation: false,
  size: false,
  structure: false,
  tracks: false,
  unrotatedDimensions: false,
  videoCodec: false,
  metadata: false,
  location: false,
  mimeType: false,
  keyframes: false
};
var needsToIterateOverSamples = ({
  fields,
  emittedFields
}) => {
  const keys = Object.keys(fields ?? {});
  const selectedKeys = keys.filter((k) => fields[k]);
  return selectedKeys.some((k) => needsSamples[k] && !emittedFields[k]);
};

// src/may-skip-video-data/may-skip-video-data.ts
var maySkipVideoData = ({ state }) => {
  return state.callbacks.tracks.hasAllTracks() && Object.values(state.callbacks.videoSampleCallbacks).length === 0 && Object.values(state.callbacks.audioSampleCallbacks).length === 0 && !needsToIterateOverSamples({
    emittedFields: state.emittedFields,
    fields: state.fields
  });
};

// src/has-all-info.ts
var getAvailableInfo = ({
  fieldsToFetch,
  state
}) => {
  const keys = Object.entries(fieldsToFetch).filter(([, value]) => value);
  const structure = state.structure.getStructureOrNull();
  const infos = keys.map(([_key]) => {
    const key = _key;
    if (key === "structure") {
      return false;
    }
    if (key === "durationInSeconds") {
      return Boolean(structure && hasDuration(structure, state));
    }
    if (key === "slowDurationInSeconds") {
      return Boolean(structure && hasSlowDuration(structure, state));
    }
    if (key === "dimensions" || key === "rotation" || key === "unrotatedDimensions") {
      return Boolean(structure && hasDimensions(structure, state));
    }
    if (key === "fps") {
      return Boolean(structure && hasFps(structure));
    }
    if (key === "slowFps") {
      return Boolean(structure && hasFpsSuitedForSlowFps(structure));
    }
    if (key === "isHdr") {
      return Boolean(structure && hasHdr(structure, state));
    }
    if (key === "videoCodec") {
      return Boolean(structure && hasVideoCodec(structure, state));
    }
    if (key === "audioCodec") {
      return Boolean(structure && hasAudioCodec(structure, state));
    }
    if (key === "tracks") {
      return Boolean(structure && hasTracks(structure, state));
    }
    if (key === "keyframes") {
      return Boolean(structure && hasKeyframes(structure, state));
    }
    if (key === "internalStats") {
      return true;
    }
    if (key === "size") {
      return true;
    }
    if (key === "mimeType") {
      return true;
    }
    if (key === "name") {
      return true;
    }
    if (key === "container") {
      return Boolean(structure && hasContainer(structure));
    }
    if (key === "metadata" || key === "location") {
      return false;
    }
    if (key === "slowKeyframes") {
      return false;
    }
    if (key === "slowNumberOfFrames") {
      return false;
    }
    throw new Error(`Unknown key: ${key}`);
  });
  const entries = [];
  let i = 0;
  for (const [key] of keys) {
    entries.push([key, infos[i++]]);
  }
  return Object.fromEntries(entries);
};
var hasAllInfo = ({
  fields,
  state
}) => {
  const availableInfo = getAvailableInfo({
    fieldsToFetch: fields ?? {},
    state
  });
  return Object.values(availableInfo).every(Boolean) && (maySkipVideoData({ state }) || state.callbacks.canSkipTracksState.canSkipTracks());
};

// src/register-track.ts
var registerTrack = async ({
  state,
  track,
  container
}) => {
  if (track.type === "video") {
    state.callbacks.tracks.addTrack(track);
    if (state.onVideoTrack) {
      const callback = await state.onVideoTrack({ track, container });
      await state.callbacks.registerVideoSampleCallback(track.trackId, callback ?? null);
    }
  }
  if (track.type === "audio") {
    state.callbacks.tracks.addTrack(track);
    if (state.onAudioTrack) {
      const callback = await state.onAudioTrack({ track, container });
      await state.callbacks.registerAudioSampleCallback(track.trackId, callback ?? null);
    }
  }
};
var registerVideoTrackWhenProfileIsAvailable = ({
  state,
  track,
  container
}) => {
  state.riff.registerOnAvcProfileCallback(async (profile) => {
    await registerTrack({
      state,
      track: addAvcProfileToTrack(track, profile),
      container
    });
  });
};

// src/boxes/iso-base-media/esds/decoder-specific-config.ts
var parseDecoderSpecificConfig = (iterator) => {
  const layerTag = iterator.getUint8();
  const layerSize = iterator.getPaddedFourByteNumber();
  const start = iterator.counter.getOffset();
  if (layerTag !== 5) {
    iterator.discard(layerSize);
    return {
      type: "unknown-decoder-specific-config"
    };
  }
  const bytes = iterator.getSlice(layerSize);
  iterator.counter.decrement(layerSize);
  iterator.startReadingBits();
  const audioObjectType = iterator.getBits(5);
  const samplingFrequencyIndex = iterator.getBits(4);
  if (samplingFrequencyIndex === 15) {
    iterator.getBits(24);
  }
  const channelConfiguration = iterator.getBits(4);
  iterator.stopReadingBits();
  const read = iterator.counter.getOffset() - start;
  if (read < layerSize) {
    iterator.discard(layerSize - read);
  }
  return {
    type: "mp4a-specific-config",
    audioObjectType,
    samplingFrequencyIndex,
    channelConfiguration,
    asBytes: bytes
  };
};

// src/boxes/iso-base-media/esds/esds-descriptors.ts
var mapToObjectAudioIndicator = (num) => {
  if (num === 64) {
    return "aac";
  }
  if (num === 107) {
    return "mp3";
  }
  return "unknown";
};
var processDescriptor = ({
  iterator
}) => {
  const tag = iterator.getUint8();
  if (tag === 4) {
    const size = iterator.getPaddedFourByteNumber();
    const initialOffset = iterator.counter.getOffset();
    const objectTypeIndication = iterator.getUint8();
    iterator.startReadingBits();
    const streamType = iterator.getBits(6);
    const upStream = iterator.getBits(1);
    iterator.getBits(1);
    const bufferSizeDB = iterator.getBits(24);
    iterator.stopReadingBits();
    const maxBitrate = iterator.getUint32();
    const avgBitrate = iterator.getUint32();
    const decoderSpecificConfigs = [];
    while (size - (iterator.counter.getOffset() - initialOffset) > 0) {
      const decoderSpecificConfig = parseDecoderSpecificConfig(iterator);
      decoderSpecificConfigs.push(decoderSpecificConfig);
    }
    return {
      descriptor: {
        type: "decoder-config-descriptor",
        objectTypeIndication: mapToObjectAudioIndicator(objectTypeIndication),
        asNumber: objectTypeIndication,
        bufferSizeDB,
        streamType,
        upStream,
        avgBitrate,
        maxBitrate,
        decoderSpecificConfigs
      }
    };
  }
  if (tag === 6) {
    const size = iterator.getPaddedFourByteNumber();
    iterator.discard(size);
    return {
      descriptor: {
        type: "sl-config-descriptor"
      }
    };
  }
  return {
    descriptor: null
  };
};
var parseDescriptors = (iterator, maxBytes) => {
  const descriptors = [];
  const initialOffset = iterator.counter.getOffset();
  while (iterator.bytesRemaining() > 0 && iterator.counter.getOffset() - initialOffset < maxBytes) {
    const { descriptor } = processDescriptor({
      iterator
    });
    if (descriptor) {
      descriptors.push(descriptor);
    } else {
      break;
    }
  }
  return descriptors;
};

// src/boxes/iso-base-media/esds/esds.ts
var parseEsds = ({
  data,
  size,
  fileOffset
}) => {
  const version = data.getUint8();
  data.discard(3);
  const tag = data.getUint8();
  const sizeOfInstance = data.getPaddedFourByteNumber();
  const esId = data.getUint16();
  data.discard(1);
  const remaining = size - (data.counter.getOffset() - fileOffset);
  const descriptors = parseDescriptors(data, remaining);
  const remainingNow = size - (data.counter.getOffset() - fileOffset);
  data.discard(remainingNow);
  return {
    type: "esds-box",
    version,
    tag,
    sizeOfInstance,
    esId,
    descriptors
  };
};

// src/convert-audio-or-video-sample.ts
var convertAudioOrVideoSampleToWebCodecsTimestamps = (sample, timescale) => {
  const { cts, dts, timestamp } = sample;
  return {
    cts: cts * 1e6 / timescale,
    dts: dts * 1e6 / timescale,
    timestamp: timestamp * 1e6 / timescale,
    duration: sample.duration === undefined ? undefined : sample.duration * 1e6 / timescale,
    data: sample.data,
    trackId: sample.trackId,
    type: sample.type,
    offset: sample.offset,
    timescale: 1e6
  };
};

// src/boxes/iso-base-media/mdat/mdat.ts
var parseMdat = async ({
  data,
  size,
  fileOffset,
  existingBoxes,
  state,
  signal,
  maySkipSampleProcessing
}) => {
  const alreadyHas = hasTracks({
    type: "iso-base-media",
    boxes: existingBoxes
  }, state);
  if (!alreadyHas) {
    if (maySkipSampleProcessing) {
      data.discard(size - (data.counter.getOffset() - fileOffset));
      return Promise.resolve({
        type: "mdat-box",
        boxSize: size,
        status: "samples-skipped",
        fileOffset
      });
    }
    data.discard(size - (data.counter.getOffset() - fileOffset));
    data.disallowDiscard();
    return Promise.resolve({
      type: "mdat-box",
      boxSize: size,
      status: "samples-buffered",
      fileOffset
    });
  }
  const tracks2 = getTracks({ type: "iso-base-media", boxes: existingBoxes }, state);
  const allTracks = [
    ...tracks2.videoTracks,
    ...tracks2.audioTracks,
    ...tracks2.otherTracks
  ];
  const flatSamples = allTracks.map((track) => {
    const samplePositions = getSamplePositionsFromTrack(track.trakBox, getMoofBox(existingBoxes));
    if (!samplePositions) {
      throw new Error("No sample positions");
    }
    return samplePositions.map((samplePosition) => {
      return {
        track: { ...track },
        samplePosition
      };
    });
  }).flat(1);
  while (true) {
    if (signal && signal.aborted) {
      break;
    }
    const samplesWithIndex = flatSamples.find((sample) => {
      return sample.samplePosition.offset === data.counter.getOffset();
    });
    if (!samplesWithIndex) {
      const nextSample_ = flatSamples.filter((s) => s.samplePosition.offset > data.counter.getOffset()).sort((a, b) => a.samplePosition.offset - b.samplePosition.offset)[0];
      if (nextSample_) {
        data.discard(nextSample_.samplePosition.offset - data.counter.getOffset());
        continue;
      } else {
        const bytesRemaining = size + fileOffset - data.counter.getOffset();
        data.discard(bytesRemaining);
        break;
      }
    }
    if (data.bytesRemaining() < samplesWithIndex.samplePosition.size) {
      break;
    }
    const bytes = data.getSlice(samplesWithIndex.samplePosition.size);
    const { cts, dts, duration: duration2, isKeyframe, offset } = samplesWithIndex.samplePosition;
    if (samplesWithIndex.track.type === "audio") {
      await state.callbacks.onAudioSample(samplesWithIndex.track.trackId, convertAudioOrVideoSampleToWebCodecsTimestamps({
        data: bytes,
        timestamp: cts,
        duration: duration2,
        cts,
        dts,
        trackId: samplesWithIndex.track.trackId,
        type: isKeyframe ? "key" : "delta",
        offset,
        timescale: samplesWithIndex.track.timescale
      }, samplesWithIndex.track.timescale));
    }
    if (samplesWithIndex.track.type === "video") {
      const nalUnitType = bytes[4] & 31;
      let isRecoveryPoint = false;
      if (nalUnitType === 6) {
        const seiType = bytes[5];
        isRecoveryPoint = seiType === 6;
      }
      await state.callbacks.onVideoSample(samplesWithIndex.track.trackId, convertAudioOrVideoSampleToWebCodecsTimestamps({
        data: bytes,
        timestamp: cts,
        duration: duration2,
        cts,
        dts,
        trackId: samplesWithIndex.track.trackId,
        type: isKeyframe && !isRecoveryPoint ? "key" : "delta",
        offset,
        timescale: samplesWithIndex.track.timescale
      }, samplesWithIndex.track.timescale));
    }
    const remaining = size - (data.counter.getOffset() - fileOffset);
    data.removeBytesRead();
    if (remaining === 0) {
      break;
    }
  }
  return Promise.resolve({
    type: "mdat-box",
    boxSize: size,
    status: "samples-processed",
    fileOffset
  });
};

// src/boxes/iso-base-media/mdhd.ts
var parseMdhd = ({
  data,
  size,
  fileOffset
}) => {
  const version = data.getUint8();
  data.discard(3);
  const creationTime = version === 1 ? Number(data.getUint64()) : data.getUint32();
  const modificationTime = version === 1 ? Number(data.getUint64()) : data.getUint32();
  const timescale = data.getUint32();
  const duration2 = version === 1 ? data.getUint64() : data.getUint32();
  const language2 = data.getUint16();
  const quality = data.getUint16();
  const remaining = size - (data.counter.getOffset() - fileOffset);
  if (remaining !== 0) {
    throw new Error(`Expected remaining bytes to be 0, got ${remaining}`);
  }
  return {
    type: "mdhd-box",
    duration: Number(duration2),
    timescale,
    version,
    language: language2,
    quality,
    creationTime,
    modificationTime
  };
};

// src/boxes/iso-base-media/meta/hdlr.ts
var parseHdlr = ({
  iterator,
  size,
  offset
}) => {
  const box = iterator.startBox(size - 8);
  const version = iterator.getUint8();
  if (version !== 0) {
    throw new Error(`Unsupported hdlr version: ${version}`);
  }
  iterator.discard(3);
  iterator.discard(4);
  const hdlrType = iterator.getByteString(4, false);
  iterator.discard(4);
  iterator.discard(4);
  iterator.discard(4);
  const componentName = iterator.readUntilNullTerminator();
  box.discardRest();
  return Promise.resolve({
    type: "hdlr-box",
    boxSize: size,
    offset,
    hdlrType,
    componentName
  });
};

// src/boxes/iso-base-media/meta/ilst.ts
var parseFromWellKnownType = (wellKnownType, iterator, size) => {
  if (wellKnownType === 1) {
    const value = iterator.getByteString(size, false);
    return { type: "text", value };
  }
  if (wellKnownType === 21) {
    if (size === 1) {
      return { type: "number", value: iterator.getInt8() };
    }
    if (size === 2) {
      return { type: "number", value: iterator.getInt16() };
    }
    if (size === 3) {
      return { type: "number", value: iterator.getInt24() };
    }
    if (size === 4) {
      return { type: "number", value: iterator.getInt32() };
    }
    if (size === 8) {
      return { type: "number", value: Number(iterator.getInt64()) };
    }
    throw new Error(`Weird size for number ${size}`);
  }
  if (wellKnownType === 22) {
    if (size === 1) {
      return { type: "number", value: iterator.getUint8() };
    }
    if (size === 2) {
      return { type: "number", value: iterator.getUint16() };
    }
    if (size === 3) {
      return { type: "number", value: iterator.getUint24() };
    }
    if (size === 4) {
      return { type: "number", value: iterator.getUint32() };
    }
    throw new Error(`Weird size for number ${size}`);
  }
  if (wellKnownType === 23) {
    if (size === 4) {
      return { type: "number", value: iterator.getFloat32() };
    }
    if (size === 8) {
      return { type: "number", value: iterator.getFloat64() };
    }
    throw new Error(`Weird size for number ${size}`);
  }
  iterator.discard(size);
  return { type: "unknown", value: null };
};
var parseIlstBox = ({
  iterator,
  size,
  offset
}) => {
  const box = iterator.startBox(size - 8);
  const entries = [];
  while (iterator.counter.getOffset() < size + offset) {
    const metadataSize = iterator.getUint32();
    const index = iterator.getUint32();
    if (index === 1936419184) {
      iterator.discard(metadataSize - 8);
      continue;
    }
    const innerSize = iterator.getUint32();
    const type = iterator.getAtom();
    const typeIndicator = iterator.getUint8();
    if (typeIndicator !== 0) {
      throw new Error("Expected type indicator to be 0");
    }
    const wellKnownType = iterator.getUint24();
    iterator.discard(4);
    const value = parseFromWellKnownType(wellKnownType, iterator, innerSize - 16);
    entries.push({ index, type, wellKnownType, value });
  }
  box.discardRest();
  return {
    type: "ilst-box",
    boxSize: size,
    offset,
    entries
  };
};

// src/boxes/iso-base-media/moov/moov.ts
var parseMoov = async ({
  iterator,
  offset,
  size,
  state,
  signal,
  logLevel,
  fields
}) => {
  const boxes = [];
  const children = await parseIsoBaseMediaBoxes({
    iterator,
    maxBytes: size - (iterator.counter.getOffset() - offset),
    allowIncompleteBoxes: false,
    initialBoxes: boxes,
    state,
    continueMdat: false,
    signal,
    logLevel,
    fields
  });
  if (children.status === "incomplete") {
    throw new Error("Incomplete boxes are not allowed");
  }
  return {
    offset,
    boxSize: size,
    type: "moov-box",
    children: boxes
  };
};

// src/boxes/iso-base-media/stsd/av1c.ts
var parseAv1C = ({
  data,
  size
}) => {
  return {
    type: "av1C-box",
    privateData: data.getSlice(size - 8)
  };
};

// src/boxes/iso-base-media/stsd/avcc.ts
var parseAvcc = ({
  data,
  size
}) => {
  const confVersion = data.getUint8();
  if (confVersion !== 1) {
    throw new Error(`Unsupported AVCC version ${confVersion}`);
  }
  const profile = data.getUint8();
  const profileCompatibility = data.getUint8();
  const level = data.getUint8();
  const str = `${profile.toString(16).padStart(2, "0")}${profileCompatibility.toString(16).padStart(2, "0")}${level.toString(16).padStart(2, "0")}`;
  data.counter.decrement(4);
  const privateData = data.getSlice(size - 8);
  return {
    type: "avcc-box",
    privateData,
    configurationString: str
  };
};

// src/boxes/iso-base-media/parse-icc-profile.ts
var parseIccProfile = (data) => {
  const iterator = getArrayBufferIterator(data, Infinity);
  const size = iterator.getUint32();
  if (size !== data.length) {
    throw new Error("Invalid ICC profile size");
  }
  const preferredCMMType = iterator.getByteString(4, false);
  const profileVersion = iterator.getByteString(4, false);
  const profileDeviceClass = iterator.getByteString(4, false);
  const colorSpace = iterator.getByteString(4, false);
  const pcs = iterator.getByteString(4, false);
  const dateTime = iterator.getSlice(12);
  const signature = iterator.getByteString(4, false);
  if (signature !== "acsp") {
    throw new Error("Invalid ICC profile signature");
  }
  const primaryPlatform = iterator.getByteString(4, false);
  const profileFlags = iterator.getUint32();
  const deviceManufacturer = iterator.getByteString(4, false);
  const deviceModel = iterator.getByteString(4, false);
  const deviceAttributes = iterator.getUint64();
  const renderingIntent = iterator.getUint32();
  const pcsIlluminant1 = iterator.getUint32();
  const pcsIlluminant2 = iterator.getUint32();
  const pcsIlluminant3 = iterator.getUint32();
  const profileCreator = iterator.getByteString(4, false);
  const profileId = iterator.getByteString(16, false);
  iterator.discard(28);
  const tagCount = iterator.getUint32();
  const entries = [];
  for (let i = 0;i < tagCount; i++) {
    const entry = {
      tag: iterator.getByteString(4, false),
      offset: iterator.getUint32(),
      size: iterator.getUint32()
    };
    entries.push(entry);
  }
  let lastOffset = -1;
  let rXYZ = null;
  let gXYZ = null;
  let bXYZ = null;
  let whitePoint = null;
  for (const entry of entries) {
    const found = data.slice(entry.offset, entry.offset + entry.size);
    if (entry.tag === "rXYZ" || entry.tag === "gXYZ" || entry.tag === "bXYZ" || entry.tag === "wtpt") {
      const it = getArrayBufferIterator(found, Infinity);
      it.discard(4);
      const x = it.getInt32() / 65536;
      const y = it.getInt32() / 65536;
      const z = it.getInt32() / 65536;
      it.destroy();
      const point = { x, y, z };
      if (entry.tag === "rXYZ") {
        rXYZ = point;
      } else if (entry.tag === "gXYZ") {
        gXYZ = point;
      } else if (entry.tag === "bXYZ") {
        bXYZ = point;
      } else if (entry.tag === "wtpt") {
        whitePoint = point;
      }
    }
    if (lastOffset !== -1) {
      const bytesToAdvance = entry.offset - lastOffset;
      const bytesToGoBackwards = entry.size - bytesToAdvance;
      if (bytesToGoBackwards > 0) {
        iterator.counter.decrement(bytesToGoBackwards);
      }
    }
    lastOffset = entry.offset;
  }
  const profile = {
    size,
    preferredCMMType,
    profileVersion,
    profileDeviceClass,
    colorSpace,
    pcs,
    dateTime,
    signature,
    primaryPlatform,
    profileFlags,
    deviceManufacturer,
    deviceModel,
    deviceAttributes,
    renderingIntent,
    pcsIlluminant: [
      pcsIlluminant1 / 65536,
      pcsIlluminant2 / 65536,
      pcsIlluminant3 / 65536
    ],
    profileCreator,
    profileId,
    entries,
    bXYZ,
    gXYZ,
    rXYZ,
    whitePoint
  };
  iterator.destroy();
  return profile;
};

// src/boxes/iso-base-media/stsd/colr.ts
var parseColorParameterBox = ({
  iterator,
  size
}) => {
  const byteString = iterator.getByteString(4, false);
  if (byteString === "nclx") {
    const primaries2 = iterator.getUint16();
    const transfer = iterator.getUint16();
    const matrixIndex = iterator.getUint16();
    iterator.startReadingBits();
    const fullRangeFlag = Boolean(iterator.getBits(1));
    iterator.stopReadingBits();
    return {
      type: "colr-box",
      colorType: "transfer-characteristics",
      fullRangeFlag,
      matrixIndex,
      primaries: primaries2,
      transfer
    };
  }
  if (byteString === "nclc") {
    const primaries2 = iterator.getUint16();
    const transfer = iterator.getUint16();
    const matrixIndex = iterator.getUint16();
    return {
      type: "colr-box",
      colorType: "transfer-characteristics",
      fullRangeFlag: false,
      matrixIndex,
      primaries: primaries2,
      transfer
    };
  }
  if (byteString === "prof") {
    const profile = iterator.getSlice(size - 12);
    return {
      type: "colr-box",
      colorType: "icc-profile",
      profile,
      parsed: parseIccProfile(profile)
    };
  }
  throw new Error("Unexpected box type " + byteString);
};

// src/boxes/iso-base-media/stsd/ctts.ts
var parseCtts = ({
  iterator,
  offset,
  size
}) => {
  const version = iterator.getUint8();
  if (version !== 0 && version !== 1) {
    throw new Error(`Unsupported CTTS version ${version}`);
  }
  const flags = iterator.getSlice(3);
  const entryCount = iterator.getUint32();
  const entries = [];
  for (let i = 0;i < entryCount; i++) {
    const sampleCount = iterator.getUint32();
    const sampleOffset = iterator.getInt32();
    entries.push({
      sampleCount,
      sampleOffset
    });
  }
  return {
    type: "ctts-box",
    boxSize: size,
    offset,
    version,
    flags: [...flags],
    entryCount,
    entries
  };
};

// src/boxes/iso-base-media/stsd/hvcc.ts
var parseHvcc = ({
  data,
  size,
  offset
}) => {
  const privateData = data.getSlice(size - 8);
  data.counter.decrement(size - 8);
  const constraintString = getHvc1CodecString(data);
  const remaining = size - (data.counter.getOffset() - offset);
  data.discard(remaining);
  return {
    type: "hvcc-box",
    privateData,
    configurationString: constraintString
  };
};

// src/boxes/iso-base-media/stsd/keys.ts
var parseKeys = ({
  iterator,
  offset,
  size
}) => {
  const box = iterator.startBox(size - 8);
  const version = iterator.getUint8();
  iterator.discard(3);
  const entryCount = iterator.getUint32();
  const entries = [];
  for (let i = 0;i < entryCount; i++) {
    const keySize = iterator.getUint32();
    const namespace = iterator.getAtom();
    const value = iterator.getByteString(keySize - 8, false);
    const entry = {
      keySize,
      namespace,
      value
    };
    entries.push(entry);
  }
  box.discardRest();
  return {
    type: "keys-box",
    boxSize: size,
    offset,
    version,
    entryCount,
    entries
  };
};

// src/boxes/iso-base-media/stsd/mebx.ts
var parseMebx = async ({
  iterator,
  offset,
  size,
  state,
  signal,
  fields
}) => {
  iterator.discard(6);
  const dataReferenceIndex = iterator.getUint16();
  const boxes = [];
  const children = await parseIsoBaseMediaBoxes({
    iterator,
    maxBytes: iterator.counter.getOffset() - offset,
    allowIncompleteBoxes: false,
    initialBoxes: boxes,
    state,
    continueMdat: false,
    signal,
    logLevel: "info",
    fields
  });
  if (children.status === "incomplete") {
    throw new Error("Incomplete boxes are not allowed");
  }
  return {
    type: "mebx-box",
    boxSize: size,
    offset,
    dataReferenceIndex,
    format: "mebx",
    children: boxes
  };
};

// src/boxes/iso-base-media/stsd/pasp.ts
var parsePasp = ({
  iterator,
  offset,
  size
}) => {
  const hSpacing = iterator.getUint32();
  const vSpacing = iterator.getUint32();
  const bytesRemainingInBox = size - (iterator.counter.getOffset() - offset);
  iterator.discard(bytesRemainingInBox);
  return {
    type: "pasp-box",
    boxSize: size,
    offset,
    hSpacing,
    vSpacing
  };
};

// src/boxes/iso-base-media/stsd/stco.ts
var parseStco = ({
  iterator,
  offset,
  size,
  mode64Bit
}) => {
  const version = iterator.getUint8();
  if (version !== 0) {
    throw new Error(`Unsupported STSD version ${version}`);
  }
  const flags = iterator.getSlice(3);
  const entryCount = iterator.getUint32();
  const entries = [];
  for (let i = 0;i < entryCount; i++) {
    const bytesRemaining = size - (iterator.counter.getOffset() - offset);
    if (bytesRemaining < 4) {
      break;
    }
    entries.push(mode64Bit ? iterator.getUint64() : iterator.getUint32());
  }
  iterator.discard(size - (iterator.counter.getOffset() - offset));
  return {
    type: "stco-box",
    boxSize: size,
    offset,
    version,
    flags: [...flags],
    entries,
    entryCount
  };
};

// src/boxes/iso-base-media/stsd/stsc.ts
var parseStsc = ({
  iterator,
  offset,
  size
}) => {
  const version = iterator.getUint8();
  if (version !== 0) {
    throw new Error(`Unsupported STSD version ${version}`);
  }
  const flags = iterator.getSlice(3);
  const entryCount = iterator.getUint32();
  const entries = [];
  for (let i = 0;i < entryCount; i++) {
    const firstChunk = iterator.getUint32();
    const samplesPerChunk = iterator.getUint32();
    const sampleDescriptionIndex = iterator.getUint32();
    if (sampleDescriptionIndex !== 1) {
      throw new Error(`Expected sampleDescriptionIndex to be 1, but got ${sampleDescriptionIndex}`);
    }
    entries.push({
      firstChunk,
      samplesPerChunk
    });
  }
  return {
    type: "stsc-box",
    boxSize: size,
    offset,
    version,
    flags: [...flags],
    entryCount,
    entries
  };
};

// src/boxes/iso-base-media/stsd/stsd.ts
var parseStsd = async ({
  iterator,
  offset,
  size,
  state,
  signal,
  fields
}) => {
  const version = iterator.getUint8();
  if (version !== 0) {
    throw new Error(`Unsupported STSD version ${version}`);
  }
  iterator.discard(3);
  const numberOfEntries = iterator.getUint32();
  const bytesRemainingInBox = size - (iterator.counter.getOffset() - offset);
  const boxes = await parseSamples({
    iterator,
    maxBytes: bytesRemainingInBox,
    state,
    signal,
    logLevel: "info",
    fields
  });
  if (boxes.length !== numberOfEntries) {
    throw new Error(`Expected ${numberOfEntries} sample descriptions, got ${boxes.length}`);
  }
  return {
    type: "stsd-box",
    boxSize: size,
    offset,
    numberOfEntries,
    samples: boxes
  };
};

// src/boxes/iso-base-media/stsd/stss.ts
var parseStss = ({
  iterator,
  offset,
  boxSize
}) => {
  const version = iterator.getUint8();
  if (version !== 0) {
    throw new Error(`Unsupported STSS version ${version}`);
  }
  const flags = iterator.getSlice(3);
  const sampleCount = iterator.getUint32();
  const sampleNumber = [];
  for (let i = 0;i < sampleCount; i++) {
    sampleNumber.push(iterator.getUint32());
  }
  const bytesRemainingInBox = boxSize - (iterator.counter.getOffset() - offset);
  if (bytesRemainingInBox > 0) {
    throw new Error(`Unexpected bytes remaining in box stss`);
  }
  return {
    type: "stss-box",
    version,
    flags: [...flags],
    sampleNumber,
    boxSize,
    offset
  };
};

// src/boxes/iso-base-media/stsd/stsz.ts
var parseStsz = ({
  iterator,
  offset,
  size
}) => {
  const version = iterator.getUint8();
  if (version !== 0) {
    throw new Error(`Unsupported STSD version ${version}`);
  }
  const flags = iterator.getSlice(3);
  const sampleSize = iterator.getUint32();
  const sampleCount = iterator.getUint32();
  if (sampleSize !== 0) {
    return {
      type: "stsz-box",
      boxSize: size,
      offset,
      version,
      flags: [...flags],
      sampleCount,
      countType: "fixed",
      sampleSize
    };
  }
  const samples = [];
  for (let i = 0;i < sampleCount; i++) {
    const bytesRemaining = size - (iterator.counter.getOffset() - offset);
    if (bytesRemaining < 4) {
      break;
    }
    samples.push(iterator.getUint32());
  }
  iterator.discard(size - (iterator.counter.getOffset() - offset));
  return {
    type: "stsz-box",
    boxSize: size,
    offset,
    version,
    flags: [...flags],
    sampleCount,
    countType: "variable",
    entries: samples
  };
};

// src/boxes/iso-base-media/stsd/stts.ts
var parseStts = ({
  data,
  size,
  fileOffset
}) => {
  const initialOffset = data.counter.getOffset();
  const initialCounter = initialOffset - fileOffset;
  const version = data.getUint8();
  if (version !== 0) {
    throw new Error(`Unsupported STTS version ${version}`);
  }
  data.discard(3);
  const entryCount = data.getUint32();
  const sampleDistributions = [];
  for (let i = 0;i < entryCount; i++) {
    const sampleCount = data.getUint32();
    const sampleDelta = data.getUint32();
    const sampleDistribution = {
      sampleCount,
      sampleDelta
    };
    sampleDistributions.push(sampleDistribution);
  }
  const bytesUsed = data.counter.getOffset() - initialOffset + initialCounter;
  if (bytesUsed !== size) {
    throw new Error(`Expected stts box to be ${size} bytes, but was ${bytesUsed} bytes`);
  }
  return {
    type: "stts-box",
    sampleDistribution: sampleDistributions
  };
};

// src/boxes/iso-base-media/tfdt.ts
var parseTfdt = ({
  iterator,
  size,
  offset
}) => {
  const version = iterator.getUint8();
  iterator.discard(3);
  const num = version === 0 ? iterator.getUint32() : Number(iterator.getUint64());
  const bytesRemaining = size - (iterator.counter.getOffset() - offset);
  if (bytesRemaining !== 0) {
    throw new Error("expected 0 bytes " + bytesRemaining);
  }
  return {
    type: "tfdt-box",
    version,
    baseMediaDecodeTime: num,
    offset
  };
};

// src/boxes/iso-base-media/tfhd.ts
var getTfhd = ({
  iterator,
  offset,
  size
}) => {
  const version = iterator.getUint8();
  const flags = iterator.getUint24();
  const trackId = iterator.getUint32();
  const baseDataOffsetPresent = flags & 1;
  const baseDataOffset = baseDataOffsetPresent ? Number(iterator.getUint64()) : 0;
  const baseSampleDescriptionIndexPresent = flags & 2;
  const baseSampleDescriptionIndex = baseSampleDescriptionIndexPresent ? iterator.getUint32() : 0;
  const defaultSampleDurationPresent = flags & 8;
  const defaultSampleDuration = defaultSampleDurationPresent ? iterator.getUint32() : 0;
  const defaultSampleSizePresent = flags & 16;
  const defaultSampleSize = defaultSampleSizePresent ? iterator.getUint32() : 0;
  const defaultSampleFlagsPresent = flags & 32;
  const defaultSampleFlags = defaultSampleFlagsPresent ? iterator.getUint32() : 0;
  const bytesRemaining = size - (iterator.counter.getOffset() - offset);
  if (bytesRemaining !== 0) {
    throw new Error("expected 0 bytes " + bytesRemaining);
  }
  return {
    type: "tfhd-box",
    version,
    trackId,
    baseDataOffset,
    baseSampleDescriptionIndex,
    defaultSampleDuration,
    defaultSampleSize,
    defaultSampleFlags
  };
};

// src/boxes/iso-base-media/tkhd.ts
function getRotationAngleFromMatrix(matrix) {
  const [a, b, c, d] = matrix;
  if (a === 0 && b === 0 && c === 0 && d === 0) {
    return 0;
  }
  if (Math.round(a * a + b * b) !== 1 || Math.round(c * c + d * d) !== 1) {
    throw new Error("The provided matrix is not a valid rotation matrix.");
  }
  const angleRadians = Math.atan2(c, a);
  const angleDegrees = angleRadians * (180 / Math.PI);
  return angleDegrees;
}
var applyRotation = ({
  matrix,
  width,
  height
}) => {
  const newWidth = matrix[0] * width + matrix[1] * height;
  const newHeight = matrix[2] * width + matrix[3] * height;
  return {
    width: Math.abs(newWidth),
    height: Math.abs(newHeight)
  };
};
var parseTkhd = ({
  iterator,
  offset,
  size
}) => {
  const version = iterator.getUint8();
  iterator.discard(3);
  const creationTime = version === 1 ? iterator.getUint64() : iterator.getUint32();
  const modificationTime = version === 1 ? iterator.getUint64() : iterator.getUint32();
  const trackId = iterator.getUint32();
  iterator.discard(4);
  const duration2 = version === 1 ? iterator.getUint64() : iterator.getUint32();
  iterator.discard(4);
  iterator.discard(4);
  const layer = iterator.getUint16();
  const alternateGroup = iterator.getUint16();
  const volume = iterator.getUint16();
  iterator.discard(2);
  const matrix = [
    iterator.getFixedPointSigned1616Number(),
    iterator.getFixedPointSigned1616Number(),
    iterator.getFixedPointSigned230Number(),
    iterator.getFixedPointSigned1616Number(),
    iterator.getFixedPointSigned1616Number(),
    iterator.getFixedPointSigned230Number(),
    iterator.getFixedPointSigned1616Number(),
    iterator.getFixedPointSigned1616Number(),
    iterator.getFixedPointSigned230Number()
  ];
  const rotationMatrix = [matrix[0], matrix[1], matrix[3], matrix[4]];
  const widthWithoutRotationApplied = iterator.getFixedPointUnsigned1616Number();
  const heightWithoutRotationApplied = iterator.getFixedPointSigned1616Number();
  const { width, height } = applyRotation({
    matrix: rotationMatrix,
    width: widthWithoutRotationApplied,
    height: heightWithoutRotationApplied
  });
  const rotation = getRotationAngleFromMatrix(rotationMatrix);
  return {
    offset,
    boxSize: size,
    type: "tkhd-box",
    creationTime: toUnixTimestamp(Number(creationTime)),
    modificationTime: toUnixTimestamp(Number(modificationTime)),
    trackId,
    duration: Number(duration2),
    layer,
    alternateGroup,
    volume,
    matrix,
    width,
    height,
    version,
    rotation,
    unrotatedWidth: widthWithoutRotationApplied,
    unrotatedHeight: heightWithoutRotationApplied
  };
};

// src/boxes/iso-base-media/trak/trak.ts
var parseTrak = async ({
  data,
  size,
  offsetAtStart,
  state: options,
  signal,
  logLevel,
  fields
}) => {
  const initialBoxes = [];
  const result = await parseIsoBaseMediaBoxes({
    iterator: data,
    maxBytes: size - (data.counter.getOffset() - offsetAtStart),
    allowIncompleteBoxes: false,
    initialBoxes,
    state: options,
    continueMdat: false,
    signal,
    logLevel,
    fields
  });
  if (result.status === "incomplete") {
    throw new Error("Incomplete boxes are not allowed");
  }
  return {
    offset: offsetAtStart,
    boxSize: size,
    type: "trak-box",
    children: initialBoxes
  };
};

// src/boxes/iso-base-media/trun.ts
var parseTrun = ({
  iterator,
  offset,
  size
}) => {
  const version = iterator.getUint8();
  if (version !== 0) {
    throw new Error(`Unsupported TRUN version ${version}`);
  }
  const flags = iterator.getUint24();
  const sampleCount = iterator.getUint32();
  const dataOffset = flags & 1 ? iterator.getInt32() : null;
  const firstSampleFlags = flags & 4 ? iterator.getUint32() : null;
  const samples = [];
  for (let i = 0;i < sampleCount; i++) {
    const sampleDuration = flags & 256 ? iterator.getUint32() : null;
    const sampleSize = flags & 512 ? iterator.getUint32() : null;
    const sampleFlags = flags & 1024 ? iterator.getUint32() : null;
    const sampleCompositionTimeOffset = flags & 2048 ? version === 0 ? iterator.getUint32() : iterator.getInt32Le() : null;
    samples.push({
      sampleDuration,
      sampleSize,
      sampleFlags,
      sampleCompositionTimeOffset
    });
  }
  const currentOffset = iterator.counter.getOffset();
  const left = size - (currentOffset - offset);
  if (left !== 0) {
    throw new Error(`Unexpected data left in TRUN box: ${left}`);
  }
  return {
    type: "trun-box",
    version,
    sampleCount,
    dataOffset,
    firstSampleFlags,
    samples
  };
};

// src/boxes/iso-base-media/process-box.ts
var getChildren = async ({
  boxType,
  iterator,
  bytesRemainingInBox,
  state,
  signal,
  logLevel,
  fields
}) => {
  const parseChildren = boxType === "mdia" || boxType === "minf" || boxType === "stbl" || boxType === "udta" || boxType === "moof" || boxType === "dims" || boxType === "meta" || boxType === "wave" || boxType === "traf" || boxType === "stsb";
  if (parseChildren) {
    const boxes = [];
    const parsed = await parseIsoBaseMediaBoxes({
      iterator,
      maxBytes: bytesRemainingInBox,
      allowIncompleteBoxes: false,
      initialBoxes: boxes,
      state,
      continueMdat: false,
      signal,
      logLevel,
      fields
    });
    if (parsed.status === "incomplete") {
      throw new Error("Incomplete boxes are not allowed");
    }
    return boxes;
  }
  if (bytesRemainingInBox < 0) {
    throw new Error("Box size is too big " + JSON.stringify({ boxType }));
  }
  iterator.discard(bytesRemainingInBox);
  return [];
};
var parseMdatPartially = async ({
  iterator,
  boxSize,
  fileOffset,
  parsedBoxes,
  state,
  signal
}) => {
  const box = await parseMdat({
    data: iterator,
    size: boxSize,
    fileOffset,
    existingBoxes: parsedBoxes,
    state,
    signal,
    maySkipSampleProcessing: state.supportsContentRange
  });
  if ((box.status === "samples-processed" || box.status === "samples-buffered") && box.fileOffset + boxSize === iterator.counter.getOffset()) {
    return {
      type: "complete",
      box,
      size: boxSize,
      skipTo: null
    };
  }
  return {
    type: "partial-mdat-box",
    boxSize,
    fileOffset
  };
};
var processBox = async ({
  iterator,
  allowIncompleteBoxes,
  parsedBoxes,
  state,
  signal,
  logLevel,
  fields
}) => {
  const fileOffset = iterator.counter.getOffset();
  const bytesRemaining = iterator.bytesRemaining();
  const boxSizeRaw = iterator.getFourByteNumber();
  if (boxSizeRaw === 1 && iterator.bytesRemaining() < 12 || iterator.bytesRemaining() < 4) {
    iterator.counter.decrement(iterator.counter.getOffset() - fileOffset);
    if (allowIncompleteBoxes) {
      return {
        type: "incomplete"
      };
    }
    throw new Error(`Expected box size of ${bytesRemaining}, got ${boxSizeRaw}. Incomplete boxes are not allowed.`);
  }
  if (boxSizeRaw === 0) {
    return {
      type: "complete",
      box: {
        type: "void-box",
        boxSize: 0
      },
      size: 4,
      skipTo: null
    };
  }
  const boxType = iterator.getByteString(4, false);
  const boxSize = boxSizeRaw === 1 ? iterator.getEightByteNumber() : boxSizeRaw;
  if (bytesRemaining < boxSize) {
    if (boxType === "mdat") {
      const shouldSkip = maySkipVideoData({ state }) || !hasTracks({ type: "iso-base-media", boxes: parsedBoxes }, state) && state.supportsContentRange;
      if (shouldSkip) {
        const skipTo = fileOffset + boxSize;
        const bytesToSkip = skipTo - iterator.counter.getOffset();
        if (bytesToSkip > 1e6) {
          return {
            type: "complete",
            box: {
              type: "mdat-box",
              boxSize,
              fileOffset,
              status: "samples-skipped"
            },
            size: boxSize,
            skipTo: fileOffset + boxSize
          };
        }
      } else {
        return parseMdatPartially({
          iterator,
          boxSize,
          fileOffset,
          parsedBoxes,
          state,
          signal
        });
      }
    }
    iterator.counter.decrement(iterator.counter.getOffset() - fileOffset);
    if (allowIncompleteBoxes) {
      return {
        type: "incomplete"
      };
    }
    throw new Error(`Expected box size of ${bytesRemaining}, got ${boxSize}. Incomplete boxes are not allowed.`);
  }
  if (boxType === "ftyp") {
    const box = parseFtyp({ iterator, size: boxSize, offset: fileOffset });
    return {
      type: "complete",
      box,
      size: boxSize,
      skipTo: null
    };
  }
  if (boxType === "colr") {
    const box = parseColorParameterBox({
      iterator,
      size: boxSize
    });
    return {
      type: "complete",
      box,
      size: boxSize,
      skipTo: null
    };
  }
  if (boxType === "mvhd") {
    const box = parseMvhd({ iterator, offset: fileOffset, size: boxSize });
    return {
      type: "complete",
      box,
      size: boxSize,
      skipTo: null
    };
  }
  if (boxType === "tkhd") {
    const box = parseTkhd({ iterator, offset: fileOffset, size: boxSize });
    return {
      type: "complete",
      box,
      size: boxSize,
      skipTo: null
    };
  }
  if (boxType === "trun") {
    const box = parseTrun({ iterator, offset: fileOffset, size: boxSize });
    return {
      type: "complete",
      box,
      size: boxSize,
      skipTo: null
    };
  }
  if (boxType === "tfdt") {
    const box = parseTfdt({ iterator, size: boxSize, offset: fileOffset });
    return {
      type: "complete",
      box,
      size: boxSize,
      skipTo: null
    };
  }
  if (boxType === "stsd") {
    const box = await parseStsd({
      iterator,
      offset: fileOffset,
      size: boxSize,
      state,
      signal,
      fields
    });
    return {
      type: "complete",
      box,
      size: boxSize,
      skipTo: null
    };
  }
  if (boxType === "stsz") {
    const box = parseStsz({
      iterator,
      offset: fileOffset,
      size: boxSize
    });
    return {
      type: "complete",
      box,
      size: boxSize,
      skipTo: null
    };
  }
  if (boxType === "stco" || boxType === "co64") {
    const box = parseStco({
      iterator,
      offset: fileOffset,
      size: boxSize,
      mode64Bit: boxType === "co64"
    });
    return {
      type: "complete",
      box,
      size: boxSize,
      skipTo: null
    };
  }
  if (boxType === "pasp") {
    const box = parsePasp({
      iterator,
      offset: fileOffset,
      size: boxSize
    });
    return {
      type: "complete",
      box,
      size: boxSize,
      skipTo: null
    };
  }
  if (boxType === "stss") {
    const box = parseStss({
      iterator,
      offset: fileOffset,
      boxSize
    });
    return {
      type: "complete",
      box,
      size: boxSize,
      skipTo: null
    };
  }
  if (boxType === "ctts") {
    const box = parseCtts({
      iterator,
      offset: fileOffset,
      size: boxSize
    });
    return {
      type: "complete",
      box,
      size: boxSize,
      skipTo: null
    };
  }
  if (boxType === "stsc") {
    const box = parseStsc({
      iterator,
      offset: fileOffset,
      size: boxSize
    });
    return {
      type: "complete",
      box,
      size: boxSize,
      skipTo: null
    };
  }
  if (boxType === "mebx") {
    const box = await parseMebx({
      iterator,
      offset: fileOffset,
      size: boxSize,
      state,
      signal,
      fields
    });
    return {
      type: "complete",
      box,
      size: boxSize,
      skipTo: null
    };
  }
  if (boxType === "hdlr") {
    const box = await parseHdlr({ iterator, size: boxSize, offset: fileOffset });
    return {
      type: "complete",
      box,
      size: boxSize,
      skipTo: null
    };
  }
  if (boxType === "keys") {
    const box = parseKeys({ iterator, size: boxSize, offset: fileOffset });
    return {
      type: "complete",
      box,
      size: boxSize,
      skipTo: null
    };
  }
  if (boxType === "ilst") {
    const box = parseIlstBox({
      iterator,
      offset: fileOffset,
      size: boxSize
    });
    return {
      type: "complete",
      box,
      size: boxSize,
      skipTo: null
    };
  }
  if (boxType === "moov") {
    const box = await parseMoov({
      iterator,
      offset: fileOffset,
      size: boxSize,
      state,
      signal,
      logLevel,
      fields
    });
    state.callbacks.tracks.setIsDone();
    return {
      type: "complete",
      box,
      size: boxSize,
      skipTo: null
    };
  }
  if (boxType === "trak") {
    const box = await parseTrak({
      data: iterator,
      size: boxSize,
      offsetAtStart: fileOffset,
      state,
      signal,
      logLevel,
      fields
    });
    const transformedTrack = makeBaseMediaTrack(box);
    if (transformedTrack) {
      await registerTrack({
        state,
        track: transformedTrack,
        container: "mp4"
      });
    }
    return {
      type: "complete",
      box,
      size: boxSize,
      skipTo: null
    };
  }
  if (boxType === "stts") {
    const box = parseStts({
      data: iterator,
      size: boxSize,
      fileOffset
    });
    return {
      type: "complete",
      box,
      size: boxSize,
      skipTo: null
    };
  }
  if (boxType === "avcC") {
    const box = parseAvcc({
      data: iterator,
      size: boxSize
    });
    return {
      type: "complete",
      box,
      size: boxSize,
      skipTo: null
    };
  }
  if (boxType === "av1C") {
    const box = parseAv1C({
      data: iterator,
      size: boxSize
    });
    return {
      type: "complete",
      box,
      size: boxSize,
      skipTo: null
    };
  }
  if (boxType === "hvcC") {
    const box = parseHvcc({
      data: iterator,
      size: boxSize,
      offset: fileOffset
    });
    return {
      type: "complete",
      box,
      size: boxSize,
      skipTo: null
    };
  }
  if (boxType === "tfhd") {
    const box = getTfhd({
      iterator,
      offset: fileOffset,
      size: boxSize
    });
    return {
      type: "complete",
      box,
      size: boxSize,
      skipTo: null
    };
  }
  if (boxType === "mdhd") {
    const box = parseMdhd({
      data: iterator,
      size: boxSize,
      fileOffset
    });
    return {
      type: "complete",
      box,
      size: boxSize,
      skipTo: null
    };
  }
  if (boxType === "esds") {
    const box = parseEsds({
      data: iterator,
      size: boxSize,
      fileOffset
    });
    return {
      type: "complete",
      box,
      size: boxSize,
      skipTo: null
    };
  }
  if (boxType === "mdat") {
    const box = await parseMdat({
      data: iterator,
      size: boxSize,
      fileOffset,
      existingBoxes: parsedBoxes,
      state,
      signal,
      maySkipSampleProcessing: state.supportsContentRange
    });
    if (box === null) {
      throw new Error("Unexpected null");
    }
    return {
      type: "complete",
      box,
      size: boxSize,
      skipTo: null
    };
  }
  const bytesRemainingInBox = boxSize - (iterator.counter.getOffset() - fileOffset);
  const children = await getChildren({
    boxType,
    iterator,
    bytesRemainingInBox,
    state,
    signal,
    logLevel,
    fields
  });
  return {
    type: "complete",
    box: {
      type: "regular-box",
      boxType,
      boxSize,
      children,
      offset: fileOffset
    },
    size: boxSize,
    skipTo: null
  };
};
var parseIsoBaseMediaBoxes = async ({
  iterator,
  maxBytes,
  allowIncompleteBoxes,
  initialBoxes,
  state,
  continueMdat,
  signal,
  logLevel,
  fields
}) => {
  const initialOffset = iterator.counter.getOffset();
  const alreadyHasMdat = state.structure.getStructureOrNull()?.boxes.find((b) => b.type === "mdat-box");
  while (iterator.bytesRemaining() > 0 && iterator.counter.getOffset() - initialOffset < maxBytes) {
    const result = continueMdat ? await parseMdatPartially({
      iterator,
      boxSize: continueMdat.boxSize,
      fileOffset: continueMdat.fileOffset,
      parsedBoxes: initialBoxes,
      state,
      signal
    }) : await processBox({
      iterator,
      allowIncompleteBoxes,
      parsedBoxes: initialBoxes,
      state,
      signal,
      logLevel,
      fields
    });
    if (result.type === "incomplete") {
      if (Number.isFinite(maxBytes)) {
        throw new Error("maxBytes must be Infinity for top-level boxes");
      }
      return {
        status: "incomplete",
        continueParsing: () => {
          return parseIsoBaseMediaBoxes({
            iterator,
            maxBytes,
            allowIncompleteBoxes,
            initialBoxes,
            state,
            continueMdat: false,
            signal,
            logLevel,
            fields
          });
        },
        skipTo: null
      };
    }
    if (result.type === "partial-mdat-box") {
      return {
        status: "incomplete",
        continueParsing: () => {
          return Promise.resolve(parseIsoBaseMediaBoxes({
            iterator,
            maxBytes,
            allowIncompleteBoxes,
            initialBoxes,
            state,
            continueMdat: result,
            signal,
            logLevel,
            fields
          }));
        },
        skipTo: null
      };
    }
    if (result.box.type === "mdat-box" && alreadyHasMdat) {
      initialBoxes = initialBoxes.filter((b) => b.type !== "mdat-box");
      initialBoxes.push(result.box);
      iterator.allowDiscard();
      break;
    } else {
      initialBoxes.push(result.box);
      if (hasAllInfo({ fields, state })) {
        return {
          status: "done"
        };
      }
    }
    if (result.skipTo !== null) {
      if (!state.supportsContentRange) {
        throw new Error("Content-Range header is not supported by the reader, but was asked to seek");
      }
      return {
        status: "incomplete",
        continueParsing: () => {
          return parseIsoBaseMediaBoxes({
            iterator,
            maxBytes,
            allowIncompleteBoxes,
            initialBoxes,
            state,
            continueMdat: false,
            signal,
            logLevel,
            fields
          });
        },
        skipTo: result.skipTo
      };
    }
    if (iterator.bytesRemaining() < 0) {
      return {
        status: "incomplete",
        continueParsing: () => {
          return parseIsoBaseMediaBoxes({
            iterator,
            maxBytes,
            allowIncompleteBoxes,
            initialBoxes,
            state,
            continueMdat: false,
            signal,
            logLevel,
            fields
          });
        },
        skipTo: null
      };
    }
    iterator.removeBytesRead();
  }
  const mdatState = getMdatBox(initialBoxes);
  const skipped = mdatState?.status === "samples-skipped" && !maySkipVideoData({ state }) && state.supportsContentRange;
  const buffered = mdatState?.status === "samples-buffered" && !maySkipVideoData({ state });
  if (skipped || buffered) {
    return {
      status: "incomplete",
      continueParsing: () => {
        if (buffered) {
          iterator.skipTo(mdatState.fileOffset, false);
        }
        return parseIsoBaseMediaBoxes({
          iterator,
          maxBytes,
          allowIncompleteBoxes: false,
          initialBoxes,
          state,
          continueMdat: false,
          signal,
          logLevel,
          fields
        });
      },
      skipTo: skipped ? mdatState.fileOffset : null
    };
  }
  return {
    status: "done"
  };
};

// src/boxes/iso-base-media/stsd/samples.ts
var videoTags = [
  "cvid",
  "jpeg",
  "smc ",
  "rle ",
  "rpza",
  "kpcd",
  "png ",
  "mjpa",
  "mjpb",
  "SVQ1",
  "SVQ3",
  "mp4v",
  "avc1",
  "dvc ",
  "dvcp",
  "gif ",
  "h263",
  "tiff",
  "raw ",
  "2vuY",
  "yuv2",
  "v308",
  "v408",
  "v216",
  "v410",
  "v210",
  "hvc1",
  "ap4h",
  "av01"
];
var audioTags = [
  0,
  "NONE",
  "raw ",
  "twos",
  "sowt",
  "MAC3 ",
  "MAC6 ",
  "ima4",
  "fl32",
  "lpcm",
  "fl64",
  "in24",
  "in32",
  "ulaw",
  "alaw",
  1836253186,
  1836253201,
  "dvca",
  "QDMC",
  "QDM2",
  "Qclp",
  1836253269,
  ".mp3",
  "mp4a",
  "ac-3"
];
var processSample = async ({
  iterator,
  state: options,
  signal,
  logLevel,
  fields
}) => {
  const fileOffset = iterator.counter.getOffset();
  const bytesRemaining = iterator.bytesRemaining();
  const boxSize = iterator.getUint32();
  if (bytesRemaining < boxSize) {
    throw new Error(`Expected box size of ${bytesRemaining}, got ${boxSize}`);
  }
  const boxFormat = iterator.getAtom();
  const isVideo = videoTags.includes(boxFormat);
  const isAudio = audioTags.includes(boxFormat) || audioTags.includes(Number(boxFormat));
  iterator.discard(6);
  const dataReferenceIndex = iterator.getUint16();
  if (!isVideo && !isAudio) {
    const bytesRemainingInBox = boxSize - (iterator.counter.getOffset() - fileOffset);
    iterator.discard(bytesRemainingInBox);
    return {
      sample: {
        type: "unknown",
        offset: fileOffset,
        dataReferenceIndex,
        size: boxSize,
        format: boxFormat
      }
    };
  }
  if (isAudio) {
    const version = iterator.getUint16();
    const revisionLevel = iterator.getUint16();
    const vendor = iterator.getSlice(4);
    if (version === 0) {
      const numberOfChannels = iterator.getUint16();
      const sampleSize = iterator.getUint16();
      const compressionId = iterator.getUint16();
      const packetSize = iterator.getUint16();
      const sampleRate = iterator.getFixedPointUnsigned1616Number();
      const bytesRemainingInBox = boxSize - (iterator.counter.getOffset() - fileOffset);
      const initialBoxes = [];
      const children = await parseIsoBaseMediaBoxes({
        iterator,
        allowIncompleteBoxes: false,
        maxBytes: bytesRemainingInBox,
        initialBoxes,
        state: options,
        continueMdat: false,
        signal,
        logLevel,
        fields
      });
      if (children.status === "incomplete") {
        throw new Error("Incomplete boxes are not allowed");
      }
      return {
        sample: {
          format: boxFormat,
          offset: fileOffset,
          dataReferenceIndex,
          version,
          revisionLevel,
          vendor: [...Array.from(new Uint8Array(vendor))],
          size: boxSize,
          type: "audio",
          numberOfChannels,
          sampleSize,
          compressionId,
          packetSize,
          sampleRate,
          samplesPerPacket: null,
          bytesPerPacket: null,
          bytesPerFrame: null,
          bitsPerSample: null,
          children: initialBoxes
        }
      };
    }
    if (version === 1) {
      const numberOfChannels = iterator.getUint16();
      const sampleSize = iterator.getUint16();
      const compressionId = iterator.getInt16();
      const packetSize = iterator.getUint16();
      const sampleRate = iterator.getFixedPointUnsigned1616Number();
      const samplesPerPacket = iterator.getUint32();
      const bytesPerPacket = iterator.getUint32();
      const bytesPerFrame = iterator.getUint32();
      const bytesPerSample = iterator.getUint32();
      const bytesRemainingInBox = boxSize - (iterator.counter.getOffset() - fileOffset);
      const initialBoxes = [];
      const children = await parseIsoBaseMediaBoxes({
        iterator,
        allowIncompleteBoxes: false,
        maxBytes: bytesRemainingInBox,
        initialBoxes,
        state: options,
        continueMdat: false,
        signal,
        logLevel,
        fields
      });
      if (children.status === "incomplete") {
        throw new Error("Incomplete boxes are not allowed");
      }
      return {
        sample: {
          format: boxFormat,
          offset: fileOffset,
          dataReferenceIndex,
          version,
          revisionLevel,
          vendor: [...Array.from(new Uint8Array(vendor))],
          size: boxSize,
          type: "audio",
          numberOfChannels,
          sampleSize,
          compressionId,
          packetSize,
          sampleRate,
          samplesPerPacket,
          bytesPerPacket,
          bytesPerFrame,
          bitsPerSample: bytesPerSample,
          children: initialBoxes
        }
      };
    }
    if (version === 2) {
      iterator.getUint16();
      const sampleSize = iterator.getUint16();
      const compressionId = iterator.getUint16();
      const packetSize = iterator.getUint16();
      iterator.getFixedPointUnsigned1616Number();
      iterator.getUint32();
      const higherSampleRate = iterator.getFloat64();
      const numAudioChannel = iterator.getUint32();
      iterator.getUint32();
      const bitsPerChannel = iterator.getUint32();
      iterator.getUint32();
      const bytesPerFrame = iterator.getUint32();
      const samplesPerPacket = iterator.getUint32();
      const bytesRemainingInBox = boxSize - (iterator.counter.getOffset() - fileOffset);
      const children = await parseIsoBaseMediaBoxes({
        iterator,
        allowIncompleteBoxes: false,
        maxBytes: bytesRemainingInBox,
        initialBoxes: [],
        state: options,
        continueMdat: false,
        signal,
        logLevel,
        fields
      });
      if (children.status === "incomplete") {
        throw new Error("Incomplete boxes are not allowed");
      }
      const initialBoxes = [];
      return {
        sample: {
          format: boxFormat,
          offset: fileOffset,
          dataReferenceIndex,
          version,
          revisionLevel,
          vendor: [...Array.from(new Uint8Array(vendor))],
          size: boxSize,
          type: "audio",
          numberOfChannels: numAudioChannel,
          sampleSize,
          compressionId,
          packetSize,
          sampleRate: higherSampleRate,
          samplesPerPacket,
          bytesPerPacket: null,
          bytesPerFrame,
          bitsPerSample: bitsPerChannel,
          children: initialBoxes
        }
      };
    }
    throw new Error(`Unsupported version ${version}`);
  }
  if (isVideo) {
    const version = iterator.getUint16();
    const revisionLevel = iterator.getUint16();
    const vendor = iterator.getSlice(4);
    const temporalQuality = iterator.getUint32();
    const spacialQuality = iterator.getUint32();
    const width = iterator.getUint16();
    const height = iterator.getUint16();
    const horizontalResolution = iterator.getFixedPointUnsigned1616Number();
    const verticalResolution = iterator.getFixedPointUnsigned1616Number();
    const dataSize = iterator.getUint32();
    const frameCountPerSample = iterator.getUint16();
    const compressorName = iterator.getPascalString();
    const depth = iterator.getUint16();
    const colorTableId = iterator.getInt16();
    const bytesRemainingInBox = boxSize - (iterator.counter.getOffset() - fileOffset);
    const initialBoxes = [];
    const children = bytesRemainingInBox > 8 ? await parseIsoBaseMediaBoxes({
      iterator,
      allowIncompleteBoxes: false,
      maxBytes: bytesRemainingInBox,
      initialBoxes,
      state: options,
      continueMdat: false,
      signal,
      logLevel,
      fields
    }) : (iterator.discard(bytesRemainingInBox), { status: "done" });
    if (children.status === "incomplete") {
      throw new Error("Incomplete boxes are not allowed");
    }
    return {
      sample: {
        format: boxFormat,
        offset: fileOffset,
        dataReferenceIndex,
        version,
        revisionLevel,
        vendor: [...Array.from(new Uint8Array(vendor))],
        size: boxSize,
        type: "video",
        width,
        height,
        horizontalResolutionPpi: horizontalResolution,
        verticalResolutionPpi: verticalResolution,
        spacialQuality,
        temporalQuality,
        dataSize,
        frameCountPerSample,
        compressorName,
        depth,
        colorTableId,
        descriptors: initialBoxes
      }
    };
  }
  throw new Error(`Unknown sample format ${boxFormat}`);
};
var parseSamples = async ({
  iterator,
  maxBytes,
  state,
  signal,
  logLevel,
  fields
}) => {
  const samples = [];
  const initialOffset = iterator.counter.getOffset();
  while (iterator.bytesRemaining() > 0 && iterator.counter.getOffset() - initialOffset < maxBytes) {
    const { sample } = await processSample({
      iterator,
      state,
      signal,
      logLevel,
      fields
    });
    if (sample) {
      samples.push(sample);
    }
  }
  return samples;
};

// src/boxes/webm/segments/block-simple-block-flags.ts
var parseBlockFlags = (iterator, type) => {
  if (type === matroskaElements.Block) {
    iterator.startReadingBits();
    iterator.getBits(4);
    const invisible = Boolean(iterator.getBits(1));
    const lacing = iterator.getBits(2);
    iterator.getBits(1);
    iterator.stopReadingBits();
    return {
      invisible,
      lacing,
      keyframe: null
    };
  }
  if (type === matroskaElements.SimpleBlock) {
    iterator.startReadingBits();
    const keyframe = Boolean(iterator.getBits(1));
    iterator.getBits(3);
    const invisible = Boolean(iterator.getBits(1));
    const lacing = iterator.getBits(2);
    iterator.getBits(1);
    iterator.stopReadingBits();
    return {
      invisible,
      lacing,
      keyframe
    };
  }
  throw new Error("Unexpected type");
};

// src/boxes/webm/get-sample-from-block.ts
var getSampleFromBlock = (ebml, state, offset) => {
  const iterator = getArrayBufferIterator(ebml.value, ebml.value.length);
  const trackNumber2 = iterator.getVint();
  if (trackNumber2 === null) {
    throw new Error("Not enough data to get track number, should not happen");
  }
  const timecodeRelativeToCluster = iterator.getInt16();
  const { keyframe } = parseBlockFlags(iterator, ebml.type === "SimpleBlock" ? matroskaElements.SimpleBlock : matroskaElements.Block);
  const { codec, trackTimescale } = state.webm.getTrackInfoByNumber(trackNumber2);
  const clusterOffset = state.webm.getTimestampOffsetForByteOffset(offset);
  const timescale = state.webm.getTimescale();
  if (clusterOffset === undefined) {
    throw new Error("Could not find offset for byte offset " + offset);
  }
  const timecodeInNanoSeconds = (timecodeRelativeToCluster + clusterOffset) * timescale * (trackTimescale ?? 1);
  const timecodeInMicroseconds = timecodeInNanoSeconds / 1000;
  if (!codec) {
    throw new Error(`Could not find codec for track ${trackNumber2}`);
  }
  const remainingNow = ebml.value.length - iterator.counter.getOffset();
  if (codec.startsWith("V_")) {
    const partialVideoSample = {
      data: iterator.getSlice(remainingNow),
      cts: timecodeInMicroseconds,
      dts: timecodeInMicroseconds,
      duration: undefined,
      trackId: trackNumber2,
      timestamp: timecodeInMicroseconds,
      offset,
      timescale
    };
    if (keyframe === null) {
      iterator.destroy();
      return {
        type: "partial-video-sample",
        partialVideoSample
      };
    }
    const sample = {
      ...partialVideoSample,
      type: keyframe ? "key" : "delta"
    };
    iterator.destroy();
    return {
      type: "video-sample",
      videoSample: sample
    };
  }
  if (codec.startsWith("A_")) {
    const audioSample = {
      data: iterator.getSlice(remainingNow),
      trackId: trackNumber2,
      timestamp: timecodeInMicroseconds,
      type: "key",
      duration: undefined,
      cts: timecodeInMicroseconds,
      dts: timecodeInMicroseconds,
      offset,
      timescale
    };
    iterator.destroy();
    return {
      type: "audio-sample",
      audioSample
    };
  }
  iterator.destroy();
  return {
    type: "no-sample"
  };
};

// src/boxes/webm/parse-ebml.ts
var parseEbml = async (iterator, state) => {
  const hex = iterator.getMatroskaSegmentId();
  if (hex === null) {
    throw new Error("Not enough bytes left to parse EBML - this should not happen");
  }
  const hasInMap = ebmlMap[hex];
  if (!hasInMap) {
    throw new Error(`Don't know how to parse EBML hex ID ${JSON.stringify(hex)}`);
  }
  const off = iterator.counter.getOffset();
  const size = iterator.getVint();
  const minVintWidth = iterator.counter.getOffset() - off;
  if (size === null) {
    throw new Error("Not enough bytes left to parse EBML - this should not happen");
  }
  if (hasInMap.type === "uint") {
    const beforeUintOffset = iterator.counter.getOffset();
    const value = size === 0 ? 0 : iterator.getUint(size);
    const { name } = hasInMap;
    return {
      type: name,
      value: {
        value,
        byteLength: iterator.counter.getOffset() - beforeUintOffset
      },
      minVintWidth
    };
  }
  if (hasInMap.type === "string") {
    const value = iterator.getByteString(size, true);
    return {
      type: hasInMap.name,
      value,
      minVintWidth
    };
  }
  if (hasInMap.type === "float") {
    const value = size === 0 ? 0 : size === 4 ? iterator.getFloat32() : iterator.getFloat64();
    return {
      type: hasInMap.name,
      value: {
        value,
        size: size === 4 ? "32" : "64"
      },
      minVintWidth
    };
  }
  if (hasInMap.type === "hex-string") {
    return {
      type: hasInMap.name,
      value: "0x" + [...iterator.getSlice(size)].map((b) => b.toString(16).padStart(2, "0")).join("").replace(new RegExp("^" + hex), ""),
      minVintWidth
    };
  }
  if (hasInMap.type === "uint8array") {
    return {
      type: hasInMap.name,
      value: iterator.getSlice(size),
      minVintWidth
    };
  }
  if (hasInMap.type === "children") {
    const children = [];
    const startOffset = iterator.counter.getOffset();
    while (true) {
      if (size === 0) {
        break;
      }
      const offset = iterator.counter.getOffset();
      const value = await parseEbml(iterator, state);
      const remapped = await postprocessEbml({
        offset,
        ebml: value,
        state
      });
      children.push(remapped);
      const offsetNow = iterator.counter.getOffset();
      if (offsetNow - startOffset > size) {
        throw new Error(`Offset ${offsetNow - startOffset} is larger than the length of the hex ${size}`);
      }
      if (offsetNow - startOffset === size) {
        break;
      }
    }
    return { type: hasInMap.name, value: children, minVintWidth };
  }
  throw new Error(`Unknown segment type ${hasInMap.type}`);
};
var postprocessEbml = async ({
  offset,
  ebml,
  state
}) => {
  if (ebml.type === "TimestampScale") {
    state.webm.setTimescale(ebml.value.value);
  }
  if (ebml.type === "TrackEntry") {
    state.webm.onTrackEntrySegment(ebml);
    const track = getTrack({
      track: ebml,
      timescale: state.webm.getTimescale()
    });
    if (track) {
      await registerTrack({
        state,
        track,
        container: "webm"
      });
    }
  }
  if (ebml.type === "Timestamp") {
    state.webm.setTimestampOffset(offset, ebml.value.value);
  }
  if (ebml.type === "Block" || ebml.type === "SimpleBlock") {
    const sample = getSampleFromBlock(ebml, state, offset);
    if (sample.type === "video-sample") {
      await state.callbacks.onVideoSample(sample.videoSample.trackId, sample.videoSample);
      return {
        type: "Block",
        value: new Uint8Array([]),
        minVintWidth: ebml.minVintWidth
      };
    }
    if (sample.type === "audio-sample") {
      await state.callbacks.onAudioSample(sample.audioSample.trackId, sample.audioSample);
      return {
        type: "Block",
        value: new Uint8Array([]),
        minVintWidth: ebml.minVintWidth
      };
    }
    if (sample.type === "no-sample") {
      return {
        type: "Block",
        value: new Uint8Array([]),
        minVintWidth: ebml.minVintWidth
      };
    }
  }
  if (ebml.type === "BlockGroup") {
    const block2 = ebml.value.find((c) => c.type === "SimpleBlock" || c.type === "Block");
    if (!block2 || block2.type !== "SimpleBlock" && block2.type !== "Block") {
      throw new Error("Expected block segment");
    }
    const hasReferenceBlock = ebml.value.find((c) => c.type === "ReferenceBlock");
    const sample = block2.value.length === 0 ? null : getSampleFromBlock(block2, state, offset);
    if (sample && sample.type === "partial-video-sample") {
      const completeFrame = {
        ...sample.partialVideoSample,
        type: hasReferenceBlock ? "delta" : "key"
      };
      await state.callbacks.onVideoSample(sample.partialVideoSample.trackId, completeFrame);
    }
    return {
      type: "BlockGroup",
      value: [],
      minVintWidth: ebml.minVintWidth
    };
  }
  return ebml;
};

// src/log.ts
var logLevels = ["trace", "verbose", "info", "warn", "error"];
var getNumberForLogLevel = (level) => {
  return logLevels.indexOf(level);
};
var isEqualOrBelowLogLevel = (currentLevel, level) => {
  return getNumberForLogLevel(currentLevel) <= getNumberForLogLevel(level);
};
var Log = {
  trace: (logLevel, ...args) => {
    if (isEqualOrBelowLogLevel(logLevel, "trace")) {
      return console.log(...args);
    }
  },
  verbose: (logLevel, ...args) => {
    if (isEqualOrBelowLogLevel(logLevel, "verbose")) {
      return console.log(...args);
    }
  },
  info: (logLevel, ...args) => {
    if (isEqualOrBelowLogLevel(logLevel, "info")) {
      return console.log(...args);
    }
  },
  warn: (logLevel, ...args) => {
    if (isEqualOrBelowLogLevel(logLevel, "warn")) {
      return console.warn(...args);
    }
  },
  error: (...args) => {
    return console.error(...args);
  }
};

// src/state/emitted-fields.ts
var emittedState = () => {
  const emittedFields = {
    audioCodec: false,
    container: false,
    dimensions: false,
    durationInSeconds: false,
    fps: false,
    internalStats: false,
    isHdr: false,
    location: false,
    metadata: false,
    mimeType: false,
    name: false,
    rotation: false,
    size: false,
    structure: false,
    tracks: false,
    videoCodec: false,
    unrotatedDimensions: false,
    slowDurationInSeconds: false,
    slowFps: false,
    slowKeyframes: false,
    slowNumberOfFrames: false,
    keyframes: false
  };
  return emittedFields;
};

// src/state/keyframes.ts
var keyframesState = () => {
  const keyframes = [];
  return {
    addKeyframe: (keyframe) => {
      keyframes.push(keyframe);
    },
    getKeyframes: () => {
      return keyframes;
    }
  };
};

// src/state/riff.ts
var riffSpecificState = () => {
  let avcProfile = null;
  let nextTrackIndex = 0;
  const profileCallbacks = [];
  const registerOnAvcProfileCallback = (callback) => {
    profileCallbacks.push(callback);
  };
  const onProfile = async (profile) => {
    avcProfile = profile;
    for (const callback of profileCallbacks) {
      await callback(profile);
    }
    profileCallbacks.length = 0;
  };
  return {
    getAvcProfile: () => {
      return avcProfile;
    },
    onProfile,
    registerOnAvcProfileCallback,
    getNextTrackIndex: () => {
      return nextTrackIndex;
    },
    incrementNextTrackIndex: () => {
      nextTrackIndex++;
    }
  };
};

// src/state/can-skip-tracks.ts
var needsTracksField = {
  audioCodec: true,
  container: false,
  dimensions: true,
  durationInSeconds: true,
  slowDurationInSeconds: true,
  slowFps: true,
  fps: true,
  internalStats: false,
  isHdr: true,
  name: false,
  rotation: true,
  size: false,
  structure: true,
  tracks: true,
  unrotatedDimensions: true,
  videoCodec: true,
  metadata: true,
  location: true,
  mimeType: false,
  slowKeyframes: true,
  slowNumberOfFrames: true,
  keyframes: true
};
var makeCanSkipTracksState = ({
  hasAudioTrackHandlers,
  fields,
  hasVideoTrackHandlers
}) => {
  return {
    canSkipTracks: () => {
      if (hasAudioTrackHandlers || hasVideoTrackHandlers) {
        return false;
      }
      const keys = Object.keys(fields ?? {});
      const selectedKeys = keys.filter((k) => fields[k]);
      return !selectedKeys.some((k) => needsTracksField[k]);
    }
  };
};

// src/state/has-tracks-section.ts
var makeTracksSectionState = (canSkipTracksState) => {
  const tracks2 = [];
  let doneWithTracks = false;
  return {
    hasAllTracks: () => doneWithTracks,
    setIsDone: () => {
      doneWithTracks = true;
    },
    addTrack: (track) => {
      tracks2.push(track);
    },
    getTracks: () => tracks2,
    ensureHasTracksAtEnd: () => {
      if (canSkipTracksState.canSkipTracks()) {
        return;
      }
      if (!doneWithTracks) {
        throw new Error("Error in Media Parser: End of parsing has been reached, but no tracks have been found");
      }
    }
  };
};

// src/state/sample-callbacks.ts
var sampleCallback = ({
  signal,
  hasAudioTrackHandlers,
  hasVideoTrackHandlers,
  fields,
  keyframes,
  emittedFields,
  slowDurationAndFpsState
}) => {
  const videoSampleCallbacks = {};
  const audioSampleCallbacks = {};
  const queuedAudioSamples = {};
  const queuedVideoSamples = {};
  const canSkipTracksState = makeCanSkipTracksState({
    hasAudioTrackHandlers,
    fields,
    hasVideoTrackHandlers
  });
  const tracksState = makeTracksSectionState(canSkipTracksState);
  const samplesForTrack = {};
  return {
    registerVideoSampleCallback: async (id, callback) => {
      if (callback === null) {
        delete videoSampleCallbacks[id];
        return;
      }
      videoSampleCallbacks[id] = callback;
      for (const queued of queuedVideoSamples[id] ?? []) {
        await callback(queued);
      }
      queuedVideoSamples[id] = [];
    },
    onAudioSample: async (trackId, audioSample) => {
      if (signal?.aborted) {
        throw new Error("Aborted");
      }
      if (typeof samplesForTrack[trackId] === "undefined") {
        samplesForTrack[trackId] = 0;
      }
      const callback = audioSampleCallbacks[trackId];
      if (audioSample.data.length > 0) {
        samplesForTrack[trackId]++;
        if (callback) {
          await callback(audioSample);
        }
      }
    },
    getSamplesForTrack: (trackId) => {
      return samplesForTrack[trackId] ?? 0;
    },
    onVideoSample: async (trackId, videoSample) => {
      if (signal?.aborted) {
        throw new Error("Aborted");
      }
      if (typeof samplesForTrack[trackId] === "undefined") {
        samplesForTrack[trackId] = 0;
      }
      if (videoSample.data.length > 0) {
        samplesForTrack[trackId]++;
        const callback = videoSampleCallbacks[trackId];
        if (callback) {
          await callback(videoSample);
        }
      }
      if (needsToIterateOverSamples({
        fields,
        emittedFields
      })) {
        if (fields.slowKeyframes && videoSample.type === "key") {
          keyframes.addKeyframe({
            trackId,
            decodingTimeInSeconds: videoSample.dts / videoSample.timescale,
            positionInBytes: videoSample.offset,
            presentationTimeInSeconds: videoSample.cts / videoSample.timescale,
            sizeInBytes: videoSample.data.length
          });
        }
        slowDurationAndFpsState.addSample(videoSample);
      }
    },
    canSkipTracksState,
    registerAudioSampleCallback: async (id, callback) => {
      if (callback === null) {
        delete audioSampleCallbacks[id];
        return;
      }
      audioSampleCallbacks[id] = callback;
      for (const queued of queuedAudioSamples[id] ?? []) {
        await callback(queued);
      }
      queuedAudioSamples[id] = [];
    },
    tracks: tracksState,
    audioSampleCallbacks,
    videoSampleCallbacks
  };
};

// src/state/slow-duration-fps.ts
var slowDurationAndFpsState = () => {
  let smallestSample;
  let largestSample;
  let samples = 0;
  const getSlowDurationInSeconds = () => {
    if (smallestSample !== undefined && largestSample !== undefined) {
      const startingTimestampDifference = largestSample - smallestSample;
      const timeBetweenSamples = startingTimestampDifference / (samples - 1);
      return timeBetweenSamples * samples;
    }
    throw new Error("No samples");
  };
  return {
    addSample: (videoSample) => {
      samples++;
      const presentationTimeInSeconds = videoSample.cts / videoSample.timescale;
      if (largestSample === undefined || presentationTimeInSeconds > largestSample) {
        largestSample = presentationTimeInSeconds;
      }
      if (smallestSample === undefined || presentationTimeInSeconds < smallestSample) {
        smallestSample = presentationTimeInSeconds;
      }
    },
    getSlowDurationInSeconds,
    getFps: () => {
      return samples / getSlowDurationInSeconds();
    },
    getSlowNumberOfFrames: () => samples
  };
};

// src/state/structure.ts
var structureState = () => {
  let structure = null;
  return {
    getStructureOrNull: () => {
      return structure;
    },
    getStructure: () => {
      if (structure === null) {
        throw new Error("Expected structure");
      }
      return structure;
    },
    setStructure: (value) => {
      structure = value;
    }
  };
};

// src/state/webm.ts
var webmState = () => {
  const trackEntries = {};
  const onTrackEntrySegment = (trackEntry2) => {
    const trackId = getTrackId(trackEntry2);
    if (!trackId) {
      throw new Error("Expected track id");
    }
    if (trackEntries[trackId]) {
      return;
    }
    const codec = getTrackCodec(trackEntry2);
    if (!codec) {
      throw new Error("Expected codec");
    }
    const trackTimescale = getTrackTimestampScale(trackEntry2);
    trackEntries[trackId] = {
      codec: codec.value,
      trackTimescale: trackTimescale?.value ?? null
    };
  };
  const timestampMap = new Map;
  const getTimestampOffsetForByteOffset = (byteOffset) => {
    const entries = Array.from(timestampMap.entries());
    const sortedByByteOffset = entries.sort((a, b) => {
      return a[0] - b[0];
    }).reverse();
    for (const [offset, timestamp] of sortedByByteOffset) {
      if (offset >= byteOffset) {
        continue;
      }
      return timestamp;
    }
    return timestampMap.get(byteOffset);
  };
  const setTimestampOffset = (byteOffset, timestamp) => {
    timestampMap.set(byteOffset, timestamp);
  };
  let timescale = null;
  const setTimescale = (newTimescale) => {
    timescale = newTimescale;
  };
  const getTimescale = () => {
    if (timescale === null) {
      return 1e6;
    }
    return timescale;
  };
  return {
    onTrackEntrySegment,
    getTrackInfoByNumber: (id) => trackEntries[id],
    setTimestampOffset,
    getTimestampOffsetForByteOffset,
    timescale,
    getTimescale,
    setTimescale
  };
};

// src/state/parser-state.ts
var makeParserState = ({
  hasAudioTrackHandlers,
  hasVideoTrackHandlers,
  signal,
  getIterator,
  fields,
  onAudioTrack,
  onVideoTrack,
  supportsContentRange
}) => {
  let skippedBytes = 0;
  const increaseSkippedBytes = (bytes) => {
    skippedBytes += bytes;
  };
  const structure = structureState();
  const keyframes = keyframesState();
  const emittedFields = emittedState();
  const slowDurationAndFps = slowDurationAndFpsState();
  return {
    riff: riffSpecificState(),
    callbacks: sampleCallback({
      signal,
      hasAudioTrackHandlers,
      hasVideoTrackHandlers,
      fields,
      keyframes,
      emittedFields,
      slowDurationAndFpsState: slowDurationAndFps
    }),
    getInternalStats: () => ({
      skippedBytes,
      finalCursorOffset: getIterator()?.counter.getOffset() ?? 0
    }),
    getSkipBytes: () => skippedBytes,
    increaseSkippedBytes,
    keyframes,
    structure,
    onAudioTrack,
    onVideoTrack,
    supportsContentRange,
    webm: webmState(),
    emittedFields,
    fields,
    slowDurationAndFps
  };
};

// src/boxes/webm/segments/parse-children.ts
var processParseResult = ({
  parseResult,
  children,
  state,
  fields,
  topLevelStructure
}) => {
  if (parseResult.segment && !children.includes(parseResult.segment)) {
    children.push(parseResult.segment);
    if (hasAllInfo({ fields, state })) {
      return {
        status: "done",
        segment: parseResult.segment
      };
    }
    if (parseResult.segment.type === "Tracks") {
      state.callbacks.tracks.setIsDone();
    }
  }
  if (parseResult.status === "incomplete") {
    return {
      status: "incomplete",
      segment: parseResult.segment,
      continueParsing: async () => {
        const newParseResult = await parseResult.continueParsing();
        return processParseResult({
          children,
          parseResult: newParseResult,
          state,
          fields,
          topLevelStructure
        });
      }
    };
  }
  return {
    status: "done",
    segment: parseResult.segment
  };
};
var expectAndProcessSegment = async ({
  iterator,
  state,
  offset,
  children,
  fields,
  topLevelStructure
}) => {
  const segment = await expectSegment({
    iterator,
    state,
    offset,
    children,
    fields,
    topLevelStructure
  });
  return processParseResult({
    children,
    parseResult: segment,
    state,
    fields,
    topLevelStructure
  });
};
var continueAfterSegmentResult = async ({
  result,
  length,
  children,
  state,
  iterator,
  startOffset,
  fields,
  topLevelStructure
}) => {
  if (result.status === "done") {
    throw new Error("Should not continue after done");
  }
  const segmentResult = await result.continueParsing();
  if (segmentResult.status === "done") {
    return {
      status: "incomplete",
      continueParsing: () => {
        return expectChildren({
          children,
          iterator,
          length,
          state,
          startOffset,
          fields,
          topLevelStructure
        });
      },
      skipTo: null
    };
  }
  return {
    status: "incomplete",
    continueParsing: () => {
      return continueAfterSegmentResult({
        result: segmentResult,
        children,
        iterator,
        length,
        state,
        startOffset,
        fields,
        topLevelStructure
      });
    },
    skipTo: null
  };
};
var expectChildren = async ({
  iterator,
  length,
  children,
  state,
  startOffset,
  fields,
  topLevelStructure
}) => {
  while (iterator.counter.getOffset() < startOffset + length) {
    if (iterator.bytesRemaining() === 0) {
      break;
    }
    const currentOffset = iterator.counter.getOffset();
    const child = await expectAndProcessSegment({
      iterator,
      state,
      offset: currentOffset,
      children,
      fields,
      topLevelStructure
    });
    if (hasAllInfo({
      fields,
      state
    })) {
      return {
        status: "done"
      };
    }
    if (child.status === "incomplete") {
      return {
        status: "incomplete",
        continueParsing: () => {
          return continueAfterSegmentResult({
            result: child,
            children,
            iterator,
            length: length - (currentOffset - startOffset),
            state,
            startOffset: currentOffset,
            fields,
            topLevelStructure
          });
        },
        skipTo: null
      };
    }
  }
  return {
    status: "done"
  };
};

// src/boxes/webm/segments.ts
var continueAfterMatroskaParseResult = async ({
  result,
  iterator,
  state,
  segment
}) => {
  if (result.status === "done") {
    throw new Error("Should not continue after done");
  }
  const proceeded = await result.continueParsing();
  if (proceeded.status === "done") {
    return {
      status: "done",
      segment
    };
  }
  return {
    continueParsing() {
      return continueAfterMatroskaParseResult({
        result: proceeded,
        iterator,
        state,
        segment
      });
    },
    segment: null,
    status: "incomplete"
  };
};
var expectSegment = async ({
  iterator,
  state,
  offset,
  children,
  fields,
  topLevelStructure
}) => {
  iterator.counter.decrement(iterator.counter.getOffset() - offset);
  if (iterator.bytesRemaining() === 0) {
    return {
      status: "incomplete",
      continueParsing: () => {
        return expectAndProcessSegment({
          iterator,
          state,
          offset,
          children,
          fields,
          topLevelStructure
        });
      },
      segment: null
    };
  }
  const segmentId = iterator.getMatroskaSegmentId();
  if (segmentId === null) {
    iterator.counter.decrement(iterator.counter.getOffset() - offset);
    return {
      status: "incomplete",
      continueParsing: () => {
        return expectAndProcessSegment({
          iterator,
          state,
          offset,
          children,
          fields,
          topLevelStructure
        });
      },
      segment: null
    };
  }
  const offsetBeforeVInt = iterator.counter.getOffset();
  const length = iterator.getVint();
  const offsetAfterVInt = iterator.counter.getOffset();
  if (length === null) {
    iterator.counter.decrement(iterator.counter.getOffset() - offset);
    return {
      status: "incomplete",
      continueParsing: () => {
        return expectSegment({
          iterator,
          state,
          offset,
          children,
          fields,
          topLevelStructure
        });
      },
      segment: null
    };
  }
  const bytesRemainingNow = iterator.byteLength() - iterator.counter.getOffset();
  if (segmentId === "0x18538067" || segmentId === "0x1f43b675") {
    const newSegment = {
      type: segmentId === "0x18538067" ? "Segment" : "Cluster",
      minVintWidth: offsetAfterVInt - offsetBeforeVInt,
      value: []
    };
    const main = await expectChildren({
      iterator,
      length,
      children: newSegment.value,
      state,
      startOffset: iterator.counter.getOffset(),
      fields,
      topLevelStructure
    });
    if (main.status === "incomplete") {
      return {
        status: "incomplete",
        continueParsing: () => {
          return continueAfterMatroskaParseResult({
            iterator,
            state,
            result: main,
            segment: newSegment
          });
        },
        segment: newSegment
      };
    }
    return {
      status: "done",
      segment: newSegment
    };
  }
  if (bytesRemainingNow < length) {
    const bytesRead = iterator.counter.getOffset() - offset;
    iterator.counter.decrement(bytesRead);
    return {
      status: "incomplete",
      segment: null,
      continueParsing: () => {
        return expectSegment({
          iterator,
          state,
          offset,
          children,
          fields,
          topLevelStructure
        });
      }
    };
  }
  const segment = await parseSegment({
    segmentId,
    iterator,
    length,
    state,
    headerReadSoFar: iterator.counter.getOffset() - offset
  });
  return {
    status: "done",
    segment
  };
};
var parseSegment = async ({
  segmentId,
  iterator,
  length,
  state,
  headerReadSoFar
}) => {
  if (length < 0) {
    throw new Error(`Expected length of ${segmentId} to be greater or equal 0`);
  }
  iterator.counter.decrement(headerReadSoFar);
  const offset = iterator.counter.getOffset();
  const ebml = await parseEbml(iterator, state);
  const remapped = await postprocessEbml({ offset, ebml, state });
  return remapped;
};

// src/errors.ts
class IsAGifError extends Error {
  mimeType;
  sizeInBytes;
  fileName;
  constructor({
    message,
    mimeType,
    sizeInBytes,
    fileName
  }) {
    super(message);
    this.fileName = "IsAGifError";
    this.mimeType = mimeType;
    this.sizeInBytes = sizeInBytes;
    this.fileName = fileName;
    if (Error.captureStackTrace) {
      Error.captureStackTrace(this, IsAGifError);
    }
  }
}

class IsAnImageError extends Error {
  imageType;
  dimensions;
  mimeType;
  sizeInBytes;
  fileName;
  constructor({
    dimensions,
    imageType,
    message,
    mimeType,
    sizeInBytes,
    fileName
  }) {
    super(message);
    this.name = "IsAnImageError";
    this.imageType = imageType;
    this.dimensions = dimensions;
    this.mimeType = mimeType;
    this.sizeInBytes = sizeInBytes;
    this.fileName = fileName;
    if (Error.captureStackTrace) {
      Error.captureStackTrace(this, IsAnImageError);
    }
  }
}

class IsAPdfError extends Error {
  mimeType;
  sizeInBytes;
  fileName;
  constructor({
    message,
    mimeType,
    sizeInBytes,
    fileName
  }) {
    super(message);
    this.name = "IsAPdfError";
    this.mimeType = mimeType;
    this.sizeInBytes = sizeInBytes;
    this.fileName = fileName;
    if (Error.captureStackTrace) {
      Error.captureStackTrace(this, IsAPdfError);
    }
  }
}

class IsAnUnsupportedFileTypeError extends Error {
  mimeType;
  sizeInBytes;
  fileName;
  constructor({
    message,
    mimeType,
    sizeInBytes,
    fileName
  }) {
    super(message);
    this.name = "IsAnUnsupportedFileTypeError";
    this.mimeType = mimeType;
    this.sizeInBytes = sizeInBytes;
    this.fileName = fileName;
    if (Error.captureStackTrace) {
      Error.captureStackTrace(this, IsAnUnsupportedFileTypeError);
    }
  }
}

class IsAnUnsupportedAudioTypeError extends Error {
  mimeType;
  sizeInBytes;
  fileName;
  audioType;
  constructor({
    message,
    mimeType,
    sizeInBytes,
    fileName,
    audioType
  }) {
    super(message);
    this.name = "IsAnUnsupportedAudioTypeError";
    this.mimeType = mimeType;
    this.sizeInBytes = sizeInBytes;
    this.fileName = fileName;
    this.audioType = audioType;
    if (Error.captureStackTrace) {
      Error.captureStackTrace(this, IsAnUnsupportedAudioTypeError);
    }
  }
}
// src/metadata/metadata-from-iso.ts
var mapToKey = (index) => {
  if (index === 2839630420) {
    return "artist";
  }
  if (index === 2841734242) {
    return "album";
  }
  if (index === 2841865588) {
    return "comment";
  }
  if (index === 2841928057) {
    return "releaseDate";
  }
  if (index === 2842125678) {
    return "genre";
  }
  if (index === 2842583405) {
    return "title";
  }
  if (index === 2842980207) {
    return "encoder";
  }
  if (index === 2843177588) {
    return "writer";
  }
  if (index === 2841866361) {
    return "copyright";
  }
  if (index === 2841930098) {
    return "director";
  }
  if (index === 2842718820) {
    return "producer";
  }
  if (index === 2841929075) {
    return "description";
  }
  return null;
};
var parseIlstBoxWithoutKeys = (ilstBox) => {
  return ilstBox.entries.map((entry) => {
    const key = mapToKey(entry.index);
    if (!key) {
      return null;
    }
    if (entry.value.type === "unknown") {
      return null;
    }
    return {
      trackId: null,
      key,
      value: entry.value.value
    };
  }).filter(truthy);
};
var parseIsoMetaBox = (meta, trackId) => {
  const ilstBox = meta.children.find((b) => b.type === "ilst-box");
  const keysBox = meta.children.find((b) => b.type === "keys-box");
  if (!ilstBox || !keysBox) {
    if (ilstBox) {
      return parseIlstBoxWithoutKeys(ilstBox);
    }
    return [];
  }
  const entries = [];
  for (let i = 0;i < ilstBox.entries.length; i++) {
    const ilstEntry = ilstBox.entries[i];
    const keysEntry = keysBox.entries[i];
    if (ilstEntry.value.type !== "unknown") {
      const value = typeof ilstEntry.value.value === "string" && ilstEntry.value.value.endsWith("\x00") ? ilstEntry.value.value.slice(0, -1) : ilstEntry.value.value;
      entries.push({
        key: keysEntry.value,
        value,
        trackId
      });
    }
  }
  return entries;
};
var getMetadataFromIsoBase = (isoBase) => {
  const moov = getMoovBox(isoBase.boxes);
  if (!moov) {
    return [];
  }
  const traks = getTraks(moov);
  const meta = moov.children.find((b) => b.type === "regular-box" && b.boxType === "meta");
  const udta = moov.children.find((b) => b.type === "regular-box" && b.boxType === "udta");
  const metaInUdta = udta?.children.find((b) => {
    return b.type === "regular-box" && b.boxType === "meta";
  });
  const metaInTracks = traks.map((t) => {
    const metaBox = t.children.find((child) => child.type === "regular-box" && child.boxType === "meta");
    if (metaBox) {
      const tkhd = getTkhdBox(t);
      if (!tkhd) {
        throw new Error("No tkhd box found");
      }
      return parseIsoMetaBox(metaBox, tkhd.trackId);
    }
    return null;
  }).filter(truthy);
  return [
    ...meta ? parseIsoMetaBox(meta, null) : [],
    ...metaInUdta ? parseIsoMetaBox(metaInUdta, null) : [],
    ...metaInTracks.flat(1)
  ];
};

// src/metadata/metadata-from-matroska.ts
var removeEndZeroes = (value) => {
  return value.endsWith("\x00") ? removeEndZeroes(value.slice(0, -1)) : value;
};
var parseSimpleTagIntoEbml = (children, trackId) => {
  const tagName = children.find((c) => c.type === "TagName");
  const tagString = children.find((c) => c.type === "TagString");
  if (!tagName || !tagString) {
    return null;
  }
  return {
    trackId,
    key: tagName.value.toLowerCase(),
    value: removeEndZeroes(tagString.value)
  };
};
var getMetadataFromMatroska = (structure) => {
  const entries = [];
  for (const segment of structure.boxes) {
    if (segment.type !== "Segment") {
      continue;
    }
    const tags2 = segment.value.filter((s) => s.type === "Tags");
    for (const tag of tags2) {
      for (const child of tag.value) {
        if (child.type !== "Tag") {
          continue;
        }
        let trackId = null;
        const target = child.value.find((c) => c.type === "Targets");
        if (target) {
          const tagTrackId = target.value.find((c) => c.type === "TagTrackUID")?.value;
          if (tagTrackId) {
            trackId = getTrackWithUid(segment, tagTrackId);
          }
        }
        const simpleTags = child.value.filter((s) => s.type === "SimpleTag");
        for (const simpleTag of simpleTags) {
          const parsed = parseSimpleTagIntoEbml(simpleTag.value, trackId);
          if (parsed) {
            entries.push(parsed);
          }
        }
      }
    }
  }
  return entries;
};

// src/metadata/metadata-from-riff.ts
var getMetadataFromRiff = (structure) => {
  const boxes = structure.boxes.find((b) => b.type === "list-box" && b.listType === "INFO");
  if (!boxes) {
    return [];
  }
  const { children } = boxes;
  return children.map((child) => {
    if (child.type !== "isft-box") {
      return null;
    }
    return {
      trackId: null,
      key: "encoder",
      value: child.software
    };
  }).filter(truthy);
};

// src/metadata/get-metadata.ts
var getMetadata = (structure) => {
  if (structure.type === "matroska") {
    return getMetadataFromMatroska(structure);
  }
  if (structure.type === "riff") {
    return getMetadataFromRiff(structure);
  }
  if (structure.type === "transport-stream") {
    return [];
  }
  return getMetadataFromIsoBase(structure);
};

// src/get-location.ts
function parseLocation(locationString) {
  const locationPattern = /^([+-]\d{2}\.?\d{0,10})([+-]\d{3}\.?\d{0,10})([+-]\d+(\.\d+)?)?\/$/;
  const match = locationString.match(locationPattern);
  if (!match) {
    return null;
  }
  const latitude = parseFloat(match[1]);
  const longitude = parseFloat(match[2]);
  const altitude = match[3] ? parseFloat(match[3]) : null;
  return {
    latitude,
    longitude,
    altitude
  };
}
var getLocation = (structure) => {
  const metadata = getMetadata(structure);
  const locationEntry = metadata.find((entry) => entry.key === "com.apple.quicktime.location.ISO6709");
  const horizontalAccuracy = metadata.find((entry) => entry.key === "com.apple.quicktime.location.accuracy.horizontal");
  if (locationEntry) {
    const parsed = parseLocation(locationEntry.value);
    if (parsed === null) {
      return null;
    }
    return {
      ...parsed,
      horizontalAccuracy: horizontalAccuracy?.value ? parseFloat(String(horizontalAccuracy.value)) : null
    };
  }
  return null;
};

// src/emit-available-info.ts
var emitAvailableInfo = ({
  hasInfo,
  parseResult,
  callbacks,
  state,
  returnValue,
  contentLength,
  name,
  mimeType,
  fieldsInReturnValue
}) => {
  const keys = Object.keys(hasInfo);
  const segments = state.structure.getStructureOrNull();
  const { emittedFields } = state;
  for (const key of keys) {
    if (key === "structure") {
      if (parseResult && hasInfo.structure && !emittedFields.structure && segments) {
        callbacks.onStructure?.(segments);
        if (fieldsInReturnValue.structure) {
          returnValue.structure = segments;
        }
        emittedFields.structure = true;
      }
      continue;
    }
    if (key === "durationInSeconds") {
      if (hasInfo.durationInSeconds && parseResult && segments) {
        if (!emittedFields.durationInSeconds) {
          const durationInSeconds = getDuration(segments, state);
          callbacks.onDurationInSeconds?.(durationInSeconds);
          if (fieldsInReturnValue.durationInSeconds) {
            returnValue.durationInSeconds = durationInSeconds;
          }
          emittedFields.durationInSeconds = true;
        }
      }
      continue;
    }
    if (key === "slowDurationInSeconds") {
      if (hasInfo.slowDurationInSeconds && !emittedFields.slowDurationInSeconds && parseResult && segments) {
        const slowDurationInSeconds = getDuration(segments, state) ?? state.slowDurationAndFps.getSlowDurationInSeconds();
        callbacks.onSlowDurationInSeconds?.(slowDurationInSeconds);
        if (fieldsInReturnValue.slowDurationInSeconds) {
          returnValue.slowDurationInSeconds = slowDurationInSeconds;
        }
        emittedFields.slowDurationInSeconds = true;
      }
      continue;
    }
    if (key === "fps") {
      if (hasInfo.fps && parseResult && segments) {
        if (!emittedFields.fps) {
          const fps = getFps(segments);
          callbacks.onFps?.(fps);
          if (fieldsInReturnValue.fps) {
            returnValue.fps = fps;
          }
          emittedFields.fps = true;
        }
        if (!emittedFields.slowFps) {
          const fps = getFps(segments);
          if (fps) {
            callbacks.onSlowFps?.(fps);
            if (fieldsInReturnValue.slowFps) {
              returnValue.slowFps = fps;
            }
            emittedFields.slowFps = true;
          }
        }
      }
      continue;
    }
    if (key === "slowFps") {
      if (hasInfo.slowFps && !emittedFields.slowFps && parseResult && segments) {
        const slowFps = state.slowDurationAndFps.getFps();
        callbacks.onSlowFps?.(slowFps);
        if (fieldsInReturnValue.slowFps) {
          returnValue.slowFps = slowFps;
        }
        emittedFields.slowFps = true;
      }
      continue;
    }
    if (key === "dimensions") {
      if (hasInfo.dimensions && !emittedFields.dimensions && parseResult && segments) {
        const dimensionsQueried = getDimensions(segments, state);
        const dimensions = {
          height: dimensionsQueried.height,
          width: dimensionsQueried.width
        };
        callbacks.onDimensions?.(dimensions);
        if (fieldsInReturnValue.dimensions) {
          returnValue.dimensions = dimensions;
        }
        emittedFields.dimensions = true;
      }
      continue;
    }
    if (key === "unrotatedDimensions") {
      if (hasInfo.unrotatedDimensions && !emittedFields.unrotatedDimensions && parseResult && segments) {
        const dimensionsQueried = getDimensions(segments, state);
        const unrotatedDimensions = {
          height: dimensionsQueried.unrotatedHeight,
          width: dimensionsQueried.unrotatedWidth
        };
        callbacks.onUnrotatedDimensions?.(unrotatedDimensions);
        if (fieldsInReturnValue.unrotatedDimensions) {
          returnValue.unrotatedDimensions = unrotatedDimensions;
        }
        emittedFields.unrotatedDimensions = true;
      }
      continue;
    }
    if (key === "rotation") {
      if (hasInfo.rotation && !emittedFields.rotation && parseResult && segments) {
        const dimensionsQueried = getDimensions(segments, state);
        const { rotation } = dimensionsQueried;
        callbacks.onRotation?.(rotation);
        if (fieldsInReturnValue.rotation) {
          returnValue.rotation = rotation;
        }
        emittedFields.rotation = true;
      }
      continue;
    }
    if (key === "videoCodec") {
      if (!emittedFields.videoCodec && hasInfo.videoCodec && parseResult && segments) {
        const videoCodec = getVideoCodec(segments, state);
        callbacks.onVideoCodec?.(videoCodec);
        if (fieldsInReturnValue.videoCodec) {
          returnValue.videoCodec = videoCodec;
        }
        emittedFields.videoCodec = true;
      }
      continue;
    }
    if (key === "audioCodec") {
      if (!emittedFields.audioCodec && hasInfo.audioCodec && parseResult && segments) {
        const audioCodec = getAudioCodec(segments, state);
        callbacks.onAudioCodec?.(audioCodec);
        if (fieldsInReturnValue.audioCodec) {
          returnValue.audioCodec = audioCodec;
        }
        emittedFields.audioCodec = true;
      }
      continue;
    }
    if (key === "tracks") {
      if (!emittedFields.tracks && hasInfo.tracks && parseResult && segments) {
        const { videoTracks, audioTracks } = getTracks(segments, state);
        callbacks.onTracks?.({ videoTracks, audioTracks });
        if (fieldsInReturnValue.tracks) {
          returnValue.tracks = { videoTracks, audioTracks };
        }
        emittedFields.tracks = true;
      }
      continue;
    }
    if (key === "internalStats") {
      if (hasInfo.internalStats) {
        const internalStats = state.getInternalStats();
        if (fieldsInReturnValue.internalStats) {
          returnValue.internalStats = internalStats;
        }
        emittedFields.internalStats = true;
      }
      continue;
    }
    if (key === "size") {
      if (!emittedFields.size && hasInfo.size) {
        callbacks.onSize?.(contentLength);
        if (fieldsInReturnValue.size) {
          returnValue.size = contentLength;
        }
        emittedFields.size = true;
      }
      continue;
    }
    if (key === "mimeType") {
      if (!emittedFields.mimeType && hasInfo.mimeType) {
        callbacks.onMimeType?.(mimeType);
        if (fieldsInReturnValue.mimeType) {
          returnValue.mimeType = mimeType;
        }
        emittedFields.mimeType = true;
      }
      continue;
    }
    if (key === "name") {
      if (!emittedFields.name && hasInfo.name) {
        callbacks.onName?.(name);
        if (fieldsInReturnValue.name) {
          returnValue.name = name;
        }
        emittedFields.name = true;
      }
      continue;
    }
    if (key === "isHdr") {
      if (!returnValue.isHdr && hasInfo.isHdr && parseResult && segments) {
        const isHdr = getIsHdr(segments, state);
        callbacks.onIsHdr?.(isHdr);
        if (fieldsInReturnValue.isHdr) {
          returnValue.isHdr = isHdr;
        }
        emittedFields.isHdr = true;
      }
      continue;
    }
    if (key === "container") {
      if (!returnValue.container && hasInfo.container && parseResult && segments) {
        const container = getContainer(segments);
        callbacks.onContainer?.(container);
        if (fieldsInReturnValue.container) {
          returnValue.container = container;
        }
        emittedFields.container = true;
      }
      continue;
    }
    if (key === "metadata") {
      if (!emittedFields.metadata && hasInfo.metadata && parseResult && segments) {
        const metadata = getMetadata(segments);
        callbacks.onMetadata?.(metadata);
        if (fieldsInReturnValue.metadata) {
          returnValue.metadata = metadata;
        }
        emittedFields.metadata = true;
      }
      continue;
    }
    if (key === "location") {
      if (!emittedFields.location && hasInfo.location && parseResult && segments) {
        const location = getLocation(segments);
        callbacks.onLocation?.(location);
        if (fieldsInReturnValue.location) {
          returnValue.location = location;
        }
        emittedFields.location = true;
      }
      continue;
    }
    if (key === "slowKeyframes") {
      if (!emittedFields.slowKeyframes && hasInfo.slowKeyframes && parseResult) {
        callbacks.onSlowKeyframes?.(state.keyframes.getKeyframes());
        if (fieldsInReturnValue.slowKeyframes) {
          returnValue.slowKeyframes = state.keyframes.getKeyframes();
        }
        emittedFields.slowKeyframes = true;
      }
      continue;
    }
    if (key === "slowNumberOfFrames") {
      if (!emittedFields.slowNumberOfFrames && hasInfo.slowNumberOfFrames && parseResult) {
        callbacks.onSlowNumberOfFrames?.(state.slowDurationAndFps.getSlowNumberOfFrames());
        if (fieldsInReturnValue.slowNumberOfFrames) {
          returnValue.slowNumberOfFrames = state.slowDurationAndFps.getSlowNumberOfFrames();
        }
        emittedFields.slowNumberOfFrames = true;
      }
      continue;
    }
    if (key === "keyframes") {
      if (!emittedFields.keyframes && hasInfo.keyframes && parseResult) {
        callbacks.onKeyframes?.(getKeyframes(state.structure.getStructure()));
        if (fieldsInReturnValue.keyframes) {
          returnValue.keyframes = getKeyframes(state.structure.getStructure());
        }
        emittedFields.keyframes = true;
      }
      continue;
    }
    throw new Error(`Unhandled key: ${key}`);
  }
};

// src/get-fields-from-callbacks.ts
var getFieldsFromCallback = ({
  fields,
  callbacks
}) => {
  const newFields = {
    audioCodec: Boolean(callbacks.onAudioCodec),
    container: Boolean(callbacks.onContainer),
    dimensions: Boolean(callbacks.onDimensions),
    durationInSeconds: Boolean(callbacks.onDurationInSeconds),
    fps: Boolean(callbacks.onFps),
    internalStats: Boolean(callbacks.onInternalStats),
    isHdr: Boolean(callbacks.onIsHdr),
    location: Boolean(callbacks.onLocation),
    metadata: Boolean(callbacks.onMetadata),
    mimeType: Boolean(callbacks.onMimeType),
    name: Boolean(callbacks.onName),
    rotation: Boolean(callbacks.onRotation),
    size: Boolean(callbacks.onSize),
    structure: Boolean(callbacks.onStructure),
    tracks: Boolean(callbacks.onTracks),
    unrotatedDimensions: Boolean(callbacks.onUnrotatedDimensions),
    videoCodec: Boolean(callbacks.onVideoCodec),
    slowKeyframes: Boolean(callbacks.onSlowKeyframes),
    slowDurationInSeconds: Boolean(callbacks.onSlowDurationInSeconds),
    slowFps: Boolean(callbacks.onSlowFps),
    slowNumberOfFrames: Boolean(callbacks.onSlowNumberOfFrames),
    keyframes: Boolean(callbacks.onKeyframes),
    ...fields
  };
  return newFields;
};

// src/boxes/riff/is-movi.ts
var isMoviAtom = (iterator, ckId) => {
  if (ckId !== "LIST") {
    return false;
  }
  const listType = iterator.getByteString(4, false);
  iterator.counter.decrement(4);
  return listType === "movi";
};

// src/boxes/avc/key.ts
var getKeyFrameOrDeltaFromAvcInfo = (infos) => {
  const keyOrDelta = infos.find((i) => i.type === "keyframe" || i.type === "delta-frame");
  if (!keyOrDelta) {
    throw new Error("expected avc to contain info about key or delta");
  }
  return keyOrDelta.type === "keyframe" ? "key" : "delta";
};

// src/boxes/avc/parse-avc.ts
var Extended_SAR = 255;
var readVuiParameters = (iterator) => {
  let sar_width = null;
  let sar_height = null;
  let overscan_appropriate_flag = null;
  let video_format = null;
  let video_full_range_flag = null;
  let colour_primaries = null;
  let transfer_characteristics = null;
  let matrix_coefficients = null;
  let chroma_sample_loc_type_top_field = null;
  let chroma_sample_loc_type_bottom_field = null;
  const aspect_ratio_info_present_flag = iterator.getBits(1);
  if (aspect_ratio_info_present_flag) {
    const aspect_ratio_idc = iterator.getBits(8);
    if (aspect_ratio_idc === Extended_SAR) {
      sar_width = iterator.getBits(16);
      sar_height = iterator.getBits(16);
    }
  }
  const overscan_info_present_flag = iterator.getBits(1);
  if (overscan_info_present_flag) {
    overscan_appropriate_flag = iterator.getBits(1);
  }
  const video_signal_type_present_flag = iterator.getBits(1);
  if (video_signal_type_present_flag) {
    video_format = iterator.getBits(3);
    video_full_range_flag = Boolean(iterator.getBits(1));
    const colour_description_present_flag = iterator.getBits(1);
    if (colour_description_present_flag) {
      colour_primaries = iterator.getBits(8);
      transfer_characteristics = iterator.getBits(8);
      matrix_coefficients = iterator.getBits(8);
    }
  }
  const chroma_loc_info_present_flag = iterator.getBits(1);
  if (chroma_loc_info_present_flag) {
    chroma_sample_loc_type_top_field = iterator.readExpGolomb();
    chroma_sample_loc_type_bottom_field = iterator.readExpGolomb();
  }
  return {
    sar_width,
    sar_height,
    overscan_appropriate_flag,
    chroma_sample_loc_type_bottom_field,
    chroma_sample_loc_type_top_field,
    colour_primaries,
    matrix_coefficients,
    transfer_characteristics,
    video_format,
    video_full_range_flag
  };
};
var readSps = (iterator) => {
  const profile = iterator.getUint8();
  const compatibility = iterator.getUint8();
  const level = iterator.getUint8();
  iterator.startReadingBits();
  const seq_parameter_set_id = iterator.readExpGolomb();
  let separate_colour_plane_flag = null;
  let bit_depth_luma_minus8 = null;
  let bit_depth_chroma_minus8 = null;
  let qpprime_y_zero_transform_bypass_flag = null;
  let log2_max_frame_num_minus4 = null;
  let log2_max_pic_order_cnt_lsb_minus4 = null;
  let max_num_ref_frames = null;
  let gaps_in_frame_num_value_allowed_flag = null;
  let mb_adaptive_frame_field_flag = null;
  let direct_8x8_inference_flag = null;
  let frame_crop_left_offset = null;
  let frame_crop_right_offset = null;
  let frame_crop_top_offset = null;
  let frame_crop_bottom_offset = null;
  let vui_parameters = null;
  if (!(profile === 100 || profile === 110 || profile === 122 || profile === 244 || profile === 44 || profile === 83 || profile === 86 || profile === 118 || profile === 128 || profile === 138 || profile === 139 || profile === 134 || profile === 135)) {
    throw new Error("Invalid profile");
  }
  const chromaFormat = iterator.readExpGolomb();
  if (chromaFormat === 3) {
    separate_colour_plane_flag = iterator.getBits(1);
  }
  bit_depth_luma_minus8 = iterator.readExpGolomb();
  bit_depth_chroma_minus8 = iterator.readExpGolomb();
  qpprime_y_zero_transform_bypass_flag = iterator.getBits(1);
  const seq_scaling_matrix_present_flag = iterator.getBits(1);
  const seq_scaling_list_present_flag = [];
  if (seq_scaling_matrix_present_flag) {
    for (let i = 0;i < (chromaFormat !== 3 ? 8 : 12); i++) {
      seq_scaling_list_present_flag[i] = iterator.getBits(1);
      if (seq_scaling_list_present_flag[i]) {
        if (i < 6) {
          throw new Error("Not implemented");
        } else {
          throw new Error("Not implemented");
        }
      }
    }
  }
  log2_max_frame_num_minus4 = iterator.readExpGolomb();
  const pic_order_cnt_type = iterator.readExpGolomb();
  if (pic_order_cnt_type === 0) {
    log2_max_pic_order_cnt_lsb_minus4 = iterator.readExpGolomb();
  } else if (pic_order_cnt_type === 1) {
    throw new Error("pic_order_cnt_type = 1 not implemented");
  }
  max_num_ref_frames = iterator.readExpGolomb();
  gaps_in_frame_num_value_allowed_flag = iterator.getBits(1);
  const pic_width_in_mbs_minus1 = iterator.readExpGolomb();
  const pic_height_in_map_units_minus1 = iterator.readExpGolomb();
  const frame_mbs_only_flag = iterator.getBits(1);
  if (!frame_mbs_only_flag) {
    mb_adaptive_frame_field_flag = iterator.getBits(1);
  }
  direct_8x8_inference_flag = iterator.getBits(1);
  const frame_cropping_flag = iterator.getBits(1);
  if (frame_cropping_flag) {
    frame_crop_left_offset = iterator.readExpGolomb();
    frame_crop_right_offset = iterator.readExpGolomb();
    frame_crop_top_offset = iterator.readExpGolomb();
    frame_crop_bottom_offset = iterator.readExpGolomb();
  }
  const vui_parameters_present_flag = iterator.getBits(1);
  if (vui_parameters_present_flag) {
    vui_parameters = readVuiParameters(iterator);
  }
  iterator.stopReadingBits();
  return {
    profile,
    compatibility,
    level,
    bit_depth_chroma_minus8,
    bit_depth_luma_minus8,
    gaps_in_frame_num_value_allowed_flag,
    log2_max_frame_num_minus4,
    log2_max_pic_order_cnt_lsb_minus4,
    max_num_ref_frames,
    pic_height_in_map_units_minus1,
    pic_width_in_mbs_minus1,
    qpprime_y_zero_transform_bypass_flag,
    separate_colour_plane_flag,
    seq_parameter_set_id,
    direct_8x8_inference_flag,
    frame_crop_bottom_offset,
    frame_crop_left_offset,
    frame_crop_right_offset,
    frame_crop_top_offset,
    mb_adaptive_frame_field_flag,
    vui_parameters
  };
};
var findEnd = (buffer) => {
  let zeroesInARow = 0;
  for (let i = 0;i < buffer.length; i++) {
    const val = buffer[i];
    if (val === 0) {
      zeroesInARow++;
      continue;
    }
    if (zeroesInARow >= 2 && val === 1) {
      return i - zeroesInARow;
    }
    zeroesInARow = 0;
  }
  return null;
};
var inspect = (buffer) => {
  const iterator = getArrayBufferIterator(buffer, buffer.byteLength);
  iterator.startReadingBits();
  iterator.getBits(1);
  iterator.getBits(2);
  const type = iterator.getBits(5);
  iterator.stopReadingBits();
  if (type === 7) {
    const end = findEnd(buffer);
    const data = readSps(iterator);
    const sps = buffer.slice(0, end === null ? Infinity : end);
    return {
      spsData: data,
      sps,
      type: "avc-profile"
    };
  }
  if (type === 5) {
    return {
      type: "keyframe"
    };
  }
  if (type === 8) {
    const end = findEnd(buffer);
    const pps = buffer.slice(0, end === null ? Infinity : end);
    return {
      type: "avc-pps",
      pps
    };
  }
  if (type === 1) {
    return {
      type: "delta-frame"
    };
  }
  iterator.destroy();
  return null;
};
var parseAvc = (buffer) => {
  let zeroesInARow = 0;
  const infos = [];
  for (let i = 0;i < buffer.length; i++) {
    const val = buffer[i];
    if (val === 0) {
      zeroesInARow++;
      continue;
    }
    if (zeroesInARow >= 2 && val === 1) {
      zeroesInARow = 0;
      const info = inspect(buffer.slice(i + 1, i + 100));
      if (info) {
        infos.push(info);
        if (info.type === "keyframe" || info.type === "delta-frame") {
          break;
        }
      }
    }
    if (val !== 1) {
      zeroesInARow = 0;
    }
  }
  return infos;
};

// src/boxes/riff/parse-movi.ts
var getStrhForIndex = (structure, trackId) => {
  const boxes = getStrlBoxes(structure);
  const box = boxes[trackId];
  if (!box) {
    throw new Error("Expected box");
  }
  const strh = getStrhBox(box.children);
  if (!strh) {
    throw new Error("strh");
  }
  return strh;
};
var handleChunk = async ({
  iterator,
  state,
  structure,
  ckId,
  ckSize
}) => {
  const offset = iterator.counter.getOffset();
  const videoChunk = ckId.match(/^([0-9]{2})dc$/);
  if (videoChunk) {
    const trackId = parseInt(videoChunk[1], 10);
    const strh = getStrhForIndex(structure, trackId);
    const samplesPerSecond = strh.rate / strh.scale;
    const nthSample = state.callbacks.getSamplesForTrack(trackId);
    const timeInSec = nthSample / samplesPerSecond;
    const timestamp = timeInSec;
    const data = iterator.getSlice(ckSize);
    const infos = parseAvc(data);
    const keyOrDelta = getKeyFrameOrDeltaFromAvcInfo(infos);
    const avcProfile = infos.find((i) => i.type === "avc-profile");
    const ppsProfile = infos.find((i) => i.type === "avc-pps");
    if (avcProfile && ppsProfile) {
      await state.riff.onProfile({ pps: ppsProfile, sps: avcProfile });
      state.callbacks.tracks.setIsDone();
    }
    await state.callbacks.onVideoSample(trackId, convertAudioOrVideoSampleToWebCodecsTimestamps({
      cts: timestamp,
      dts: timestamp,
      data,
      duration: undefined,
      timestamp,
      trackId,
      type: keyOrDelta,
      offset,
      timescale: samplesPerSecond
    }, 1));
    return;
  }
  const audioChunk = ckId.match(/^([0-9]{2})wb$/);
  if (audioChunk) {
    const trackId = parseInt(audioChunk[1], 10);
    const strh = getStrhForIndex(structure, trackId);
    const samplesPerSecond = strh.rate / strh.scale;
    const nthSample = state.callbacks.getSamplesForTrack(trackId);
    const timeInSec = nthSample / samplesPerSecond;
    const timestamp = timeInSec;
    const data = iterator.getSlice(ckSize);
    await state.callbacks.onAudioSample(trackId, convertAudioOrVideoSampleToWebCodecsTimestamps({
      cts: timestamp,
      dts: timestamp,
      data,
      duration: undefined,
      timestamp,
      trackId,
      type: "key",
      offset,
      timescale: samplesPerSecond
    }, 1));
  }
};
var parseMovi = async ({
  iterator,
  maxOffset,
  state,
  structure
}) => {
  while (iterator.counter.getOffset() < maxOffset) {
    if (iterator.bytesRemaining() < 8) {
      return {
        type: "incomplete",
        continueParsing: () => {
          return Promise.resolve(parseMovi({ iterator, maxOffset, state, structure }));
        }
      };
    }
    const ckId = iterator.getByteString(4, false);
    const ckSize = iterator.getUint32Le();
    if (maySkipVideoData({
      state
    }) && state.riff.getAvcProfile()) {
      return {
        type: "complete",
        box: {
          type: "movi-box"
        },
        skipTo: maxOffset
      };
    }
    if (iterator.bytesRemaining() < ckSize) {
      iterator.counter.decrement(8);
      return {
        type: "incomplete",
        continueParsing: () => {
          return Promise.resolve(parseMovi({ iterator, maxOffset, state, structure }));
        }
      };
    }
    await handleChunk({ iterator, state, structure, ckId, ckSize });
    while (iterator.counter.getOffset() < maxOffset && iterator.bytesRemaining() > 0) {
      if (iterator.getUint8() !== 0) {
        iterator.counter.decrement(1);
        break;
      }
    }
  }
  if (iterator.counter.getOffset() === maxOffset) {
    return {
      type: "complete",
      box: {
        type: "movi-box"
      },
      skipTo: null
    };
  }
  if (iterator.counter.getOffset() > maxOffset) {
    throw new Error("Oops, this should not happen!");
  }
  return {
    type: "incomplete",
    continueParsing: () => {
      return Promise.resolve(parseMovi({ iterator, maxOffset, state, structure }));
    }
  };
};

// src/boxes/riff/parse-avih.ts
var parseAvih = ({
  iterator,
  size
}) => {
  const { expectNoMoreBytes } = iterator.startBox(size);
  const dwMicroSecPerFrame = iterator.getUint32Le();
  const dwMaxBytesPerSec = iterator.getUint32Le();
  const paddingGranularity = iterator.getUint32Le();
  const flags = iterator.getUint32Le();
  const totalFrames = iterator.getUint32Le();
  const initialFrames = iterator.getUint32Le();
  const streams = iterator.getUint32Le();
  const suggestedBufferSize = iterator.getUint32Le();
  const width = iterator.getUint32Le();
  const height = iterator.getUint32Le();
  iterator.discard(16);
  expectNoMoreBytes();
  return {
    type: "avih-box",
    microSecPerFrame: dwMicroSecPerFrame,
    maxBytesPerSecond: dwMaxBytesPerSec,
    paddingGranularity,
    flags,
    totalFrames,
    initialFrames,
    streams,
    suggestedBufferSize,
    height,
    width
  };
};

// src/boxes/riff/parse-fmt-box.ts
var parseFmtBox = ({
  iterator,
  boxes,
  size
}) => {
  const box = iterator.startBox(size);
  const header = boxes.find((b) => b.type === "riff-header");
  if (!header) {
    throw new Error("Expected RIFF header");
  }
  if (header.fileType !== "WAVE") {
    throw new Error("Only supporting WAVE type");
  }
  const wFormatTag = iterator.getUint16Le();
  if (wFormatTag !== 1) {
    throw new Error("Expected wFormatTag to be 1, only supporting this");
  }
  const numberOfChannels = iterator.getUint16Le();
  const sampleRate = iterator.getUint32Le();
  const byteRate = iterator.getUint32Le();
  const blockAlign = iterator.getUint16Le();
  const bitsPerSample = iterator.getUint16Le();
  box.expectNoMoreBytes();
  return {
    type: "wave-format-box",
    formatTag: wFormatTag,
    numberOfChannels,
    sampleRate,
    blockAlign,
    byteRate,
    bitsPerSample
  };
};

// src/boxes/riff/parse-isft.ts
var parseIsft = ({
  iterator,
  size
}) => {
  const { expectNoMoreBytes } = iterator.startBox(size);
  const software = iterator.getByteString(size - 1, false);
  const last = iterator.getUint8();
  if (last !== 0) {
    throw new Error(`Expected 0 byte, got ${last}`);
  }
  expectNoMoreBytes();
  return {
    type: "isft-box",
    software
  };
};

// src/boxes/riff/parse-list-box.ts
var parseListBox = async ({
  iterator,
  size,
  state
}) => {
  const counter = iterator.counter.getOffset();
  const listType = iterator.getByteString(4, false);
  if (listType === "movi") {
    throw new Error("should not be handled here");
  }
  const structure = {
    type: "riff",
    boxes: []
  };
  const result = await parseRiffBody({
    structure,
    iterator,
    maxOffset: counter + size,
    state
  });
  if (result.status === "incomplete") {
    throw new Error(`Should only parse complete boxes (${listType})`);
  }
  return {
    type: "list-box",
    listType,
    children: structure.boxes
  };
};

// src/boxes/riff/parse-strf.ts
var parseStrfAudio = ({
  iterator,
  size
}) => {
  const box = iterator.startBox(size);
  const formatTag = iterator.getUint16Le();
  const numberOfChannels = iterator.getUint16Le();
  const samplesPerSec = iterator.getUint32Le();
  const avgBytesPerSec = iterator.getUint32Le();
  const blockAlign = iterator.getUint16Le();
  const bitsPerSample = iterator.getUint16Le();
  const cbSize = iterator.getUint16Le();
  box.expectNoMoreBytes();
  return {
    type: "strf-box-audio",
    avgBytesPerSecond: avgBytesPerSec,
    bitsPerSample,
    blockAlign,
    cbSize,
    formatTag,
    numberOfChannels,
    sampleRate: samplesPerSec
  };
};
var parseStrfVideo = ({
  iterator,
  size
}) => {
  const box = iterator.startBox(size);
  const biSize = iterator.getUint32Le();
  const width = iterator.getInt32Le();
  const height = iterator.getInt32Le();
  const planes = iterator.getUint16Le();
  const bitCount = iterator.getUint16Le();
  const compression = iterator.getByteString(4, false);
  const sizeImage = iterator.getUint32Le();
  const xPelsPerMeter = iterator.getInt32Le();
  const yPelsPerMeter = iterator.getInt32Le();
  const clrUsed = iterator.getUint32Le();
  const clrImportant = iterator.getUint32Le();
  box.expectNoMoreBytes();
  return {
    type: "strf-box-video",
    biSize,
    bitCount,
    clrImportant,
    clrUsed,
    compression,
    height,
    planes,
    sizeImage,
    width,
    xPelsPerMeter,
    yPelsPerMeter
  };
};
var parseStrf = ({
  iterator,
  size,
  boxes
}) => {
  const strh = boxes.find((b) => b.type === "strh-box");
  if (!strh) {
    throw new Error("strh box not found");
  }
  if (strh.fccType === "vids") {
    return parseStrfVideo({ iterator, size });
  }
  if (strh.fccType === "auds") {
    return parseStrfAudio({ iterator, size });
  }
  throw new Error(`Unsupported fccType: ${strh.fccType}`);
};

// src/boxes/riff/parse-strh.ts
var parseStrh = ({
  iterator,
  size
}) => {
  const box = iterator.startBox(size);
  const fccType = iterator.getByteString(4, false);
  if (fccType !== "vids" && fccType !== "auds") {
    throw new Error("Expected AVI handler to be vids / auds");
  }
  const handler = fccType === "vids" ? iterator.getByteString(4, false) : iterator.getUint32Le();
  if (typeof handler === "string" && handler !== "H264") {
    throw new Error(`Only H264 is supported as a stream type in .avi, got ${handler}`);
  }
  if (fccType === "auds" && handler !== 1) {
    throw new Error(`Only "1" is supported as a stream type in .avi, got ${handler}`);
  }
  const flags = iterator.getUint32Le();
  const priority = iterator.getUint16Le();
  const language2 = iterator.getUint16Le();
  const initialFrames = iterator.getUint32Le();
  const scale = iterator.getUint32Le();
  const rate = iterator.getUint32Le();
  const start = iterator.getUint32Le();
  const length = iterator.getUint32Le();
  const suggestedBufferSize = iterator.getUint32Le();
  const quality = iterator.getUint32Le();
  const sampleSize = iterator.getUint32Le();
  box.discardRest();
  return {
    type: "strh-box",
    fccType,
    handler,
    flags,
    priority,
    initialFrames,
    length,
    quality,
    rate,
    sampleSize,
    scale,
    start,
    suggestedBufferSize,
    language: language2
  };
};

// src/boxes/riff/parse-riff-box.ts
var parseRiffBox = ({
  iterator,
  size,
  id,
  boxes,
  state
}) => {
  if (id === "fmt") {
    return Promise.resolve(parseFmtBox({ iterator, boxes, size }));
  }
  if (id === "LIST") {
    return parseListBox({ iterator, size, state });
  }
  if (id === "ISFT") {
    return Promise.resolve(parseIsft({ iterator, size }));
  }
  if (id === "avih") {
    return Promise.resolve(parseAvih({ iterator, size }));
  }
  if (id === "strh") {
    return Promise.resolve(parseStrh({ iterator, size }));
  }
  if (id === "strf") {
    return Promise.resolve(parseStrf({ iterator, size, boxes }));
  }
  iterator.discard(size);
  const box = {
    type: "riff-box",
    size,
    id
  };
  return Promise.resolve(box);
};

// src/boxes/riff/expect-riff-box.ts
var expectRiffBox = async ({
  iterator,
  state,
  structure
}) => {
  if (iterator.bytesRemaining() < 16) {
    return {
      type: "incomplete",
      continueParsing() {
        return expectRiffBox({ structure, iterator, state });
      }
    };
  }
  const ckId = iterator.getByteString(4, false);
  const ckSize = iterator.getUint32Le();
  if (isMoviAtom(iterator, ckId)) {
    iterator.discard(4);
    return parseMovi({
      iterator,
      maxOffset: ckSize + iterator.counter.getOffset() - 4,
      state,
      structure
    });
  }
  if (iterator.bytesRemaining() < ckSize) {
    iterator.counter.decrement(8);
    return {
      type: "incomplete",
      continueParsing: () => {
        return expectRiffBox({ structure, iterator, state });
      }
    };
  }
  return {
    type: "complete",
    box: await parseRiffBox({
      id: ckId,
      iterator,
      size: ckSize,
      boxes: structure.boxes,
      state
    }),
    skipTo: null
  };
};

// src/boxes/riff/parse-box.ts
var continueAfterRiffBoxResult = ({
  result,
  structure,
  iterator,
  maxOffset,
  state: options
}) => {
  if (result.type === "incomplete") {
    return Promise.resolve({
      status: "incomplete",
      async continueParsing() {
        return Promise.resolve(continueAfterRiffBoxResult({
          result: await result.continueParsing(),
          structure,
          iterator,
          maxOffset,
          state: options
        }));
      },
      segments: structure,
      skipTo: null
    });
  }
  if (result.type === "complete" && result.box) {
    structure.boxes.push(result.box);
  }
  return parseRiffBody({ iterator, maxOffset, state: options, structure });
};
var parseRiffBody = async ({
  iterator,
  structure,
  maxOffset,
  state
}) => {
  while (iterator.bytesRemaining() > 0 && iterator.counter.getOffset() < maxOffset) {
    const result = await expectRiffBox({
      iterator,
      state,
      structure
    });
    if (result.type === "complete" && result.skipTo !== null) {
      return {
        status: "incomplete",
        skipTo: result.skipTo,
        continueParsing() {
          return Promise.resolve(continueAfterRiffBoxResult({
            iterator,
            maxOffset,
            state,
            result,
            structure
          }));
        }
      };
    }
    if (result.type === "incomplete") {
      return {
        status: "incomplete",
        async continueParsing() {
          return Promise.resolve(continueAfterRiffBoxResult({
            iterator,
            maxOffset,
            state,
            result: await result.continueParsing(),
            structure
          }));
        },
        skipTo: null
      };
    }
    if (result.box === null) {
      continue;
    }
    structure.boxes.push(result.box);
    if (result.box.type === "list-box" && result.box.listType === "hdrl") {
      const tracks2 = getTracks(structure, state);
      if (!tracks2.videoTracks.some((t) => t.codec === TO_BE_OVERRIDDEN_LATER)) {
        state.callbacks.tracks.setIsDone();
      }
    }
    if (result.box.type === "wave-format-box") {
      state.callbacks.tracks.setIsDone();
    }
    if (result.box.type === "strf-box-video" || result.box.type === "strf-box-audio") {
      const strh = getStrhBox(structure.boxes);
      const strf = getStrfBox(structure.boxes);
      if (!strh || !strf) {
        throw new Error("strh or strf box missing");
      }
      if (strf.type === "strf-box-audio" && state.onAudioTrack) {
        const audioTrack = makeAviAudioTrack({
          index: state.riff.getNextTrackIndex(),
          strf
        });
        await registerTrack({
          state,
          track: audioTrack,
          container: "avi"
        });
      }
      if (state.onVideoTrack && strf.type === "strf-box-video") {
        const videoTrack = makeAviVideoTrack({
          strh,
          index: state.riff.getNextTrackIndex(),
          strf
        });
        registerVideoTrackWhenProfileIsAvailable({
          state,
          track: videoTrack,
          container: "avi"
        });
      }
      state.riff.incrementNextTrackIndex();
    }
  }
  return {
    status: "done"
  };
};
var parseRiff = ({
  iterator,
  state,
  fields
}) => {
  const riff = iterator.getByteString(4, false);
  if (riff !== "RIFF") {
    throw new Error("Not a RIFF file");
  }
  const structure = state.structure.getStructure();
  if (structure.type !== "riff") {
    throw new Error("Structure is not a RIFF structure");
  }
  const size = iterator.getUint32Le();
  const fileType = iterator.getByteString(4, false);
  if (fileType !== "WAVE" && fileType !== "AVI") {
    throw new Error(`File type ${fileType} not supported`);
  }
  structure.boxes.push({ type: "riff-header", fileSize: size, fileType });
  if (hasAllInfo({ fields, state })) {
    return Promise.resolve({
      status: "done",
      segments: structure
    });
  }
  return parseRiffBody({
    iterator,
    maxOffset: Infinity,
    state,
    structure
  });
};

// src/boxes/transport-stream/next-pes-header-store.ts
var makeNextPesHeaderStore = () => {
  let nextPesHeader = null;
  return {
    setNextPesHeader: (pesHeader) => {
      nextPesHeader = pesHeader;
    },
    getNextPesHeader: () => {
      if (!nextPesHeader) {
        throw new Error("No next PES header found");
      }
      return nextPesHeader;
    }
  };
};

// src/boxes/transport-stream/discard-rest-of-packet.ts
var discardRestOfPacket = (iterator) => {
  const next188 = 188 - iterator.counter.getOffset() % 188;
  iterator.discard(next188);
};
var getRestOfPacket = (iterator) => {
  const next188 = 188 - iterator.counter.getOffset() % 188;
  return iterator.getSlice(next188);
};

// src/boxes/transport-stream/parse-pat.ts
var parsePatTable = (iterator, tableId) => {
  iterator.getUint16();
  iterator.startReadingBits();
  iterator.getBits(7);
  iterator.getBits(1);
  const sectionNumber = iterator.getBits(8);
  const lastSectionNumber = iterator.getBits(8);
  if (tableId !== 0) {
    throw new Error("Invalid table ID: " + tableId);
  }
  const tables = [];
  for (let i = sectionNumber;i <= lastSectionNumber; i++) {
    const programNumber = iterator.getBits(16);
    iterator.getBits(3);
    const programMapIdentifier = iterator.getBits(13);
    tables.push({
      type: "transport-stream-program-association-table",
      programNumber,
      programMapIdentifier
    });
  }
  iterator.stopReadingBits();
  return {
    type: "transport-stream-pat-box",
    tableId: tableId.toString(16),
    pat: tables
  };
};
var parsePat = (iterator) => {
  iterator.startReadingBits();
  const tableId = iterator.getBits(8);
  iterator.getBits(1);
  iterator.getBits(1);
  iterator.getBits(4);
  const sectionLength = iterator.getBits(10);
  if (sectionLength > 1021) {
    throw new Error("Invalid section length");
  }
  iterator.stopReadingBits();
  const tables = parsePatTable(iterator, tableId);
  discardRestOfPacket(iterator);
  return tables;
};

// src/boxes/transport-stream/parse-pes.ts
var parsePes = (iterator) => {
  const ident = iterator.getUint24();
  if (ident !== 1) {
    throw new Error(`Unexpected PES packet start code: ${ident.toString(16)}`);
  }
  const streamId = iterator.getUint8();
  iterator.getUint16();
  iterator.startReadingBits();
  const markerBits = iterator.getBits(2);
  if (markerBits !== 2) {
    throw new Error(`Invalid marker bits: ${markerBits}`);
  }
  const scrambled = iterator.getBits(2);
  if (scrambled !== 0) {
    throw new Error(`Only supporting non-scrambled streams`);
  }
  const priority = iterator.getBits(1);
  iterator.getBits(1);
  iterator.getBits(1);
  iterator.getBits(1);
  const ptsPresent = iterator.getBits(1);
  const dtsPresent = iterator.getBits(1);
  if (!ptsPresent && dtsPresent) {
    throw new Error(`DTS is present but not PTS, this is not allowed in the spec`);
  }
  iterator.getBits(1);
  iterator.getBits(1);
  iterator.getBits(1);
  iterator.getBits(1);
  iterator.getBits(1);
  iterator.getBits(1);
  const pesHeaderLength = iterator.getBits(8);
  const offset = iterator.counter.getOffset();
  let pts = null;
  if (!ptsPresent) {
    throw new Error(`PTS is required`);
  }
  const fourBits = iterator.getBits(4);
  if (fourBits !== 3 && fourBits !== 2) {
    throw new Error(`Invalid PTS marker bits: ${fourBits}`);
  }
  const pts1 = iterator.getBits(3);
  iterator.getBits(1);
  const pts2 = iterator.getBits(15);
  iterator.getBits(1);
  const pts3 = iterator.getBits(15);
  iterator.getBits(1);
  pts = pts1 << 30 | pts2 << 15 | pts3;
  let dts = null;
  if (dtsPresent) {
    const _fourBits = iterator.getBits(4);
    if (_fourBits !== 1) {
      throw new Error(`Invalid DTS marker bits: ${_fourBits}`);
    }
    const dts1 = iterator.getBits(3);
    iterator.getBits(1);
    const dts2 = iterator.getBits(15);
    iterator.getBits(1);
    const dts3 = iterator.getBits(15);
    iterator.getBits(1);
    dts = dts1 << 30 | dts2 << 15 | dts3;
  }
  iterator.stopReadingBits();
  iterator.discard(pesHeaderLength - (iterator.counter.getOffset() - offset));
  const packet = {
    dts,
    pts,
    streamId,
    priority
  };
  return packet;
};

// src/boxes/transport-stream/parse-pmt.ts
var parsePmtTable = ({
  iterator,
  tableId,
  sectionLength
}) => {
  const start = iterator.counter.getOffset();
  iterator.getUint16();
  iterator.startReadingBits();
  iterator.getBits(7);
  iterator.getBits(1);
  const sectionNumber = iterator.getBits(8);
  const lastSectionNumber = iterator.getBits(8);
  const tables = [];
  for (let i = sectionNumber;i <= lastSectionNumber; i++) {
    iterator.getBits(3);
    iterator.getBits(13);
    iterator.getBits(4);
    const programInfoLength = iterator.getBits(12);
    const streams = [];
    while (true) {
      const streamType = iterator.getBits(8);
      iterator.getBits(3);
      const elementaryPid = iterator.getBits(13);
      iterator.getBits(4);
      const esInfoLength = iterator.getBits(12);
      iterator.getBits(esInfoLength * 8);
      streams.push({ streamType, pid: elementaryPid });
      iterator.getBits(programInfoLength * 8);
      const remaining = sectionLength - (iterator.counter.getOffset() - start);
      if (remaining <= 4) {
        break;
      }
    }
    tables.push({
      type: "transport-stream-program-map-table",
      streams
    });
  }
  if (tables.length !== 1) {
    throw new Error("Does not PMT table with more than 1 entry, uncommon");
  }
  iterator.stopReadingBits();
  return {
    type: "transport-stream-pmt-box",
    tableId,
    streams: tables[0].streams
  };
};
var parsePmt = (iterator) => {
  iterator.startReadingBits();
  const tableId = iterator.getBits(8);
  iterator.getBits(1);
  iterator.getBits(1);
  iterator.getBits(4);
  const sectionLength = iterator.getBits(10);
  if (sectionLength > 1021) {
    throw new Error("Invalid section length");
  }
  iterator.stopReadingBits();
  const tables = parsePmtTable({ iterator, tableId, sectionLength });
  discardRestOfPacket(iterator);
  return tables;
};

// src/boxes/transport-stream/adts-header.ts
var readAdtsHeader = (buffer) => {
  if (buffer.byteLength < 9) {
    return null;
  }
  const iterator = getArrayBufferIterator(buffer, buffer.byteLength);
  iterator.startReadingBits();
  const bits = iterator.getBits(12);
  if (bits !== 4095) {
    throw new Error("Invalid ADTS header ");
  }
  const id = iterator.getBits(1);
  if (id !== 0) {
    throw new Error("Only supporting MPEG-4 for .ts");
  }
  const layer = iterator.getBits(2);
  if (layer !== 0) {
    throw new Error("Only supporting layer 0 for .ts");
  }
  const protectionAbsent = iterator.getBits(1);
  const audioObjectType = iterator.getBits(2);
  const samplingFrequencyIndex = iterator.getBits(4);
  const sampleRate = getSampleRateFromSampleFrequencyIndex(samplingFrequencyIndex);
  iterator.getBits(1);
  const channelConfiguration = iterator.getBits(3);
  const codecPrivate2 = createAacCodecPrivate({
    audioObjectType,
    sampleRate,
    channelConfiguration
  });
  iterator.getBits(1);
  iterator.getBits(1);
  iterator.getBits(1);
  iterator.getBits(1);
  const frameLength = iterator.getBits(13);
  iterator.getBits(11);
  iterator.getBits(2);
  if (!protectionAbsent) {
    iterator.getBits(16);
  }
  iterator.stopReadingBits();
  iterator.destroy();
  return {
    frameLength,
    codecPrivate: codecPrivate2,
    channelConfiguration,
    sampleRate,
    audioObjectType
  };
};

// src/boxes/transport-stream/find-separator.ts
function findSubarrayIndex(array, subarray) {
  const subarrayLength = subarray.length;
  const arrayLength = array.length;
  for (let i = 0;i <= arrayLength - subarrayLength; i++) {
    let match = true;
    for (let j = 0;j < subarrayLength; j++) {
      if (array[i + j] !== subarray[j]) {
        match = false;
        break;
      }
    }
    if (match) {
      if (subarray[i - 1] === 0) {
        i--;
      }
      return i;
    }
  }
  return -1;
}
var findNextSeparator = (restOfPacket, transportStreamEntry) => {
  if (transportStreamEntry.streamType === 27) {
    return findSubarrayIndex(restOfPacket, new Uint8Array([0, 0, 1, 9]));
  }
  throw new Error(`Unsupported stream ID ${transportStreamEntry.streamType}`);
};

// src/boxes/avc/interpret-sps.ts
var getDimensionsFromSps = (sps) => {
  const height = sps.pic_height_in_map_units_minus1;
  const width = sps.pic_width_in_mbs_minus1;
  return {
    height: (height + 1) * 16,
    width: (width + 1) * 16
  };
};
var getSampleAspectRatioFromSps = (sps) => {
  if (sps.vui_parameters?.sar_height && sps.vui_parameters.sar_width) {
    return {
      width: sps.vui_parameters.sar_width,
      height: sps.vui_parameters.sar_height
    };
  }
  return {
    width: 1,
    height: 1
  };
};
var getVideoColorFromSps = (sps) => {
  const matrixCoefficients2 = sps.vui_parameters?.matrix_coefficients;
  const transferCharacteristics2 = sps.vui_parameters?.transfer_characteristics;
  const colorPrimaries = sps.vui_parameters?.colour_primaries;
  return {
    matrixCoefficients: matrixCoefficients2 ? getMatrixCoefficientsFromIndex(matrixCoefficients2) : null,
    transferCharacteristics: transferCharacteristics2 ? getTransferCharacteristicsFromIndex(transferCharacteristics2) : null,
    primaries: colorPrimaries ? getPrimariesFromIndex(colorPrimaries) : null,
    fullRange: sps.vui_parameters?.video_full_range_flag ?? null
  };
};

// src/boxes/avc/sps-and-pps.ts
var getSpsAndPps = (infos) => {
  const avcProfile = infos.find((i) => i.type === "avc-profile");
  const ppsProfile = infos.find((i) => i.type === "avc-pps");
  if (!avcProfile || !ppsProfile) {
    throw new Error("Expected avcProfile and ppsProfile");
  }
  return { pps: ppsProfile, sps: avcProfile };
};

// src/boxes/transport-stream/handle-avc-packet.ts
var MPEG_TIMESCALE = 90000;
var handleAvcPacket = async ({
  streamBuffer,
  programId,
  state,
  offset
}) => {
  const avc = parseAvc(streamBuffer.buffer);
  const isTrackRegistered = state.callbacks.tracks.getTracks().find((t) => {
    return t.trackId === programId;
  });
  if (!isTrackRegistered) {
    const spsAndPps = getSpsAndPps(avc);
    const dimensions = getDimensionsFromSps(spsAndPps.sps.spsData);
    const sampleAspectRatio = getSampleAspectRatioFromSps(spsAndPps.sps.spsData);
    const track = {
      rotation: 0,
      trackId: programId,
      type: "video",
      timescale: MPEG_TIMESCALE,
      codec: getCodecStringFromSpsAndPps(spsAndPps.sps),
      codecPrivate: createSpsPpsData(spsAndPps),
      fps: null,
      codedWidth: dimensions.width,
      codedHeight: dimensions.height,
      height: dimensions.height,
      width: dimensions.width,
      displayAspectWidth: dimensions.width,
      displayAspectHeight: dimensions.height,
      trakBox: null,
      codecWithoutConfig: "h264",
      description: undefined,
      sampleAspectRatio: {
        denominator: sampleAspectRatio.height,
        numerator: sampleAspectRatio.width
      },
      color: getVideoColorFromSps(spsAndPps.sps.spsData)
    };
    await registerTrack({ track, state, container: "transport-stream" });
  }
  const sample = {
    cts: streamBuffer.pesHeader.pts,
    dts: streamBuffer.pesHeader.dts ?? streamBuffer.pesHeader.pts,
    timestamp: streamBuffer.pesHeader.pts,
    duration: undefined,
    data: new Uint8Array(streamBuffer.buffer),
    trackId: programId,
    type: getKeyFrameOrDeltaFromAvcInfo(avc),
    offset,
    timescale: MPEG_TIMESCALE
  };
  await state.callbacks.onVideoSample(programId, convertAudioOrVideoSampleToWebCodecsTimestamps(sample, MPEG_TIMESCALE));
};

// src/boxes/transport-stream/handle-aac-packet.ts
var handleAacPacket = async ({
  streamBuffer,
  state,
  programId,
  offset
}) => {
  const adtsHeader = readAdtsHeader(streamBuffer.buffer);
  if (!adtsHeader) {
    throw new Error("Invalid ADTS header - too short");
  }
  const { channelConfiguration, codecPrivate: codecPrivate2, sampleRate, audioObjectType } = adtsHeader;
  const isTrackRegistered = state.callbacks.tracks.getTracks().find((t) => {
    return t.trackId === programId;
  });
  if (!isTrackRegistered) {
    const track = {
      type: "audio",
      codecPrivate: codecPrivate2,
      trackId: programId,
      trakBox: null,
      timescale: MPEG_TIMESCALE,
      codecWithoutConfig: "aac",
      codec: mapAudioObjectTypeToCodecString(audioObjectType),
      description: undefined,
      numberOfChannels: channelConfiguration,
      sampleRate
    };
    await registerTrack({
      track,
      state,
      container: "transport-stream"
    });
  }
  const sample = {
    cts: streamBuffer.pesHeader.pts,
    dts: streamBuffer.pesHeader.dts ?? streamBuffer.pesHeader.pts,
    timestamp: streamBuffer.pesHeader.pts,
    duration: undefined,
    data: new Uint8Array(streamBuffer.buffer),
    trackId: programId,
    type: "key",
    offset,
    timescale: MPEG_TIMESCALE
  };
  await state.callbacks.onAudioSample(programId, convertAudioOrVideoSampleToWebCodecsTimestamps(sample, MPEG_TIMESCALE));
};

// src/boxes/transport-stream/process-stream-buffers.ts
var processStreamBuffer = async ({
  streamBuffer,
  state,
  programId,
  structure
}) => {
  const stream = getStreamForId(structure, programId);
  if (!stream) {
    throw new Error("No stream found");
  }
  if (stream.streamType === 27) {
    await handleAvcPacket({
      programId,
      streamBuffer,
      state,
      offset: streamBuffer.offset
    });
  } else if (stream.streamType === 15) {
    await handleAacPacket({
      streamBuffer,
      state,
      programId,
      offset: streamBuffer.offset
    });
  }
  if (!state.callbacks.tracks.hasAllTracks()) {
    const tracksRegistered = state.callbacks.tracks.getTracks().length;
    const { streams } = findProgramMapTableOrThrow(structure);
    if (streams.length === tracksRegistered) {
      state.callbacks.tracks.setIsDone();
    }
  }
};
var processFinalStreamBuffers = async ({
  streamBufferMap,
  state,
  structure
}) => {
  for (const [programId, buffer] of streamBufferMap) {
    if (buffer.buffer.byteLength > 0) {
      await processStreamBuffer({
        streamBuffer: buffer,
        state,
        programId,
        structure
      });
      streamBufferMap.delete(programId);
    }
  }
};

// src/boxes/transport-stream/parse-stream-packet.ts
var parseAdtsStream = async ({
  restOfPacket,
  transportStreamEntry,
  streamBuffers,
  nextPesHeader,
  state,
  structure,
  offset
}) => {
  const streamBuffer = streamBuffers.get(transportStreamEntry.pid);
  if (!streamBuffer) {
    streamBuffers.set(transportStreamEntry.pid, {
      buffer: restOfPacket,
      pesHeader: nextPesHeader,
      offset
    });
    return;
  }
  const expectedLength = readAdtsHeader(streamBuffer.buffer)?.frameLength ?? null;
  const bytesToTake = expectedLength ? Math.min(restOfPacket.length, expectedLength - streamBuffer.buffer.byteLength) : restOfPacket.length;
  streamBuffer.buffer = combineUint8Arrays([
    streamBuffer.buffer,
    restOfPacket.slice(0, bytesToTake)
  ]);
  if (expectedLength === streamBuffer.buffer.byteLength) {
    await processStreamBuffer({
      streamBuffer,
      programId: transportStreamEntry.pid,
      state,
      structure
    });
    const rest = restOfPacket.slice(bytesToTake);
    streamBuffers.set(transportStreamEntry.pid, {
      buffer: rest,
      pesHeader: nextPesHeader,
      offset
    });
  }
};
var parseAvcStream = async ({
  restOfPacket,
  transportStreamEntry,
  streamBuffers,
  nextPesHeader,
  programId,
  state,
  structure,
  offset
}) => {
  const indexOfSeparator = findNextSeparator(restOfPacket, transportStreamEntry);
  const streamBuffer = streamBuffers.get(transportStreamEntry.pid);
  if (indexOfSeparator === -1) {
    if (streamBuffer) {
      streamBuffer.buffer = combineUint8Arrays([
        streamBuffer.buffer,
        restOfPacket
      ]);
      return;
    }
    streamBuffers.set(programId, {
      pesHeader: nextPesHeader,
      buffer: restOfPacket,
      offset
    });
    return;
  }
  if (streamBuffer) {
    const packet = restOfPacket.slice(0, indexOfSeparator);
    streamBuffer.buffer = combineUint8Arrays([streamBuffer.buffer, packet]);
    await processStreamBuffer({
      state,
      streamBuffer,
      programId,
      structure
    });
    const rest = restOfPacket.slice(indexOfSeparator);
    streamBuffers.set(programId, {
      pesHeader: nextPesHeader,
      buffer: rest,
      offset
    });
    return;
  }
  if (indexOfSeparator !== 0) {
    throw new Error("No stream buffer found but new separator is not at the beginning");
  }
  streamBuffers.set(programId, {
    pesHeader: nextPesHeader,
    buffer: restOfPacket.slice(indexOfSeparator),
    offset
  });
};
var parseStream = ({
  iterator,
  transportStreamEntry,
  streamBuffers,
  state,
  programId,
  structure,
  nextPesHeader
}) => {
  const restOfPacket = getRestOfPacket(iterator);
  if (transportStreamEntry.streamType === 27) {
    return parseAvcStream({
      restOfPacket,
      transportStreamEntry,
      streamBuffers,
      nextPesHeader,
      state,
      programId,
      structure,
      offset: iterator.counter.getOffset()
    });
  }
  if (transportStreamEntry.streamType === 15) {
    return parseAdtsStream({
      restOfPacket,
      transportStreamEntry,
      streamBuffers,
      nextPesHeader,
      state,
      structure,
      offset: iterator.counter.getOffset()
    });
  }
  throw new Error(`Unsupported stream type ${transportStreamEntry.streamType}`);
};

// src/boxes/transport-stream/parse-packet.ts
var parsePacket = async ({
  iterator,
  structure,
  streamBuffers,
  parserState,
  nextPesHeaderStore
}) => {
  const offset = iterator.counter.getOffset();
  const syncByte = iterator.getUint8();
  if (syncByte !== 71) {
    throw new Error("Invalid sync byte");
  }
  iterator.startReadingBits();
  iterator.getBits(1);
  const payloadUnitStartIndicator = iterator.getBits(1);
  iterator.getBits(1);
  const programId = iterator.getBits(13);
  iterator.getBits(2);
  const adaptationFieldControl1 = iterator.getBits(1);
  iterator.getBits(1);
  iterator.getBits(4);
  iterator.stopReadingBits();
  if (adaptationFieldControl1 === 1) {
    iterator.startReadingBits();
    const adaptationFieldLength = iterator.getBits(8);
    const headerOffset = iterator.counter.getOffset();
    if (adaptationFieldLength > 0) {
      iterator.getBits(1);
      iterator.getBits(1);
      iterator.getBits(1);
      iterator.getBits(1);
      iterator.getBits(1);
      iterator.getBits(1);
      iterator.getBits(1);
      iterator.getBits(1);
    }
    const remaining = adaptationFieldLength - (iterator.counter.getOffset() - headerOffset);
    iterator.stopReadingBits();
    const toDiscard = Math.max(0, remaining);
    iterator.discard(toDiscard);
  }
  const read = iterator.counter.getOffset() - offset;
  if (read === 188) {
    return Promise.resolve(null);
  }
  const pat = structure.boxes.find((b) => b.type === "transport-stream-pmt-box");
  const isPes = payloadUnitStartIndicator && pat?.streams.find((e) => e.pid === programId);
  if (isPes) {
    const packetPes = parsePes(iterator);
    nextPesHeaderStore.setNextPesHeader(packetPes);
  } else if (payloadUnitStartIndicator === 1) {
    iterator.getUint8();
  }
  if (programId === 0) {
    return Promise.resolve(parsePat(iterator));
  }
  const program = getProgramForId(structure, programId);
  if (program) {
    const pmt = parsePmt(iterator);
    return Promise.resolve(pmt);
  }
  const stream = getStreamForId(structure, programId);
  if (stream) {
    await parseStream({
      iterator,
      transportStreamEntry: stream,
      streamBuffers,
      nextPesHeader: nextPesHeaderStore.getNextPesHeader(),
      state: parserState,
      programId,
      structure
    });
    return Promise.resolve(null);
  }
  throw new Error("Unknown packet identifier");
};

// src/boxes/transport-stream/parse-transport-stream.ts
var parseTransportStream = async ({
  iterator,
  state,
  streamBuffers,
  fields,
  nextPesHeaderStore
}) => {
  const structure = state.structure.getStructure();
  if (structure.type !== "transport-stream") {
    throw new Error("Invalid structure type");
  }
  if (iterator.bytesRemaining() === 0) {
    await processFinalStreamBuffers({
      streamBufferMap: streamBuffers,
      state,
      structure
    });
    return Promise.resolve({
      status: "done",
      segments: structure
    });
  }
  while (true) {
    if (hasAllInfo({
      fields,
      state
    })) {
      break;
    }
    if (iterator.bytesRemaining() < 188) {
      return Promise.resolve({
        status: "incomplete",
        segments: structure,
        skipTo: null,
        continueParsing: () => {
          return parseTransportStream({
            iterator,
            state,
            streamBuffers,
            fields,
            nextPesHeaderStore
          });
        }
      });
    }
    const packet = await parsePacket({
      iterator,
      structure,
      streamBuffers,
      parserState: state,
      nextPesHeaderStore
    });
    if (packet) {
      structure.boxes.push(packet);
      break;
    }
  }
  return Promise.resolve({
    segments: structure,
    status: "incomplete",
    continueParsing() {
      return parseTransportStream({
        iterator,
        state,
        streamBuffers,
        fields,
        nextPesHeaderStore
      });
    },
    skipTo: null
  });
};

// src/boxes/webm/parse-webm-header.ts
var continueAfterMatroskaResult = (result, structure) => {
  if (result.status === "done") {
    return {
      status: "done"
    };
  }
  return {
    status: "incomplete",
    continueParsing: async () => {
      const newResult = await result.continueParsing();
      return continueAfterMatroskaResult(newResult, structure);
    },
    skipTo: null
  };
};
var parseWebm = async ({
  counter,
  state,
  fields
}) => {
  const structure = state.structure.getStructure();
  if (structure.type !== "matroska") {
    throw new Error("Invalid structure type");
  }
  const results = await expectChildren({
    iterator: counter,
    length: Infinity,
    children: structure.boxes,
    state,
    startOffset: counter.counter.getOffset(),
    fields,
    topLevelStructure: structure
  });
  return continueAfterMatroskaResult(results, structure);
};

// src/parse-video.ts
var parseVideo = ({
  iterator,
  state,
  signal,
  logLevel,
  fields,
  mimeType,
  contentLength,
  name
}) => {
  if (iterator.bytesRemaining() === 0) {
    return Promise.reject(new Error("no bytes"));
  }
  const fileType = iterator.detectFileType();
  if (fileType.type === "riff") {
    Log.verbose(logLevel, "Detected RIFF container");
    state.structure.setStructure({
      type: "riff",
      boxes: []
    });
    return Promise.resolve(parseRiff({ iterator, state, fields }));
  }
  if (fileType.type === "iso-base-media") {
    Log.verbose(logLevel, "Detected ISO Base Media container");
    const initialBoxes = [];
    state.structure.setStructure({
      type: "iso-base-media",
      boxes: initialBoxes
    });
    return parseIsoBaseMediaBoxes({
      iterator,
      maxBytes: Infinity,
      allowIncompleteBoxes: true,
      initialBoxes,
      state,
      continueMdat: false,
      signal,
      logLevel,
      fields
    });
  }
  if (fileType.type === "webm") {
    Log.verbose(logLevel, "Detected Matroska container");
    state.structure.setStructure({
      boxes: [],
      type: "matroska"
    });
    return parseWebm({ counter: iterator, state, fields });
  }
  if (fileType.type === "transport-stream") {
    Log.verbose(logLevel, "Detected MPEG-2 Transport Stream");
    state.structure.setStructure({
      boxes: [],
      type: "transport-stream"
    });
    return parseTransportStream({
      iterator,
      state,
      streamBuffers: new Map,
      fields,
      nextPesHeaderStore: makeNextPesHeaderStore()
    });
  }
  if (fileType.type === "mp3") {
    return Promise.reject(new IsAnUnsupportedAudioTypeError({
      message: "MP3 files are not yet supported",
      mimeType,
      sizeInBytes: contentLength,
      fileName: name,
      audioType: "mp3"
    }));
  }
  if (fileType.type === "wav") {
    return Promise.reject(new IsAnUnsupportedAudioTypeError({
      message: "WAV files are not yet supported",
      mimeType,
      sizeInBytes: contentLength,
      fileName: name,
      audioType: "wav"
    }));
  }
  if (fileType.type === "aac") {
    return Promise.reject(new IsAnUnsupportedAudioTypeError({
      message: "AAC files are not yet supported",
      mimeType,
      sizeInBytes: contentLength,
      fileName: name,
      audioType: "aac"
    }));
  }
  if (fileType.type === "gif") {
    return Promise.reject(new IsAGifError({
      message: "GIF files are not yet supported",
      mimeType,
      sizeInBytes: contentLength,
      fileName: name
    }));
  }
  if (fileType.type === "pdf") {
    return Promise.reject(new IsAPdfError({
      message: "GIF files are not supported",
      mimeType,
      sizeInBytes: contentLength,
      fileName: name
    }));
  }
  if (fileType.type === "bmp" || fileType.type === "jpeg" || fileType.type === "png" || fileType.type === "webp") {
    return Promise.reject(new IsAnImageError({
      message: "Image files are not supported",
      imageType: fileType.type,
      dimensions: fileType.dimensions,
      mimeType,
      sizeInBytes: contentLength,
      fileName: name
    }));
  }
  if (fileType.type === "unknown") {
    return Promise.reject(new IsAnUnsupportedFileTypeError({
      message: "Unknown file format",
      mimeType,
      sizeInBytes: contentLength,
      fileName: name
    }));
  }
  return Promise.reject(new Error("Unknown video format " + fileType));
};

// src/parse-media.ts
var parseMedia = async function({
  src,
  fields: _fieldsInReturnValue,
  reader: readerInterface = fetchReader,
  onAudioTrack,
  onVideoTrack,
  signal,
  logLevel = "info",
  onParseProgress,
  ...more
}) {
  let iterator = null;
  let parseResult = null;
  const fieldsInReturnValue = _fieldsInReturnValue ?? {};
  const fields = getFieldsFromCallback({
    fields: fieldsInReturnValue,
    callbacks: more
  });
  const {
    reader,
    contentLength,
    name,
    contentType,
    supportsContentRange: readerSupportsContentRange
  } = await readerInterface.read(src, null, signal);
  const supportsContentRange = readerSupportsContentRange && !(typeof process !== "undefined" && typeof process.env !== "undefined" && process.env.DISABLE_CONTENT_RANGE === "true");
  const state = makeParserState({
    hasAudioTrackHandlers: Boolean(onAudioTrack),
    hasVideoTrackHandlers: Boolean(onVideoTrack),
    signal,
    getIterator: () => iterator,
    fields,
    onAudioTrack: onAudioTrack ?? null,
    onVideoTrack: onVideoTrack ?? null,
    supportsContentRange
  });
  let currentReader = reader;
  const returnValue = {};
  const moreFields = more;
  const triggerInfoEmit = () => {
    const availableInfo = getAvailableInfo({
      fieldsToFetch: fields,
      state
    });
    emitAvailableInfo({
      hasInfo: availableInfo,
      callbacks: moreFields,
      fieldsInReturnValue,
      parseResult,
      state,
      returnValue,
      contentLength,
      name,
      mimeType: contentType
    });
  };
  triggerInfoEmit();
  while (parseResult === null || parseResult.status === "incomplete") {
    while (true) {
      if (signal?.aborted) {
        throw new Error("Aborted");
      }
      const result = await currentReader.reader.read();
      if (iterator) {
        if (!result.done) {
          iterator.addData(result.value);
        }
      } else {
        if (result.done) {
          throw new Error("Unexpectedly reached EOF");
        }
        iterator = getArrayBufferIterator(result.value, contentLength ?? 1e9);
      }
      if (iterator.bytesRemaining() >= 0) {
        break;
      }
      if (result.done) {
        break;
      }
    }
    if (!iterator) {
      throw new Error("Unexpected null");
    }
    await onParseProgress?.({
      bytes: iterator.counter.getOffset(),
      percentage: contentLength ? iterator.counter.getOffset() / contentLength : null,
      totalBytes: contentLength
    });
    triggerInfoEmit();
    if (parseResult && parseResult.status === "incomplete") {
      Log.trace(logLevel, "Continuing parsing of file, currently at position", iterator.counter.getOffset());
      parseResult = await parseResult.continueParsing();
    } else {
      parseResult = await parseVideo({
        iterator,
        state,
        signal: signal ?? null,
        logLevel,
        fields,
        mimeType: contentType,
        contentLength,
        name
      });
    }
    if (parseResult.status === "incomplete" && parseResult.skipTo !== null) {
      state.increaseSkippedBytes(parseResult.skipTo - iterator.counter.getOffset());
    }
    if (hasAllInfo({
      fields,
      state
    })) {
      Log.verbose(logLevel, "Got all info, skipping to the end.");
      if (contentLength !== null) {
        state.increaseSkippedBytes(contentLength - iterator.counter.getOffset());
      }
      break;
    }
    if (parseResult.status === "incomplete" && parseResult.skipTo !== null) {
      if (!supportsContentRange) {
        throw new Error("Content-Range header is not supported by the reader, but was asked to seek");
      }
      if (parseResult.skipTo === contentLength) {
        Log.verbose(logLevel, "Skipped to end of file, not fetching.");
        break;
      }
      Log.verbose(logLevel, `Skipping over video data from position ${iterator.counter.getOffset()} -> ${parseResult.skipTo}`);
      currentReader.abort();
      const { reader: newReader } = await readerInterface.read(src, parseResult.skipTo, signal);
      currentReader = newReader;
      iterator.skipTo(parseResult.skipTo, true);
    }
  }
  Log.verbose(logLevel, "Finished parsing file");
  const hasInfo = Object.keys(fields).reduce((acc, key) => {
    if (fields?.[key]) {
      acc[key] = true;
    }
    return acc;
  }, {});
  emitAvailableInfo({
    hasInfo,
    callbacks: moreFields,
    fieldsInReturnValue,
    parseResult,
    state,
    returnValue,
    contentLength,
    mimeType: contentType,
    name
  });
  currentReader.abort();
  iterator?.destroy();
  state.callbacks.tracks.ensureHasTracksAtEnd();
  return returnValue;
};
// src/version.ts
var VERSION = "4.0.247";

// src/index.ts
var MediaParserInternals = {
  Log,
  createAacCodecPrivate,
  matroskaElements,
  ebmlMap,
  parseTkhd,
  getArrayBufferIterator,
  parseStsd,
  makeParserState,
  processSample,
  parseFtyp,
  parseEbml,
  parseMvhd
};
export {
  parseMedia,
  VERSION,
  MediaParserInternals,
  IsAnUnsupportedFileTypeError,
  IsAnUnsupportedAudioTypeError,
  IsAnImageError,
  IsAPdfError,
  IsAGifError
};
