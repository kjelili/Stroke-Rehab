"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.parseMovi = exports.handleChunk = void 0;
const convert_audio_or_video_sample_1 = require("../../convert-audio-or-video-sample");
const may_skip_video_data_1 = require("../../may-skip-video-data/may-skip-video-data");
const key_1 = require("../avc/key");
const parse_avc_1 = require("../avc/parse-avc");
const traversal_1 = require("./traversal");
const getStrhForIndex = (structure, trackId) => {
    const boxes = (0, traversal_1.getStrlBoxes)(structure);
    const box = boxes[trackId];
    if (!box) {
        throw new Error('Expected box');
    }
    const strh = (0, traversal_1.getStrhBox)(box.children);
    if (!strh) {
        throw new Error('strh');
    }
    return strh;
};
const handleChunk = async ({ iterator, state, structure, ckId, ckSize, }) => {
    const offset = iterator.counter.getOffset();
    const videoChunk = ckId.match(/^([0-9]{2})dc$/);
    if (videoChunk) {
        const trackId = parseInt(videoChunk[1], 10);
        const strh = getStrhForIndex(structure, trackId);
        const samplesPerSecond = strh.rate / strh.scale;
        const nthSample = state.callbacks.getSamplesForTrack(trackId);
        const timeInSec = nthSample / samplesPerSecond;
        const timestamp = timeInSec;
        const data = iterator.getSlice(ckSize);
        const infos = (0, parse_avc_1.parseAvc)(data);
        const keyOrDelta = (0, key_1.getKeyFrameOrDeltaFromAvcInfo)(infos);
        const avcProfile = infos.find((i) => i.type === 'avc-profile');
        const ppsProfile = infos.find((i) => i.type === 'avc-pps');
        if (avcProfile && ppsProfile) {
            await state.riff.onProfile({ pps: ppsProfile, sps: avcProfile });
            state.callbacks.tracks.setIsDone();
        }
        // We must also NOT pass a duration because if the the next sample is 0,
        // this sample would be longer. Chrome will pad it with silence.
        // If we'd pass a duration instead, it would shift the audio and we think that audio is not finished
        await state.callbacks.onVideoSample(trackId, (0, convert_audio_or_video_sample_1.convertAudioOrVideoSampleToWebCodecsTimestamps)({
            cts: timestamp,
            dts: timestamp,
            data,
            duration: undefined,
            timestamp,
            trackId,
            type: keyOrDelta,
            offset,
            timescale: samplesPerSecond,
        }, 1));
        return;
    }
    const audioChunk = ckId.match(/^([0-9]{2})wb$/);
    if (audioChunk) {
        const trackId = parseInt(audioChunk[1], 10);
        const strh = getStrhForIndex(structure, trackId);
        const samplesPerSecond = strh.rate / strh.scale;
        const nthSample = state.callbacks.getSamplesForTrack(trackId);
        const timeInSec = nthSample / samplesPerSecond;
        const timestamp = timeInSec;
        const data = iterator.getSlice(ckSize);
        // In example.avi, we have samples with 0 data
        // Chrome fails on these
        // We must also NOT pass a duration because if the the next sample is 0,
        // this sample would be longer. Chrome will pad it with silence.
        // If we'd pass a duration instead, it would shift the audio and we think that audio is not finished
        await state.callbacks.onAudioSample(trackId, (0, convert_audio_or_video_sample_1.convertAudioOrVideoSampleToWebCodecsTimestamps)({
            cts: timestamp,
            dts: timestamp,
            data,
            duration: undefined,
            timestamp,
            trackId,
            type: 'key',
            offset,
            timescale: samplesPerSecond,
        }, 1));
    }
};
exports.handleChunk = handleChunk;
const parseMovi = async ({ iterator, maxOffset, state, structure, }) => {
    while (iterator.counter.getOffset() < maxOffset) {
        if (iterator.bytesRemaining() < 8) {
            return {
                type: 'incomplete',
                continueParsing: () => {
                    return Promise.resolve((0, exports.parseMovi)({ iterator, maxOffset, state, structure }));
                },
            };
        }
        const ckId = iterator.getByteString(4, false);
        const ckSize = iterator.getUint32Le();
        if ((0, may_skip_video_data_1.maySkipVideoData)({
            state,
        }) &&
            state.riff.getAvcProfile()) {
            return {
                type: 'complete',
                box: {
                    type: 'movi-box',
                },
                skipTo: maxOffset,
            };
        }
        if (iterator.bytesRemaining() < ckSize) {
            iterator.counter.decrement(8);
            return {
                type: 'incomplete',
                continueParsing: () => {
                    return Promise.resolve((0, exports.parseMovi)({ iterator, maxOffset, state, structure }));
                },
            };
        }
        await (0, exports.handleChunk)({ iterator, state, structure, ckId, ckSize });
        // Discard added zeroes
        while (iterator.counter.getOffset() < maxOffset &&
            iterator.bytesRemaining() > 0) {
            if (iterator.getUint8() !== 0) {
                iterator.counter.decrement(1);
                break;
            }
        }
    }
    if (iterator.counter.getOffset() === maxOffset) {
        return {
            type: 'complete',
            box: {
                type: 'movi-box',
            },
            skipTo: null,
        };
    }
    if (iterator.counter.getOffset() > maxOffset) {
        throw new Error('Oops, this should not happen!');
    }
    return {
        type: 'incomplete',
        continueParsing: () => {
            return Promise.resolve((0, exports.parseMovi)({ iterator, maxOffset, state, structure }));
        },
    };
};
exports.parseMovi = parseMovi;
